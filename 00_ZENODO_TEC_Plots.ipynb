{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d30b0b68-1504-44c0-9122-26a0206bc07a",
   "metadata": {},
   "source": [
    "Figure unique 3 rangées: F10.7, Kp, Dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f5b54-4775-405d-b043-151a4f919cfe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ===== Composite figure (3 rows): F10.7, Kp, Dst (2010–2025) with TEC period highlighted =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# --------- Plot settings ---------\n",
    "matplotlib.rcParams[\"savefig.dpi\"] = 300\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (10, 9)\n",
    "matplotlib.rcParams[\"font.size\"] = 8\n",
    "\n",
    "# --------- Paths (adapt as needed) ---------\n",
    "CSV_PATH    = Path(\"data/indices/F10_7_2010_2025.csv\")              # JD, F_obs, F_adj\n",
    "Kp_TXT      = Path(\"data/indices/GFZ_all_indices_2010-2025.txt\")    # GFZ Kp file\n",
    "Dst_TXT     = Path(\"data/indices/Kyoto_DST_index_2010-2025.txt\")    # Kyoto Dst file\n",
    "OUT_ALL_PNG = Path(\"figures/F107_Kp_Dst_3rows_2010-2025.png\")\n",
    "\n",
    "# --------- Time windows ---------\n",
    "plot_start = pd.Timestamp(\"2010-01-01\")\n",
    "plot_end   = pd.Timestamp(\"2025-09-26\")\n",
    "tec_start  = pd.Timestamp(\"2015-10-01\")\n",
    "tec_end    = pd.Timestamp(\"2025-09-26\")\n",
    "\n",
    "\n",
    "# --------- Helpers ---------\n",
    "def jd_to_datetime_utc(jd: float) -> datetime:\n",
    "    \"\"\"\n",
    "    Convert a Julian Date (JD) to a timezone-aware UTC datetime.\n",
    "    \"\"\"\n",
    "    jd = float(jd)\n",
    "    J = int(jd + 0.5)\n",
    "    f = jd + 0.5 - J\n",
    "    if J >= 2299161:\n",
    "        a = int((J - 1867216.25) / 36524.25)\n",
    "        A = J + 1 + a - int(a / 4)\n",
    "    else:\n",
    "        A = J\n",
    "    B = A + 1524\n",
    "    C = int((B - 122.1) / 365.25)\n",
    "    D = int(365.25 * C)\n",
    "    E = int((B - D) / 30.6001)\n",
    "    day = B - D - int(30.6001 * E) + f\n",
    "    month = E - 1 if E < 14 else E - 13\n",
    "    year = C - 4716 if month > 2 else C - 4715\n",
    "\n",
    "    day_int = int(day)\n",
    "    frac_day = day - day_int\n",
    "    seconds = frac_day * 86400.0\n",
    "    hh = int(seconds // 3600)\n",
    "    mm = int((seconds % 3600) // 60)\n",
    "    ss = int(round(seconds % 60))\n",
    "\n",
    "    if ss == 60:\n",
    "        ss = 0\n",
    "        mm += 1\n",
    "    if mm == 60:\n",
    "        mm = 0\n",
    "        hh += 1\n",
    "\n",
    "    return datetime(year, month, day_int, hh, mm, ss, tzinfo=timezone.utc)\n",
    "\n",
    "\n",
    "def load_kp_gfz_daily(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load daily Kp from GFZ “all indices” text file.\n",
    "\n",
    "    Returns a DataFrame with:\n",
    "    - date      (Timestamp)\n",
    "    - kp_daily  (daily mean of 8 × 3-hour Kp values)\n",
    "    - kp8       (list of 8 Kp values per day)\n",
    "    \"\"\"\n",
    "    dates, kp_daily, kp8_store = [], [], []\n",
    "\n",
    "    with path.open(\"r\", errors=\"ignore\") as fh:\n",
    "        for line in fh:\n",
    "            if not line.strip() or line.lstrip().startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) < 28:\n",
    "                continue\n",
    "            try:\n",
    "                y, m, d = int(parts[0]), int(parts[1]), int(parts[2])\n",
    "                kp8 = [float(x) for x in parts[7:15]]\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            kparr = np.array(kp8, dtype=float)\n",
    "            kparr[kparr < 0] = np.nan\n",
    "            kp_mean = float(np.nanmean(kparr)) if np.isfinite(kparr).any() else np.nan\n",
    "\n",
    "            dates.append(pd.Timestamp(year=y, month=m, day=d))\n",
    "            kp_daily.append(kp_mean)\n",
    "            kp8_store.append(kp8)\n",
    "\n",
    "    df = pd.DataFrame({\"date\": dates, \"kp_daily\": kp_daily, \"kp8\": kp8_store})\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def load_dst_kyoto_daily(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load daily Dst from a Kyoto DST index file (2010–2025, fixed-width lines).\n",
    "\n",
    "    Returns a DataFrame with:\n",
    "    - date       (Timestamp)\n",
    "    - dst_daily  (daily mean of 24 hourly values)\n",
    "    - dst24      (list of 24 hourly values)\n",
    "    \"\"\"\n",
    "    dates, daily, hours_list = [], [], []\n",
    "\n",
    "    with path.open(\"r\", errors=\"ignore\") as fh:\n",
    "        for line in fh:\n",
    "            if (\n",
    "                not line.strip()\n",
    "                or line.lstrip().startswith(\"#\")\n",
    "                or not line.startswith(\"DST\")\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                yy = int(line[3:5])\n",
    "                mm = int(line[5:7])\n",
    "                dd = int(line[8:10])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            cent = line[14:16].strip()\n",
    "            if cent.isdigit():\n",
    "                year = int(f\"{cent}{yy:02d}\")\n",
    "            else:\n",
    "                year = 1900 + yy if yy >= 50 else 2000 + yy\n",
    "\n",
    "            vals = []\n",
    "            for i in range(24):\n",
    "                s = line[20 + i * 4 : 24 + i * 4].strip()\n",
    "                if not s:\n",
    "                    vals.append(np.nan)\n",
    "                    continue\n",
    "                try:\n",
    "                    v = int(s)\n",
    "                except Exception:\n",
    "                    vals.append(np.nan)\n",
    "                    continue\n",
    "                vals.append(np.nan if v == 9999 else float(v))\n",
    "\n",
    "            dst_mean = float(np.nanmean(vals)) if np.isfinite(vals).any() else np.nan\n",
    "            dates.append(pd.Timestamp(year=year, month=mm, day=dd))\n",
    "            daily.append(dst_mean)\n",
    "            hours_list.append(vals)\n",
    "\n",
    "    df = pd.DataFrame({\"date\": dates, \"dst_daily\": daily, \"dst24\": hours_list})\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --------- Load F10.7 (CSV: JD, F_obs, F_adj) ---------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "cols = list(df.columns)\n",
    "if len(cols) < 3:\n",
    "    raise ValueError(\"F10.7 CSV must have at least 3 columns: JD, F_obs, F_adj.\")\n",
    "\n",
    "jd_col, fobs_col, fadj_col = cols[0], cols[1], cols[2]\n",
    "\n",
    "# Convert JD to UTC datetime and extract date\n",
    "df[\"datetime_utc\"] = pd.to_datetime(\n",
    "    [jd_to_datetime_utc(x) for x in df[jd_col]], utc=True\n",
    ")\n",
    "df[\"date\"] = pd.to_datetime(df[\"datetime_utc\"].dt.date)\n",
    "\n",
    "# Remove obvious outliers in the adjusted column\n",
    "df_no_out = df.drop(df[df[fadj_col] > 500].index)\n",
    "\n",
    "mask_window = (df_no_out[\"date\"] >= plot_start) & (df_no_out[\"date\"] <= plot_end)\n",
    "dfw = df_no_out.loc[mask_window].copy()\n",
    "\n",
    "# --------- Load Kp and Dst ---------\n",
    "kp_df = load_kp_gfz_daily(Kp_TXT)\n",
    "dst_df = load_dst_kyoto_daily(Dst_TXT)\n",
    "\n",
    "kp_df = kp_df[(kp_df[\"date\"] >= plot_start) & (kp_df[\"date\"] <= plot_end)].copy()\n",
    "dst_df = dst_df[(dst_df[\"date\"] >= plot_start) & (dst_df[\"date\"] <= plot_end)].copy()\n",
    "\n",
    "# --------- Masks for TEC study period ---------\n",
    "m_f_tec = (dfw[\"date\"] >= tec_start) & (dfw[\"date\"] <= tec_end)\n",
    "m_kp_tec = (kp_df[\"date\"] >= tec_start) & (kp_df[\"date\"] <= tec_end)\n",
    "m_dst_tec = (dst_df[\"date\"] >= tec_start) & (dst_df[\"date\"] <= tec_end)\n",
    "\n",
    "# --------- Figure: 3 stacked panels, shared x-axis ---------\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(10, 9), dpi=300)\n",
    "\n",
    "# 1) F10.7 (adjusted to 1 AU)\n",
    "ax = axes[0]\n",
    "ax.plot(\n",
    "    dfw[\"date\"],\n",
    "    dfw[fadj_col],\n",
    "    lw=1.2,\n",
    "    label=\"F10.7 (1-AU adjusted, Penticton)\",\n",
    ")\n",
    "ax.plot(\n",
    "    dfw.loc[m_f_tec, \"date\"],\n",
    "    dfw.loc[m_f_tec, fadj_col],\n",
    "    lw=2.0,\n",
    "    color=\"red\",\n",
    "    label=\"TEC study period\",\n",
    ")\n",
    "ax.set_ylabel(r\"$F_{10.7}$ [sfu]\", fontsize=12, weight=\"bold\")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"best\", prop={\"size\": 8})\n",
    "\n",
    "# 2) Daily Kp (mean of 8 × 3-hour values)\n",
    "ax = axes[1]\n",
    "ax.plot(kp_df[\"date\"], kp_df[\"kp_daily\"], lw=1.2, label=\"Daily Kp\")\n",
    "ax.plot(\n",
    "    kp_df.loc[m_kp_tec, \"date\"],\n",
    "    kp_df.loc[m_kp_tec, \"kp_daily\"],\n",
    "    lw=2.0,\n",
    "    color=\"red\",\n",
    "    label=\"TEC study period\",\n",
    ")\n",
    "ax.set_ylabel(\"Kp\", fontsize=12, weight=\"bold\")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"best\", prop={\"size\": 8})\n",
    "\n",
    "# 3) Daily Dst (mean over 24 hours)\n",
    "ax = axes[2]\n",
    "ax.plot(dst_df[\"date\"], dst_df[\"dst_daily\"], lw=1.2, label=\"Daily Dst\")\n",
    "ax.plot(\n",
    "    dst_df.loc[m_dst_tec, \"date\"],\n",
    "    dst_df.loc[m_dst_tec, \"dst_daily\"],\n",
    "    lw=2.0,\n",
    "    color=\"red\",\n",
    "    label=\"TEC study period\",\n",
    ")\n",
    "ax.set_ylabel(\"Dst [nT]\", fontsize=12, weight=\"bold\")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"best\", prop={\"size\": 8})\n",
    "\n",
    "# --------- Common formatting ---------\n",
    "for ax in axes:\n",
    "    ax.set_xlim(plot_start, plot_end)\n",
    "    for tick in ax.yaxis.get_ticklabels():\n",
    "        tick.set_fontsize(12)\n",
    "        tick.set_color(\"black\")\n",
    "        tick.set_weight(\"bold\")\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    ax.tick_params(axis=\"x\", labelbottom=False)\n",
    "\n",
    "for tick in axes[-1].xaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12)\n",
    "    tick.set_color(\"black\")\n",
    "    tick.set_weight(\"bold\")\n",
    "\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.965,\n",
    "    \"F10.7, Kp, and Dst — 2010–2025 | TEC study period: Oct 2015–Sep 2025\",\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    "    weight=\"bold\",\n",
    ")\n",
    "fig.subplots_adjust(left=0.12, right=0.97, top=0.93, bottom=0.06, hspace=0.0)\n",
    "fig.text(0.5, 0.01, \"Date\", ha=\"center\", fontsize=12, weight=\"bold\")\n",
    "\n",
    "OUT_ALL_PNG.parent.mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(OUT_ALL_PNG, dpi=300)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Combined F10.7–Kp–Dst figure saved to: {OUT_ALL_PNG}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25577741-bcfe-49b7-ac29-06f1e588f834",
   "metadata": {},
   "source": [
    "Figure unique 3 rangées avec ombre: F10.7, Kp, Dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b953e1-a53b-4e1b-8aca-14b34f1b4845",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ===== Composite figure (3 rows): F10.7, Kp, Dst (2010–2025) with shaded TEC period =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# --------- Plot settings ---------\n",
    "matplotlib.rcParams[\"savefig.dpi\"] = 300\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (10, 9)\n",
    "matplotlib.rcParams[\"font.size\"] = 8\n",
    "\n",
    "# --------- Paths (adapt as needed) ---------\n",
    "CSV_PATH     = Path(\"data/indices/F10_7_2010_2025.csv\")              # JD, F_obs, F_adj\n",
    "Kp_TXT       = Path(\"data/indices/GFZ_all_indices_2010-2025.txt\")    # GFZ Kp file\n",
    "Dst_TXT      = Path(\"data/indices/Kyoto_DST_index_2010-2025.txt\")    # Kyoto Dst file\n",
    "OUT_ALL_PNG  = Path(\"figures/F107_Kp_Dst_3rows_2010-2025_shadowed.png\")\n",
    "\n",
    "# --------- Time windows ---------\n",
    "plot_start = pd.Timestamp(\"2010-01-01\")\n",
    "plot_end   = pd.Timestamp(\"2025-09-26\")\n",
    "tec_start  = pd.Timestamp(\"2015-10-01\")\n",
    "tec_end    = pd.Timestamp(\"2025-09-26\")\n",
    "\n",
    "\n",
    "# --------- Helpers ---------\n",
    "def jd_to_datetime_utc(jd: float) -> datetime:\n",
    "    \"\"\"\n",
    "    Convert a Julian Date (JD) to a timezone-aware UTC datetime.\n",
    "    \"\"\"\n",
    "    jd = float(jd)\n",
    "    J = int(jd + 0.5)\n",
    "    f = jd + 0.5 - J\n",
    "    if J >= 2299161:\n",
    "        a = int((J - 1867216.25) / 36524.25)\n",
    "        A = J + 1 + a - int(a / 4)\n",
    "    else:\n",
    "        A = J\n",
    "    B = A + 1524\n",
    "    C = int((B - 122.1) / 365.25)\n",
    "    D = int(365.25 * C)\n",
    "    E = int((B - D) / 30.6001)\n",
    "    day = B - D - int(30.6001 * E) + f\n",
    "    month = E - 1 if E < 14 else E - 13\n",
    "    year = C - 4716 if month > 2 else C - 4715\n",
    "\n",
    "    day_int = int(day)\n",
    "    frac_day = day - day_int\n",
    "    seconds = frac_day * 86400.0\n",
    "    hh = int(seconds // 3600)\n",
    "    mm = int((seconds % 3600) // 60)\n",
    "    ss = int(round(seconds % 60))\n",
    "\n",
    "    if ss == 60:\n",
    "        ss = 0\n",
    "        mm += 1\n",
    "    if mm == 60:\n",
    "        mm = 0\n",
    "        hh += 1\n",
    "\n",
    "    return datetime(year, month, day_int, hh, mm, ss, tzinfo=timezone.utc)\n",
    "\n",
    "\n",
    "def load_kp_gfz_daily(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load daily Kp from GFZ “all indices” text file.\n",
    "\n",
    "    Returns a DataFrame with:\n",
    "    - date      (Timestamp)\n",
    "    - kp_daily  (daily mean of 8 × 3-hour Kp values)\n",
    "    - kp8       (list of 8 Kp values per day)\n",
    "    \"\"\"\n",
    "    dates, kp_daily, kp8_store = [], [], []\n",
    "\n",
    "    with path.open(\"r\", errors=\"ignore\") as fh:\n",
    "        for line in fh:\n",
    "            if not line.strip() or line.lstrip().startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) < 28:\n",
    "                continue\n",
    "            try:\n",
    "                y, m, d = int(parts[0]), int(parts[1]), int(parts[2])\n",
    "                kp8 = [float(x) for x in parts[7:15]]\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            kparr = np.array(kp8, dtype=float)\n",
    "            kparr[kparr < 0] = np.nan\n",
    "            kp_mean = float(np.nanmean(kparr)) if np.isfinite(kparr).any() else np.nan\n",
    "\n",
    "            dates.append(pd.Timestamp(year=y, month=m, day=d))\n",
    "            kp_daily.append(kp_mean)\n",
    "            kp8_store.append(kp8)\n",
    "\n",
    "    df = pd.DataFrame({\"date\": dates, \"kp_daily\": kp_daily, \"kp8\": kp8_store})\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def load_dst_kyoto_daily(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load daily Dst from a Kyoto DST index file (2010–2025, fixed-width lines).\n",
    "\n",
    "    Returns a DataFrame with:\n",
    "    - date       (Timestamp)\n",
    "    - dst_daily  (daily mean of 24 hourly values)\n",
    "    - dst24      (list of 24 hourly values)\n",
    "    \"\"\"\n",
    "    dates, daily, hours_list = [], [], []\n",
    "\n",
    "    with path.open(\"r\", errors=\"ignore\") as fh:\n",
    "        for line in fh:\n",
    "            if (\n",
    "                not line.strip()\n",
    "                or line.lstrip().startswith(\"#\")\n",
    "                or not line.startswith(\"DST\")\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                yy = int(line[3:5])\n",
    "                mm = int(line[5:7])\n",
    "                dd = int(line[8:10])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            cent = line[14:16].strip()\n",
    "            if cent.isdigit():\n",
    "                year = int(f\"{cent}{yy:02d}\")\n",
    "            else:\n",
    "                year = 1900 + yy if yy >= 50 else 2000 + yy\n",
    "\n",
    "            vals = []\n",
    "            for i in range(24):\n",
    "                s = line[20 + i * 4 : 24 + i * 4].strip()\n",
    "                if not s:\n",
    "                    vals.append(np.nan)\n",
    "                    continue\n",
    "                try:\n",
    "                    v = int(s)\n",
    "                except Exception:\n",
    "                    vals.append(np.nan)\n",
    "                    continue\n",
    "                vals.append(np.nan if v == 9999 else float(v))\n",
    "\n",
    "            dst_mean = float(np.nanmean(vals)) if np.isfinite(vals).any() else np.nan\n",
    "            dates.append(pd.Timestamp(year=year, month=mm, day=dd))\n",
    "            daily.append(dst_mean)\n",
    "            hours_list.append(vals)\n",
    "\n",
    "    df = pd.DataFrame({\"date\": dates, \"dst_daily\": daily, \"dst24\": hours_list})\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --------- Load F10.7 (CSV: JD, F_obs, F_adj) ---------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "cols = list(df.columns)\n",
    "if len(cols) < 3:\n",
    "    raise ValueError(\"F10.7 CSV must have at least 3 columns: JD, F_obs, F_adj.\")\n",
    "\n",
    "jd_col, fobs_col, fadj_col = cols[0], cols[1], cols[2]\n",
    "\n",
    "# Convert JD to UTC datetime and extract date\n",
    "df[\"datetime_utc\"] = pd.to_datetime(\n",
    "    [jd_to_datetime_utc(x) for x in df[jd_col]], utc=True\n",
    ")\n",
    "df[\"date\"] = pd.to_datetime(df[\"datetime_utc\"].dt.date)\n",
    "\n",
    "# Remove obvious outliers in the adjusted column\n",
    "df_no_out = df.drop(df[df[fadj_col] > 500].index)\n",
    "\n",
    "mask_window = (df_no_out[\"date\"] >= plot_start) & (df_no_out[\"date\"] <= plot_end)\n",
    "dfw = df_no_out.loc[mask_window].copy()\n",
    "\n",
    "# --------- Load Kp and Dst ---------\n",
    "kp_df = load_kp_gfz_daily(Kp_TXT)\n",
    "dst_df = load_dst_kyoto_daily(Dst_TXT)\n",
    "\n",
    "kp_df = kp_df[(kp_df[\"date\"] >= plot_start) & (kp_df[\"date\"] <= plot_end)].copy()\n",
    "dst_df = dst_df[(dst_df[\"date\"] >= plot_start) & (dst_df[\"date\"] <= plot_end)].copy()\n",
    "\n",
    "# --------- Masks for TEC study period ---------\n",
    "m_f_tec = (dfw[\"date\"] >= tec_start) & (dfw[\"date\"] <= tec_end)\n",
    "m_kp_tec = (kp_df[\"date\"] >= tec_start) & (kp_df[\"date\"] <= tec_end)\n",
    "m_dst_tec = (dst_df[\"date\"] >= tec_start) & (dst_df[\"date\"] <= tec_end)\n",
    "\n",
    "# --------- Figure: 3 stacked panels, shared x-axis ---------\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(10, 9), dpi=300)\n",
    "\n",
    "# 1) F10.7 (adjusted to 1 AU)\n",
    "ax = axes[0]\n",
    "ax.plot(\n",
    "    dfw[\"date\"],\n",
    "    dfw[fadj_col],\n",
    "    lw=1.2,\n",
    "    label=\"F10.7 (1-AU adjusted, Penticton)\",\n",
    ")\n",
    "ax.axvspan(\n",
    "    tec_start,\n",
    "    tec_end,\n",
    "    color=\"red\",\n",
    "    alpha=0.2,\n",
    "    linewidth=0,\n",
    "    label=\"TEC study period\",\n",
    ")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"upper center\", prop={\"size\": 8})\n",
    "\n",
    "# 2) Daily Kp (mean of 8 × 3-hour values)\n",
    "ax = axes[1]\n",
    "ax.plot(kp_df[\"date\"], kp_df[\"kp_daily\"], lw=1.2, label=\"Daily Kp (GFZ)\")\n",
    "ax.axvspan(\n",
    "    tec_start,\n",
    "    tec_end,\n",
    "    color=\"green\",\n",
    "    alpha=0.2,\n",
    "    linewidth=0,\n",
    "    label=\"TEC study period\",\n",
    ")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"upper center\", prop={\"size\": 8})\n",
    "\n",
    "# 3) Daily Dst (mean over 24 hours)\n",
    "ax = axes[2]\n",
    "ax.plot(dst_df[\"date\"], dst_df[\"dst_daily\"], lw=1.2, label=\"Daily Dst (Kyoto)\")\n",
    "ax.axvspan(\n",
    "    tec_start,\n",
    "    tec_end,\n",
    "    color=\"orange\",\n",
    "    alpha=0.2,\n",
    "    linewidth=0,\n",
    "    label=\"TEC study period\",\n",
    ")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"lower center\", prop={\"size\": 8})\n",
    "\n",
    "# --------- Common formatting ---------\n",
    "for ax in axes:\n",
    "    ax.set_xlim(plot_start, plot_end)\n",
    "    for tick in ax.yaxis.get_ticklabels():\n",
    "        tick.set_fontsize(12)\n",
    "        tick.set_color(\"black\")\n",
    "        tick.set_weight(\"bold\")\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    ax.tick_params(axis=\"x\", labelbottom=False)\n",
    "\n",
    "for tick in axes[-1].xaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12)\n",
    "    tick.set_color(\"black\")\n",
    "    tick.set_weight(\"bold\")\n",
    "\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.965,\n",
    "    \"F10.7, Kp, and Dst — 2010–2025 | TEC study period: Oct 2015–Sep 2025 (shaded)\",\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    "    weight=\"bold\",\n",
    ")\n",
    "fig.subplots_adjust(left=0.12, right=0.97, top=0.93, bottom=0.06, hspace=0.0)\n",
    "fig.text(0.5, 0.01, \"Date\", ha=\"center\", fontsize=12, weight=\"bold\")\n",
    "fig.text(0.05, 0.75, r\"$F_{10.7}$ [sfu]\", ha=\"center\", rotation=90, fontsize=12, weight=\"bold\")\n",
    "fig.text(0.05, 0.50, \"Kp\", ha=\"center\", rotation=90, fontsize=12, weight=\"bold\")\n",
    "fig.text(0.05, 0.15, \"Dst [nT]\", ha=\"center\", rotation=90, fontsize=12, weight=\"bold\")\n",
    "\n",
    "OUT_ALL_PNG.parent.mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(OUT_ALL_PNG, dpi=300)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Combined shaded F10.7–Kp–Dst figure saved to: {OUT_ALL_PNG}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69890085-01e2-4707-b7b5-167818c3a731",
   "metadata": {},
   "source": [
    "Generate 4 daily tec figures / Year with GIM and offset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69724c0f-5cb5-4a8b-a1bf-9507d12e8ec5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# DAILY 2×2 FIGURES PER YEAR\n",
    "# ========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# --- input CSV files (already enriched with indices / GIM) ---\n",
    "CSV_30MIN_WITH_GIM = Path(\"data/2015_2025_MS_VTEC_30min_stats.csv\")\n",
    "CSV_DAILY_WITH_OFF = Path(\n",
    "    \"data/2015_2025_MS_VTEC_daily_stats_UTC_with_indices_and_max_with_GFZlabels.csv\"\n",
    ")\n",
    "\n",
    "# --- TEC/GIM column names in the 30-min CSV ---\n",
    "VTEC_MED_COL  = \"VTEC_median\"   # main 30-min VTEC statistic (median)\n",
    "VTEC_MEAN_COL = \"VTEC_mean\"     # optional; ignore if not present\n",
    "GIM_COL       = \"vtec_gim\"      # collocated GIM VTEC\n",
    "GIM_OFFSET_COL = \"gim_offset_tecu\"\n",
    "\n",
    "# --- output directory for figures ---\n",
    "FIG_DIR = Path(\"figures/figs_quiet/MS_FIGURES_GIM\")\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb697c5-9c49-4488-a3e4-ba4b567e88b5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _set_xticks_30min(ax: plt.Axes) -> None:\n",
    "    \"\"\"Set x-ticks every 2 hours from 0 to 24.\"\"\"\n",
    "    ax.set_xlim(-1, 24)\n",
    "    ax.set_xticks(np.arange(0, 24, 2))\n",
    "    ax.set_xticklabels([f\"{h:02d}\" for h in range(0, 24, 2)], rotation=0)\n",
    "\n",
    "\n",
    "# --- I/O helpers for 30-min and daily CSVs ---\n",
    "def _load_30min_csv(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the 30-min VTEC file, ensuring we have:\n",
    "      - ts_utc   (UTC timestamp)\n",
    "      - date_utc (date)\n",
    "      - numeric VTEC/GIM columns\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # UTC timestamp column\n",
    "    if \"ts_utc\" in df.columns:\n",
    "        df[\"ts_utc\"] = pd.to_datetime(df[\"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "    else:\n",
    "        t = pd.to_datetime(df[\"time\"], utc=True, errors=\"coerce\")\n",
    "        df[\"ts_utc\"] = t\n",
    "\n",
    "    # UTC date (date_utc)\n",
    "    if \"date_utc\" in df.columns:\n",
    "        df[\"date_utc\"] = pd.to_datetime(df[\"date_utc\"], utc=True, errors=\"coerce\").dt.date\n",
    "    else:\n",
    "        df[\"date_utc\"] = df[\"ts_utc\"].dt.floor(\"D\").dt.date\n",
    "\n",
    "    # Coerce key columns to numeric if present\n",
    "    for c in [VTEC_MED_COL, VTEC_MEAN_COL, GIM_COL]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _load_daily_csv(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the daily statistics file, ensuring a date_utc column.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    if \"date_utc\" in df.columns:\n",
    "        df[\"date_utc\"] = pd.to_datetime(df[\"date_utc\"], utc=True, errors=\"coerce\").dt.date\n",
    "    elif \"date\" in df.columns:\n",
    "        df[\"date_utc\"] = pd.to_datetime(df[\"date\"], utc=True, errors=\"coerce\").dt.date\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- load 30-min and daily inputs ---\n",
    "s30 = _load_30min_csv(CSV_30MIN_WITH_GIM)\n",
    "\n",
    "# normalize time/date types\n",
    "s30[\"ts_utc\"] = pd.to_datetime(s30[\"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "s30[\"date_utc\"] = pd.to_datetime(s30[\"date_utc\"], utc=True, errors=\"coerce\").dt.date\n",
    "\n",
    "daily_off = (\n",
    "    _load_daily_csv(CSV_DAILY_WITH_OFF)\n",
    "    if Path(CSV_DAILY_WITH_OFF).exists()\n",
    "    else pd.DataFrame(columns=[\"date_utc\", GIM_OFFSET_COL])\n",
    ")\n",
    "\n",
    "\n",
    "# --- per-day GIM offset: from daily CSV if present, otherwise from 30-min median difference ---\n",
    "def get_daily_offset(day, s30_df: pd.DataFrame, daily_df: pd.DataFrame | None = None) -> float:\n",
    "    \"\"\"\n",
    "    Return the daily GIM offset (median(VTEC − GIM) in TECU) for a given day.\n",
    "\n",
    "    Priority:\n",
    "      1) If a daily CSV is provided and contains a non-NaN gim_offset_tecu for that day, use it.\n",
    "      2) Otherwise, compute median(VTEC_median − vtec_gim) from the 30-min record.\n",
    "    \"\"\"\n",
    "    # 1) daily CSV\n",
    "    if daily_df is not None and GIM_OFFSET_COL in daily_df.columns:\n",
    "        row = daily_df.loc[daily_df[\"date_utc\"] == day, GIM_OFFSET_COL]\n",
    "        if not row.empty and pd.notna(row.iloc[0]):\n",
    "            return float(row.iloc[0])\n",
    "\n",
    "    # 2) fallback from 30-min time series\n",
    "    mask = s30_df[\"date_utc\"] == day\n",
    "    v = pd.to_numeric(s30_df.loc[mask, VTEC_MED_COL], errors=\"coerce\")\n",
    "    g = pd.to_numeric(s30_df.loc[mask, GIM_COL], errors=\"coerce\")\n",
    "    joined = pd.concat([v, g], axis=1).dropna()\n",
    "    if joined.empty:\n",
    "        return float(\"nan\")\n",
    "    return float((joined.iloc[:, 0] - joined.iloc[:, 1]).median())\n",
    "\n",
    "\n",
    "# --- selection of 4 representative days per year ---\n",
    "# Default targets: ~15 Jan / 15 Apr / 15 Jul / 15 Nov.\n",
    "DEFAULT_MONTH_DAY = [(1, 15), (4, 15), (7, 15), (11, 15)]\n",
    "\n",
    "\n",
    "def nearest_available_date(year: int, target_date, available_dates) -> date | None:\n",
    "    \"\"\"\n",
    "    Return the available date in `available_dates` closest to `target_date`.\n",
    "    All dates treated as naïve (no timezone).\n",
    "    \"\"\"\n",
    "    target = pd.Timestamp(target_date)  # naïve\n",
    "\n",
    "    avail_ts = pd.to_datetime(available_dates, errors=\"coerce\")\n",
    "    avail_ts = avail_ts[~pd.isna(avail_ts)]\n",
    "    if len(avail_ts) == 0:\n",
    "        return None\n",
    "\n",
    "    diff = (avail_ts - target)\n",
    "    try:\n",
    "        deltas = diff.to_numpy()\n",
    "    except Exception:\n",
    "        deltas = np.asarray(diff)\n",
    "\n",
    "    i_min = int(np.nanargmin(np.abs(deltas)))\n",
    "    return pd.Timestamp(avail_ts[i_min]).date()\n",
    "\n",
    "\n",
    "def pick_days_for_year(year: int, s30: pd.DataFrame) -> list[date]:\n",
    "    \"\"\"\n",
    "    Pick 4 representative days for a given year, as close as possible\n",
    "    to (year-01-15, year-04-15, year-07-15, year-11-15), but constrained\n",
    "    to dates where 30-min data exist.\n",
    "    \"\"\"\n",
    "    date_utc = pd.to_datetime(s30[\"date_utc\"], errors=\"coerce\").dt.date\n",
    "    mask_year = pd.to_datetime(date_utc).dt.year == year\n",
    "\n",
    "    dates_year = pd.to_datetime(date_utc[mask_year], errors=\"coerce\").dropna().unique()\n",
    "    out: list[date] = []\n",
    "    for m, d in DEFAULT_MONTH_DAY:\n",
    "        tgt = pd.Timestamp(year=year, month=m, day=d)\n",
    "        chosen = nearest_available_date(year, tgt, dates_year)\n",
    "        if chosen is not None:\n",
    "            out.append(chosen)\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- plot 2×2 daily panels for a given year ---\n",
    "def plot_year_grid(year: int, s30: pd.DataFrame, days: list[date] | None = None) -> Path | None:\n",
    "    \"\"\"\n",
    "    Produce a 2×2 daily panel figure for one year, comparing 30-min VTEC\n",
    "    (median / mean) with CODG GIM, and annotate the daily median offset.\n",
    "    \"\"\"\n",
    "    # selected days\n",
    "    if not days:\n",
    "        days = pick_days_for_year(year, s30)\n",
    "    days = list(days)\n",
    "\n",
    "    if len(days) == 0:\n",
    "        print(f\"[INFO] {year}: no data available.\")\n",
    "        return None\n",
    "    if len(days) < 4:\n",
    "        print(f\"[INFO] {year}: only {len(days)} day(s) available; 2×2 grid will be partial.\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 4), sharex=True, sharey=False, constrained_layout=False)\n",
    "    fig.subplots_adjust(hspace=0.0, wspace=0.12)\n",
    "\n",
    "    has_mean = VTEC_MEAN_COL in s30.columns\n",
    "    line_kw = dict(lw=1.6)\n",
    "\n",
    "    for k in range(4):\n",
    "        r, c = divmod(k, 2)\n",
    "        ax = axes[r, c]\n",
    "        if k >= len(days):\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        day = days[k]\n",
    "        day0 = pd.Timestamp(day, tz=\"UTC\")\n",
    "        day1 = day0 + pd.Timedelta(days=1)\n",
    "\n",
    "        sd = s30.loc[(s30[\"date_utc\"] == day)].copy()\n",
    "        if sd.empty:\n",
    "            ax.text(\n",
    "                0.5, 0.5, \"No data\",\n",
    "                transform=ax.transAxes, ha=\"center\", va=\"center\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # UT hours since midnight\n",
    "        hours = (sd[\"ts_utc\"] - day0).dt.total_seconds() / 3600.0\n",
    "\n",
    "        # plots\n",
    "        if VTEC_MED_COL in sd.columns:\n",
    "            ax.plot(hours, sd[VTEC_MED_COL], label=\"VTEC median (30 min)\", **line_kw)\n",
    "        if has_mean:\n",
    "            ax.plot(hours, sd[VTEC_MEAN_COL], label=\"VTEC mean (30 min)\", ls=\"--\", **line_kw)\n",
    "        if GIM_COL in sd.columns:\n",
    "            ax.plot(hours, sd[GIM_COL], label=\"CODG GIM (30 min)\", ls=\":\", **line_kw)\n",
    "\n",
    "        # daily GIM offset\n",
    "        off = get_daily_offset(day, sd, daily_off)\n",
    "        if np.isfinite(off):\n",
    "            off_txt = f\"median offset = {off:.2f} TECU\"\n",
    "        else:\n",
    "            off_txt = \"median offset = n/a\"\n",
    "\n",
    "        ax.set_title(f\"{day} — {off_txt}\", fontsize=10, loc=\"center\", weight=\"bold\")\n",
    "        ax.set_xlim(0, 24)\n",
    "        ax.set_yticks([5, 15, 25, 35, 45])\n",
    "        ax.set_ylim(0, 35)\n",
    "        ax.grid(True, alpha=0.25)\n",
    "\n",
    "        _set_xticks_30min(ax)\n",
    "\n",
    "        for t in ax.yaxis.get_ticklabels():\n",
    "            t.set_fontsize(10)\n",
    "            t.set_color(\"black\")\n",
    "            t.set_weight(\"bold\")\n",
    "        for t in ax.xaxis.get_ticklabels():\n",
    "            t.set_fontsize(10)\n",
    "            t.set_color(\"black\")\n",
    "            t.set_weight(\"bold\")\n",
    "\n",
    "    # common legend from first panel\n",
    "    handles, labels = [], []\n",
    "    for line in axes[0, 0].lines:\n",
    "        handles.append(line)\n",
    "        labels.append(line.get_label())\n",
    "\n",
    "    # hide x-labels on top row\n",
    "    plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    fig.legend(\n",
    "        handles, labels,\n",
    "        loc=\"upper center\", ncol=3, frameon=False, bbox_to_anchor=(0.5, 1.02)\n",
    "    )\n",
    "\n",
    "    fig.text(\n",
    "        0.5, 1.06,\n",
    "        f\"OUCA Observatory — 30-min VTEC vs CODG GIM (year {year})\",\n",
    "        ha=\"center\", fontsize=12, weight=\"bold\"\n",
    "    )\n",
    "    fig.text(0.5, 0.02, \"UTC hour\", ha=\"center\", fontsize=12, weight=\"bold\")\n",
    "    fig.text(0.08, 0.5, \"TEC [TECU]\", va=\"center\", rotation=\"vertical\", fontsize=12, weight=\"bold\")\n",
    "\n",
    "    out = FIG_DIR / f\"VTEC_GIM_daily_2x2_{year}.png\"\n",
    "    fig.savefig(out, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Figure {year} → {out}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- run for all years available in the 30-min CSV ---\n",
    "years = (\n",
    "    pd.to_datetime(s30[\"date_utc\"], errors=\"coerce\")\n",
    "      .dt.year.dropna().astype(int).unique()\n",
    ")\n",
    "years = sorted(years)\n",
    "\n",
    "for y in years:\n",
    "    plot_year_grid(y, s30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc445f6-75fe-4f6b-9c2a-f1f54ea96d0f",
   "metadata": {},
   "source": [
    "Generate Observed VTEC and GIM for Quiet days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10a3e8-38e0-44de-844f-4148292984c3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# === Target period ===\n",
    "PERIOD_START = pd.Timestamp(\"2015-10-01\", tz=\"UTC\").date()\n",
    "PERIOD_END   = pd.Timestamp(\"2025-09-26\", tz=\"UTC\").date()\n",
    "\n",
    "FIG_DIR = Path(r\"C:/path/to/output/figures/figs_quiet/MS_FIGURES_GIM\")  # <-- adjust\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "VTEC_COL   = \"VTEC_median\"\n",
    "MEAN_COL   = \"VTEC_mean\"\n",
    "GIM_COL    = \"vtec_gim\"\n",
    "GIM_OFFSET_COL = \"gim_offset_tecu\"\n",
    "\n",
    "\n",
    "def _set_xticks_30min(ax: plt.Axes) -> None:\n",
    "    \"\"\"Set x-ticks every 2 hours from 0 to 24.\"\"\"\n",
    "    ax.set_xlim(0, 24)\n",
    "    ax.set_xticks(np.arange(0, 24, 2))\n",
    "    ax.set_xticklabels([f\"{h:02d}\" for h in range(0, 24, 2)], rotation=0)\n",
    "\n",
    "\n",
    "# --- Ensure time/date types are clean in s30 and daily ---\n",
    "s30[\"ts_utc\"]   = pd.to_datetime(s30[\"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "s30[\"date_utc\"] = pd.to_datetime(s30[\"date_utc\"], errors=\"coerce\").dt.date\n",
    "\n",
    "daily = _load_daily_csv(CSV_DAILY_WITH_OFF)\n",
    "daily[\"date_utc\"] = pd.to_datetime(daily[\"date_utc\"], errors=\"coerce\").dt.date\n",
    "\n",
    "\n",
    "# --- Per-day GIM offset: daily CSV if present, otherwise from 30-min series ---\n",
    "def get_daily_offset(day, s30_df: pd.DataFrame, daily_df: pd.DataFrame | None = None) -> float:\n",
    "    \"\"\"\n",
    "    Return the daily offset (median(VTEC − GIM) in TECU) for a given day.\n",
    "\n",
    "    Priority:\n",
    "      1) If `daily_df` has a non-NaN gim_offset_tecu for that day, use it.\n",
    "      2) Otherwise, compute median(VTEC_median − vtec_gim) from the 30-min series.\n",
    "    \"\"\"\n",
    "    # 1) from daily file (if available)\n",
    "    if daily_df is not None and GIM_OFFSET_COL in daily_df.columns:\n",
    "        v = daily_df.loc[daily_df[\"date_utc\"] == day, GIM_OFFSET_COL].dropna()\n",
    "        if len(v):\n",
    "            return float(v.iloc[0])\n",
    "\n",
    "    # 2) fallback from 30-min data\n",
    "    df = s30_df.loc[s30_df[\"date_utc\"] == day, [VTEC_COL, GIM_COL]].dropna()\n",
    "    if df.empty:\n",
    "        return float(\"nan\")\n",
    "    return float((df[VTEC_COL] - df[GIM_COL]).median())\n",
    "\n",
    "\n",
    "# --- Quietness metrics computed from the 30-min VTEC series ---\n",
    "def daily_quiet_metrics(s30_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute basic daily metrics used to rank \"quiet\" days:\n",
    "      - coverage of VTEC and GIM (fraction of 48 slots with data)\n",
    "      - interquartile range (IQR)\n",
    "      - standard deviation\n",
    "      - median |ΔVTEC| between consecutive samples\n",
    "    \"\"\"\n",
    "\n",
    "    def _one(df: pd.DataFrame) -> pd.Series:\n",
    "        v = pd.to_numeric(df[VTEC_COL], errors=\"coerce\")\n",
    "        g = pd.to_numeric(df[GIM_COL], errors=\"coerce\")\n",
    "\n",
    "        cov_v = v.notna().sum() / 48.0\n",
    "        cov_g = g.notna().sum() / 48.0\n",
    "\n",
    "        if v.notna().any():\n",
    "            q75 = np.nanpercentile(v, 75)\n",
    "            q25 = np.nanpercentile(v, 25)\n",
    "            iqr = q75 - q25\n",
    "            std = np.nanstd(v)\n",
    "            vv = v.to_numpy()\n",
    "            dmed = (\n",
    "                np.nanmedian(np.abs(np.diff(vv)))\n",
    "                if np.count_nonzero(~np.isnan(vv)) > 1\n",
    "                else np.nan\n",
    "            )\n",
    "        else:\n",
    "            iqr = std = dmed = np.nan\n",
    "\n",
    "        return pd.Series(\n",
    "            {\n",
    "                \"cov_vtec\": cov_v,\n",
    "                \"cov_gim\":  cov_g,\n",
    "                \"iqr\":      iqr,\n",
    "                \"std\":      std,\n",
    "                \"dV_med\":   dmed,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    m = s30_df.groupby(\"date_utc\", as_index=False).apply(_one).reset_index(drop=True)\n",
    "    return m\n",
    "\n",
    "\n",
    "def pick_10_quiet_days_geomagQ(s30_df: pd.DataFrame, daily_df: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Select 10 geomagnetically quiet days based on:\n",
    "      - daily_df.geomag_label_gfz_QDNQ == 'Q'\n",
    "      - good coverage / smooth VTEC metrics (cov_vtec, cov_gim, iqr, dV_med, std)\n",
    "    \"\"\"\n",
    "    if \"geomag_label_gfz_QDNQ\" not in daily_df.columns:\n",
    "        raise RuntimeError(\"Column 'geomag_label_gfz_QDNQ' is missing from the daily CSV.\")\n",
    "\n",
    "    # Restrict to target period\n",
    "    d = daily_df.copy()\n",
    "    d = d[(d[\"date_utc\"] >= PERIOD_START) & (d[\"date_utc\"] <= PERIOD_END)].copy()\n",
    "    d[\"geomag_label_norm\"] = (\n",
    "        d[\"geomag_label_gfz_QDNQ\"].astype(str).str.strip().str.upper()\n",
    "    )\n",
    "\n",
    "    # 'Q' (quiet) days from GFZ\n",
    "    q_days = d.loc[d[\"geomag_label_norm\"] == \"Q\", [\"date_utc\"]].dropna().drop_duplicates()\n",
    "\n",
    "    # Metrics over 30-min data in the same period\n",
    "    s = s30_df[\n",
    "        (s30_df[\"date_utc\"] >= PERIOD_START) & (s30_df[\"date_utc\"] <= PERIOD_END)\n",
    "    ].copy()\n",
    "    metrics = daily_quiet_metrics(s)\n",
    "\n",
    "    # Keep only Q days\n",
    "    metQ = metrics.merge(q_days, on=\"date_utc\", how=\"inner\")\n",
    "\n",
    "    # Data coverage filters\n",
    "    metQ = metQ[(metQ[\"cov_vtec\"] >= 0.85) & (metQ[\"cov_gim\"] >= 0.70)].copy()\n",
    "\n",
    "    # Sort by quietness: low IQR, low median |ΔV|, low std\n",
    "    metQ = metQ.sort_values([\"iqr\", \"dV_med\", \"std\"], ascending=True)\n",
    "\n",
    "    days = list(metQ[\"date_utc\"].head(10))\n",
    "    if len(days) < 10:\n",
    "        print(\n",
    "            f\"[INFO] Only {len(days)} 'Q' day(s) pass coverage/quality filters in the target period.\"\n",
    "        )\n",
    "    return days\n",
    "\n",
    "\n",
    "def plot_quiet_days_5x2(\n",
    "    days: list,\n",
    "    s30_df: pd.DataFrame,\n",
    "    daily_df: pd.DataFrame | None = None,\n",
    "    title_suffix: str = \"geomagnetically quiet days (GFZ label Q)\",\n",
    ") -> Path | None:\n",
    "    \"\"\"\n",
    "    Plot up to 10 quiet days in a 5×2 panel:\n",
    "      - VTEC median (30-min)\n",
    "      - optional VTEC mean (30-min)\n",
    "      - CODG GIM VTEC (30-min)\n",
    "    \"\"\"\n",
    "    # Pad to 10 to fill grid\n",
    "    days = list(days) + [None] * max(0, 10 - len(days))\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        5, 2, figsize=(10, 10), sharex=True, sharey=False, constrained_layout=False\n",
    "    )\n",
    "    fig.subplots_adjust(hspace=0.0, wspace=0.12)\n",
    "\n",
    "    handles_global = None\n",
    "\n",
    "    for k, day in enumerate(days):\n",
    "        r, c = divmod(k, 2)\n",
    "        ax = axes[r, c]\n",
    "\n",
    "        if day is None:\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        df = s30_df.loc[s30_df[\"date_utc\"] == day].copy().sort_values(\"ts_utc\")\n",
    "        if df.empty:\n",
    "            ax.text(\n",
    "                0.5, 0.5, \"No data\",\n",
    "                transform=ax.transAxes, ha=\"center\", va=\"center\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        t_hours = df[\"ts_utc\"].dt.hour + df[\"ts_utc\"].dt.minute / 60.0\n",
    "\n",
    "        ln1 = ax.plot(\n",
    "            t_hours, df[VTEC_COL],\n",
    "            lw=2.0, label=\"VTEC median (30 min)\"\n",
    "        )[0]\n",
    "\n",
    "        if MEAN_COL in df.columns:\n",
    "            ln2 = ax.plot(\n",
    "                t_hours, df[MEAN_COL],\n",
    "                lw=1.8, ls=\"--\", label=\"VTEC mean (30 min)\"\n",
    "            )[0]\n",
    "\n",
    "        ln3 = ax.plot(\n",
    "            t_hours, df[GIM_COL],\n",
    "            lw=1.8, ls=\"--\", label=\"CODG GIM (30 min)\"\n",
    "        )[0]\n",
    "\n",
    "        off = get_daily_offset(day, s30_df, daily_df)\n",
    "        off_txt = (\n",
    "            f\"median offset = {off:.2f} TECU\"\n",
    "            if np.isfinite(off) else \"median offset = n/a\"\n",
    "        )\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"{day} — {off_txt}\",\n",
    "            fontsize=10, loc=\"center\", weight=\"bold\", y=0.80\n",
    "        )\n",
    "        ax.set_xlim(0, 24)\n",
    "        ax.set_ylim(0, 21)\n",
    "        ax.set_yticks([5, 10, 15, 20])\n",
    "        ax.grid(True, alpha=0.25)\n",
    "\n",
    "        _set_xticks_30min(ax)\n",
    "\n",
    "        for t in ax.yaxis.get_ticklabels():\n",
    "            t.set_fontsize(10)\n",
    "            t.set_color(\"black\")\n",
    "            t.set_weight(\"bold\")\n",
    "        for t in ax.xaxis.get_ticklabels():\n",
    "            t.set_fontsize(10)\n",
    "            t.set_color(\"black\")\n",
    "            t.set_weight(\"bold\")\n",
    "\n",
    "        if handles_global is None:\n",
    "            handles_global = [line for line in ax.lines]\n",
    "\n",
    "    # Common legend\n",
    "    if handles_global:\n",
    "        labels_global = [h.get_label() for h in handles_global]\n",
    "        fig.legend(\n",
    "            handles_global, labels_global,\n",
    "            loc=\"upper center\", ncol=3, frameon=False,\n",
    "            bbox_to_anchor=(0.5, 0.93)\n",
    "        )\n",
    "\n",
    "    # Hide x labels on top row\n",
    "    plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "    fig.subplots_adjust(hspace=0.0)\n",
    "\n",
    "    fig.text(\n",
    "        0.5, 0.94,\n",
    "        \"OUCA Observatory — Quiet-time VTEC vs CODG GIM\",\n",
    "        ha=\"center\", fontsize=12, weight=\"bold\"\n",
    "    )\n",
    "    fig.text(0.5, 0.06, \"Local Time (LT)\", ha=\"center\", fontsize=12, weight=\"bold\")\n",
    "    fig.text(0.08, 0.5, \"TEC [TECU]\", va=\"center\", rotation=\"vertical\",\n",
    "             fontsize=12, weight=\"bold\")\n",
    "\n",
    "    out = FIG_DIR / \"VTEC_GIM_10days_geomagQ_5x2_2015-2025.png\"\n",
    "    fig.savefig(out, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Quiet 10-day figure saved → {out}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# === Selection + plot (based ONLY on geomag_label_gfz_QDNQ == 'Q') ===\n",
    "quiet_days_Q = pick_10_quiet_days_geomagQ(s30, daily)\n",
    "print(\"Selected 'Q' days:\", quiet_days_Q)\n",
    "\n",
    "plot_quiet_days_5x2(\n",
    "    quiet_days_Q, s30, daily,\n",
    "    title_suffix=\"geomagnetically quiet days (GFZ label Q)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5997a5d-7c53-46bb-bce1-4de2bcccb001",
   "metadata": {},
   "source": [
    "Generate Final figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c7386-36b4-465e-92c2-95c1d51c6aef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Union, List\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, date, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# CELL 0 — SETUP & HELPERS\n",
    "# =========================\n",
    "\n",
    "# ------- Paths & parameters (ADAPT TO YOUR SETUP) -------\n",
    "CSV_DAILY = Path(\"/path/to/2015_2025_MS_VTEC_daily_stats_UTC_with_indices_and_max_with_GFZlabels.csv\")\n",
    "CSV_30MIN = Path(\"/path/to/2015_2025_MS_VTEC_30min_stats.csv\")\n",
    "OUTDIR_FIG = Path(\"/path/to/figures/figs_quiet\")\n",
    "OUTDIR_FIG.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TIME_COL   = \"date_utc\"\n",
    "OFFSET_COL = \"gim_offset_tecu\"\n",
    "QUIET_COL  = \"geomag_label_gfz_QDNQ\"   # 'Q', 'D', 'NQ'\n",
    "SOLAR_COL  = \"solar_label\"            # 'Low', 'High', 'NA'\n",
    "LOCAL_TZ   = \"Africa/Casablanca\"      # used in other cells for local-time plots\n",
    "VTEC_COL   = \"VTEC_median\"            # VTEC column in the 30-min CSV\n",
    "\n",
    "START = pd.Timestamp(\"2015-10-01\", tz=\"UTC\")\n",
    "END   = pd.Timestamp(\"2025-09-26\", tz=\"UTC\")\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "# ===== Load 30-min series (for possible later use) =====\n",
    "s30 = pd.read_csv(CSV_30MIN)\n",
    "\n",
    "t_utc = pd.to_datetime(s30[\"time\"], utc=True, errors=\"coerce\")\n",
    "s30 = s30.assign(\n",
    "    ts_utc=t_utc,\n",
    "    date_utc=t_utc.dt.floor(\"D\").dt.date,\n",
    "    slot=(t_utc.dt.hour * 2 + (t_utc.dt.minute // 30)).astype(int)  # 0..47\n",
    ")\n",
    "s30[VTEC_COL] = pd.to_numeric(s30[VTEC_COL], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# ===== Load daily stats + restrict time window =====\n",
    "df = pd.read_csv(CSV_DAILY)\n",
    "df[TIME_COL] = pd.to_datetime(df[TIME_COL], utc=True, errors=\"coerce\")\n",
    "df = df[(df[TIME_COL] >= START) & (df[TIME_COL] <= END)].copy()\n",
    "\n",
    "# Basic masks\n",
    "offset_abs = pd.to_numeric(df[OFFSET_COL], errors=\"coerce\").abs()\n",
    "m_off   = offset_abs < 20.0                      # |GIM offset| < 20 TECU\n",
    "m_quiet = (df[QUIET_COL] == \"Q\")                 # GFZ geomagnetic label = Q\n",
    "m_slow  = (df[SOLAR_COL].str.lower() == \"low\")   # solar_label = Low\n",
    "\n",
    "# Year column for grouping\n",
    "df[\"year\"] = df[TIME_COL].dt.year\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Global summary (Oct 2015–Sep 2025)\n",
    "# =========================\n",
    "N = len(df)\n",
    "\n",
    "summary_global = pd.DataFrame({\n",
    "    \"metric\": [\n",
    "        \"total days\",\n",
    "        \"|offset| < 20 TECU\",\n",
    "        \"geomagnetic quiet (Q)\",\n",
    "        \"solar low\",\n",
    "        \"|offset| < 20 ∩ quiet\",\n",
    "        \"|offset| < 20 ∩ solar low\",\n",
    "        \"quiet ∩ solar low\",\n",
    "        \"|offset| < 20 ∩ quiet ∩ solar low\",\n",
    "    ],\n",
    "    \"count\": [\n",
    "        N,\n",
    "        int(m_off.sum()),\n",
    "        int(m_quiet.sum()),\n",
    "        int(m_slow.sum()),\n",
    "        int((m_off & m_quiet).sum()),\n",
    "        int((m_off & m_slow).sum()),\n",
    "        int((m_quiet & m_slow).sum()),\n",
    "        int((m_off & m_quiet & m_slow).sum()),\n",
    "    ],\n",
    "})\n",
    "\n",
    "summary_global[\"pct_of_total_%\"] = (100.0 * summary_global[\"count\"] / N).round(2)\n",
    "\n",
    "print(\"=== Global summary (Oct 2015 → Sep 2025) ===\")\n",
    "print(summary_global.to_string(index=False))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Per-year summary — simple filters\n",
    "# =========================\n",
    "by_year_simple = (\n",
    "    df.assign(\n",
    "        off=m_off,\n",
    "        quiet=m_quiet,\n",
    "        solar_low=m_slow,\n",
    "    )\n",
    "    .groupby(\"year\")\n",
    "    .agg(\n",
    "        total=(\"year\", \"size\"),\n",
    "        off_sm20=(\"off\", \"sum\"),\n",
    "        quiet_Q=(\"quiet\", \"sum\"),\n",
    "        solar_low=(\"solar_low\", \"sum\"),\n",
    "    )\n",
    "    .assign(\n",
    "        pct_off=lambda d:  (100.0 * d[\"off_sm20\"]   / d[\"total\"]).round(2),\n",
    "        pct_quiet=lambda d:(100.0 * d[\"quiet_Q\"]    / d[\"total\"]).round(2),\n",
    "        pct_slow=lambda d: (100.0 * d[\"solar_low\"]  / d[\"total\"]).round(2),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n=== Per-year summary — simple filters ===\")\n",
    "print(by_year_simple.to_string())\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Per-year summary — intersections\n",
    "# =========================\n",
    "by_year_inter = (\n",
    "    df.assign(\n",
    "        inter_off_quiet = (m_off & m_quiet),\n",
    "        inter_off_slow  = (m_off & m_slow),\n",
    "        inter_quiet_slow= (m_quiet & m_slow),\n",
    "        inter_all       = (m_off & m_quiet & m_slow),\n",
    "    )\n",
    "    .groupby(\"year\")\n",
    "    .agg(\n",
    "        total=(\"year\", \"size\"),\n",
    "        off_quiet=(\"inter_off_quiet\", \"sum\"),\n",
    "        off_slow=(\"inter_off_slow\", \"sum\"),\n",
    "        quiet_slow=(\"inter_quiet_slow\", \"sum\"),\n",
    "        all_three=(\"inter_all\", \"sum\"),\n",
    "    )\n",
    "    .assign(\n",
    "        pct_off_quiet=lambda d:   (100.0 * d[\"off_quiet\"]   / d[\"total\"]).round(2),\n",
    "        pct_off_slow=lambda d:    (100.0 * d[\"off_slow\"]    / d[\"total\"]).round(2),\n",
    "        pct_quiet_slow=lambda d:  (100.0 * d[\"quiet_slow\"]  / d[\"total\"]).round(2),\n",
    "        pct_all_three=lambda d:   (100.0 * d[\"all_three\"]   / d[\"total\"]).round(2),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n=== Per-year summary — intersections ===\")\n",
    "print(by_year_inter.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee09d23-087a-42fd-97cb-9364f80b0182",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# CELL — Keep only intersection (|offset|<20, quiet, solar-low)\n",
    "#        and prepare 30-min sample + diurnal helpers\n",
    "# =====================================================\n",
    "\n",
    "# df, s30, VTEC_COL, m_off, m_quiet, m_slow must already be defined\n",
    "N = len(df)\n",
    "\n",
    "# --------- Keep only the intersection of the three filters ---------\n",
    "df_kept = df[m_off & m_quiet & m_slow].copy()\n",
    "print(f\"\\nRows kept (intersection of three filters): {len(df_kept)}/{N}\")\n",
    "\n",
    "# Normalize date_utc as a date object\n",
    "if \"date_utc\" in df_kept.columns:\n",
    "    d = pd.to_datetime(df_kept[\"date_utc\"], utc=True, errors=\"coerce\")\n",
    "else:\n",
    "    d = pd.to_datetime(df_kept[\"date\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "df_kept[\"date_utc\"] = d.dt.floor(\"D\").dt.date\n",
    "\n",
    "# Match 30-min samples for the kept days\n",
    "S = s30[s30[\"date_utc\"].isin(df_kept[\"date_utc\"])].copy().reset_index(drop=True)\n",
    "\n",
    "# --------- Helper functions for diurnal aggregation/plotting ---------\n",
    "def _set_xticks_30min(ax):\n",
    "    \"\"\"Set x-axis for 48 slots (30-min sampling) with 4-hour labels.\"\"\"\n",
    "    ax.set_xlim(0, 48)\n",
    "    ax.set_xticks(np.arange(0, 48, 8))\n",
    "    ax.set_xticklabels([f\"{h:02d}\" for h in range(0, 24, 4)], rotation=0)\n",
    "\n",
    "\n",
    "def _clean_slot(df_in: pd.DataFrame, name: str = \"slot\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure 'slot' is a regular column (not index) and remove duplicate columns.\n",
    "    Useful before grouping and reindexing by slot.\n",
    "    \"\"\"\n",
    "    out = df_in\n",
    "    if name in (out.index.names or []):\n",
    "        out = out.reset_index()\n",
    "    if out.columns.duplicated().any():\n",
    "        out = out.loc[:, ~out.columns.duplicated()]\n",
    "    return out\n",
    "\n",
    "\n",
    "def agg_diurnal(df_in: pd.DataFrame, val: str = VTEC_COL) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate a 30-min series on the 48 diurnal slots (0..47) with a clean axis.\n",
    "\n",
    "    Returns a DataFrame with:\n",
    "      slot, median, mean, q25, q75, std, N\n",
    "    \"\"\"\n",
    "    df_in = _clean_slot(df_in, \"slot\")\n",
    "    slots = pd.Index(range(48), name=\"slot\")\n",
    "\n",
    "    g = df_in.groupby(\"slot\")[val]\n",
    "\n",
    "    def _reindex_series(s: pd.Series) -> pd.Series:\n",
    "        s = s.copy()\n",
    "        s.index.name = \"slot\"\n",
    "        return s.reindex(slots)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"slot\":  slots.values,\n",
    "        \"median\": _reindex_series(g.median()),\n",
    "        \"mean\":   _reindex_series(g.mean()),\n",
    "        \"q25\":    _reindex_series(g.quantile(0.25)),\n",
    "        \"q75\":    _reindex_series(g.quantile(0.75)),\n",
    "        \"std\":    _reindex_series(g.std(ddof=1)),\n",
    "        \"N\":      _reindex_series(g.count()),\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def slot_ticks_2h(ax):\n",
    "    \"\"\"Set x-axis ticks every 2 hours (48 slots → 24 h).\"\"\"\n",
    "    ax.set_xlim(-1, 48)\n",
    "    ax.set_xticks(np.arange(0, 48, 4))\n",
    "    ax.set_xticklabels([f\"{h:02d}\" for h in range(0, 24, 2)], rotation=0)\n",
    "\n",
    "\n",
    "def nice_y(ax, vmin: float = 0.0, vmax: float = 50.0, step: float = 10.0):\n",
    "    \"\"\"Convenience function for setting a nice TEC y-axis.\"\"\"\n",
    "    ax.set_ylim(vmin, vmax)\n",
    "    ax.set_yticks(np.arange(vmin, vmax + step, step))\n",
    "\n",
    "\n",
    "row_colors = [\"green\", \"red\", \"blue\", \"orange\", \"purple\", \"brown\"]\n",
    "\n",
    "def _panel_color(idx: int) -> str:\n",
    "    \"\"\"Assign a row-based color for panel grids (2 columns).\"\"\"\n",
    "    r, _ = divmod(idx, 2)\n",
    "    return row_colors[r % len(row_colors)]\n",
    "\n",
    "\n",
    "print(f\"Quiet+low-solar days kept: {len(df_kept)} — 30-min samples: {len(S)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6a6cd-ca7e-4ee7-a95a-2cbc66247730",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 1 — COURBES DIURNES PAR ANNÉE (4×2)\n",
    "# median + IQR (q25–q75) + mean — jours quiet\n",
    "# ==========================================\n",
    "years = sorted({pd.Timestamp(d).year for d in df_kept['date_utc']})\n",
    "n = len(years)\n",
    "rows, cols = (6, 2) if n > 6 else (int(np.ceil(n/2)), 2)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 2*rows), squeeze=False, sharex='col')\n",
    "ylim=(0,50)\n",
    "for i, y in enumerate(years):\n",
    "    ax = axes[i//2, i%2]\n",
    "    color = _panel_color(i)\n",
    "    Sy = S[pd.to_datetime(S[\"date_utc\"]).dt.year == y]\n",
    "    D = agg_diurnal(Sy)\n",
    "\n",
    "    ax.plot(D[\"slot\"].values, D[\"median\"].values, '-',color=color,  lw=2.2, label='median')\n",
    "    ax.fill_between(D[\"slot\"].values, D[\"q25\"].values, D[\"q75\"].values,color=color, alpha=0.2, label='IQR (25–75)')\n",
    "    ax.plot(D[\"slot\"].values, D[\"mean\"].values,   '--',color='k', lw=1.6, label='mean')\n",
    "\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yticks([5,15,25,35,45])\n",
    "    \n",
    "    label = str(y)\n",
    "    ax.set_ylabel(label, weight='bold')\n",
    "    \n",
    "    _set_xticks_30min(ax)\n",
    "    \n",
    "    #slot_ticks_2h(ax); nice_y(ax, 0, 45, 5)\n",
    "    ax.grid(alpha=0.3) \n",
    "    #ax.set_title(str(y), weight='bold')\n",
    "    # style ticks\n",
    "    for t in ax.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    for t in ax.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    if i == 0:\n",
    "        ax.legend(loc='upper left', fontsize=8, frameon=False)\n",
    "\n",
    "# nettoyer cases vides\n",
    "for j in range(n, rows*cols):\n",
    "    axes[j//2, j%2].axis('off')\n",
    "\n",
    "plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "fig.text(0.5, 0.89, f'Annualy Diurnal Quiet time VTEC', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.5, 0.06, 'Local Time (LT)', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.06, 0.5, 'TEC [TECU]', va='center', rotation='vertical', fontsize=12, weight='bold')\n",
    "\n",
    "out = OUTDIR_FIG / \"Low_solar_activity_QUIET_YEARS_diurnal_mean_median_IQR_MS.png\"\n",
    "#plt.show()\n",
    "fig.savefig(out, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7fb114-45fd-481e-a53b-8ad2f3e39ea2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 2 — COURBES DIURNES PAR MOIS (6×2)\n",
    "# median + IQR + mean sur tous jours quiet, toutes années\n",
    "# ==========================================\n",
    "ylim=(0,50)\n",
    "fig, axes = plt.subplots(6,2, figsize=(12,12), squeeze=False, sharex='col')\n",
    "for m in range(1,13):\n",
    "    ax = axes[(m-1)//2, (m-1)%2]\n",
    "    Sm = S[pd.to_datetime(S[\"date_utc\"]).dt.month == m]\n",
    "    D = agg_diurnal(Sm)\n",
    "    color = _panel_color(m-1)\n",
    "    ax.plot(D[\"slot\"], D[\"median\"], '-',color=color, lw=2.2, label='median')\n",
    "    ax.fill_between(D[\"slot\"], D[\"q25\"], D[\"q75\"],color=color, alpha=0.2, label='IQR')\n",
    "    ax.plot(D[\"slot\"], D[\"mean\"], '--',color='k', lw=1.6, label='mean')\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yticks([5,15,25,35,45])\n",
    "    \n",
    "    label = pd.Timestamp(2000, m, 1).strftime('%B')\n",
    "    ax.set_ylabel(label, weight='bold')\n",
    "    \n",
    "    _set_xticks_30min(ax)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_ylabel(pd.Timestamp(2000,m,1).strftime('%B'), weight='bold')\n",
    "    \n",
    "    # style ticks\n",
    "    for t in ax.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    for t in ax.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "        \n",
    "axes[0,0].legend(frameon=False, fontsize=9, loc='upper left')\n",
    "\n",
    "plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "fig.text(0.5, 0.89, f'Monthly Diurnal Quiet time VTEC', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.5, 0.06, 'Local Time (LT)', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.06, 0.5, 'TEC [TECU]', va='center', rotation='vertical', fontsize=12, weight='bold')\n",
    "\n",
    "#plt.show()\n",
    "out = OUTDIR_FIG/\"Low_solar_activity_QUIET_MONTHS_diurnal_mean_median_IQR_MS.png\"\n",
    "fig.savefig(out, dpi=300, bbox_inches='tight'); plt.close(fig)\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8e580-43b3-4dee-8b90-64a57ff9129b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL A — STATS CLÉS COURBES DIURNES PAR MOIS\n",
    "# (à partir de S et agg_diurnal)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _slot_to_lt_h(slot: int) -> float:\n",
    "    \"\"\"slot (0..47) -> heure locale en décimal (0.0–23.5).\"\"\"\n",
    "    return 0.5 * float(slot)\n",
    "\n",
    "def _slot_to_lt_str(slot: int) -> str:\n",
    "    \"\"\"slot (0..47) -> 'HH:MM'.\"\"\"\n",
    "    h_float = 0.5 * float(slot)\n",
    "    h = int(h_float)\n",
    "    m = int(round((h_float - h) * 60))\n",
    "    return f\"{h:02d}:{m:02d}\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "for m in range(1, 13):\n",
    "    Sm = S[pd.to_datetime(S[\"date_utc\"]).dt.month == m].copy()\n",
    "    if Sm.empty:\n",
    "        continue\n",
    "\n",
    "    D = agg_diurnal(Sm).copy()   # doit contenir au moins: 'slot', 'median'\n",
    "    D = D.dropna(subset=[\"median\"])\n",
    "    if D.empty:\n",
    "        continue\n",
    "\n",
    "    # pic diurne du mois (max de la médiane)\n",
    "    idx_max = D[\"median\"].idxmax()\n",
    "    peak_val = float(D.loc[idx_max, \"median\"])\n",
    "    peak_slot = int(D.loc[idx_max, \"slot\"])\n",
    "    peak_lt   = _slot_to_lt_str(peak_slot)\n",
    "\n",
    "    # minimum diurne (souvent pré-dawn / nuit)\n",
    "    idx_min = D[\"median\"].idxmin()\n",
    "    min_val = float(D.loc[idx_min, \"median\"])\n",
    "    min_slot = int(D.loc[idx_min, \"slot\"])\n",
    "    min_lt   = _slot_to_lt_str(min_slot)\n",
    "\n",
    "    # contraste jour/nuit (amplitude intra-journalière)\n",
    "    day_night_range = peak_val - min_val\n",
    "\n",
    "    # pour info: médiane dans un noyau pré-dawn (00–04 LT) et après-midi (12–18 LT)\n",
    "    D[\"lt_hour\"] = D[\"slot\"].apply(_slot_to_lt_h)\n",
    "    pre_dawn = D[(D[\"lt_hour\"] >= 0.0) & (D[\"lt_hour\"] < 4.0)]\n",
    "    afternoon = D[(D[\"lt_hour\"] >= 12.0) & (D[\"lt_hour\"] < 18.0)]\n",
    "\n",
    "    pre_dawn_med = float(pre_dawn[\"median\"].mean()) if not pre_dawn.empty else np.nan\n",
    "    aft_med      = float(afternoon[\"median\"].mean()) if not afternoon.empty else np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"month\": m,\n",
    "        \"month_name\": pd.Timestamp(2000, m, 1).strftime(\"%b\"),\n",
    "        \"peak_median_TECU\": peak_val,\n",
    "        \"lt_of_peak\": peak_lt,\n",
    "        \"min_median_TECU\": min_val,\n",
    "        \"lt_of_min\": min_lt,\n",
    "        \"day_night_range_TECU\": day_night_range,\n",
    "        \"pre_dawn_median_00_04_TECU\": pre_dawn_med,\n",
    "        \"afternoon_median_12_18_TECU\": aft_med,\n",
    "    })\n",
    "\n",
    "monthly_diurnal_stats = pd.DataFrame(rows).sort_values(\"month\")\n",
    "\n",
    "print(\"=== Monthly diurnal median VTEC stats (quiet QSL–GIM20) ===\")\n",
    "print(monthly_diurnal_stats.to_string(index=False,\n",
    "      float_format=lambda x: f\"{x:6.2f}\"))\n",
    "\n",
    "# Résumés rapides pour le texte\n",
    "print(\"\\n--- Key diagnostics for text ---\")\n",
    "# mois du pic maximal\n",
    "i_max = monthly_diurnal_stats[\"peak_median_TECU\"].idxmax()\n",
    "print(\"Largest monthly diurnal median peak:\",\n",
    "      f\"{monthly_diurnal_stats.loc[i_max, 'peak_median_TECU']:.2f} TECU\",\n",
    "      f\"in {monthly_diurnal_stats.loc[i_max, 'month_name']} at\",\n",
    "      monthly_diurnal_stats.loc[i_max, \"lt_of_peak\"])\n",
    "\n",
    "# mois du plus faible pic\n",
    "i_min = monthly_diurnal_stats[\"peak_median_TECU\"].idxmin()\n",
    "print(\"Smallest monthly diurnal median peak:\",\n",
    "      f\"{monthly_diurnal_stats.loc[i_min, 'peak_median_TECU']:.2f} TECU\",\n",
    "      f\"in {monthly_diurnal_stats.loc[i_min, 'month_name']} at\",\n",
    "      monthly_diurnal_stats.loc[i_min, \"lt_of_peak\"])\n",
    "\n",
    "# plage des heures de pic\n",
    "lt_peaks = monthly_diurnal_stats[\"lt_of_peak\"].tolist()\n",
    "print(\"Monthly peak times (LT) from\",\n",
    "      lt_peaks[0], \"to\", lt_peaks[-1],\n",
    "      \"for\", \", \".join(monthly_diurnal_stats['month_name'].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71491a82-689b-43bb-ac4d-b4a453173cc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 3 — COURBES DIURNES PAR SAISON (2×2)\n",
    "# median + IQR + mean — jours quiet\n",
    "# ==========================================\n",
    "def season_of_month(m):\n",
    "    return \"DJF\" if m in (12,1,2) else (\"MAM\" if m in (3,4,5) else (\"JJA\" if m in (6,7,8) else \"SON\"))\n",
    "\n",
    "S[\"season\"] = pd.to_datetime(S[\"date_utc\"]).dt.month.map(season_of_month)\n",
    "\n",
    "order = [\"DJF\",\"MAM\",\"JJA\",\"SON\"]\n",
    "fig, axes = plt.subplots(2,2, figsize=(12,5), squeeze=False, sharex='col')\n",
    "\n",
    "for i, sname in enumerate(order):\n",
    "    color = _panel_color(i)\n",
    "    ax = axes[i//2, i%2]\n",
    "    Ss = S[S[\"season\"]==sname]\n",
    "    D = agg_diurnal(Ss)\n",
    "    \n",
    "    ax.plot(D[\"slot\"], D[\"median\"], '-', color=color, lw=2.2, label='median')\n",
    "    ax.fill_between(D[\"slot\"], D[\"q25\"], D[\"q75\"],color=color, alpha=0.2, label='IQR')\n",
    "    ax.plot(D[\"slot\"], D[\"mean\"], '--',color='k', lw=1.6, label='mean')\n",
    "    \n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yticks([5,15,25,35,45])\n",
    "    \n",
    "    label = sname\n",
    "    ax.set_ylabel(label, weight='bold')\n",
    "    \n",
    "    _set_xticks_30min(ax)\n",
    "\n",
    "    # style ticks\n",
    "    for t in ax.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    for t in ax.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "        \n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "\n",
    "axes[0,0].legend(frameon=False, fontsize=9, loc='upper left')\n",
    "\n",
    "plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "fig.text(0.5, 0.89, f'Seasonal Diurnal Quiet time VTEC', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.5, 0.03, 'Local Time (LT)', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.06, 0.5, 'TEC [TECU]', va='center', rotation='vertical', fontsize=12, weight='bold')\n",
    "\n",
    "#plt.show()\n",
    "out = OUTDIR_FIG/\"Low_solar_activity_QUIET_SEASONS_diurnal_mean_median_IQR_MS.png\"\n",
    "fig.savefig(out, dpi=300, bbox_inches='tight'); plt.close(fig)\n",
    "print(\"Saved:\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c0ca6-b042-44c9-8148-a2dd7b866b9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL B — STATS CLÉS COURBES DIURNES PAR SAISON\n",
    "# (à partir de S, season_of_month et agg_diurnal)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _slot_to_lt_h(slot: int) -> float:\n",
    "    return 0.5 * float(slot)\n",
    "\n",
    "def _slot_to_lt_str(slot: int) -> str:\n",
    "    h_float = 0.5 * float(slot)\n",
    "    h = int(h_float)\n",
    "    m = int(round((h_float - h) * 60))\n",
    "    return f\"{h:02d}:{m:02d}\"\n",
    "\n",
    "def season_of_month(m):\n",
    "    return \"DJF\" if m in (12,1,2) else (\"MAM\" if m in (3,4,5)\n",
    "           else (\"JJA\" if m in (6,7,8) else \"SON\"))\n",
    "\n",
    "S = S.copy()\n",
    "S[\"month\"] = pd.to_datetime(S[\"date_utc\"]).dt.month\n",
    "S[\"season\"] = S[\"month\"].map(season_of_month)\n",
    "\n",
    "rows = []\n",
    "order = [\"DJF\",\"MAM\",\"JJA\",\"SON\"]\n",
    "\n",
    "for sname in order:\n",
    "    Ss = S[S[\"season\"] == sname].copy()\n",
    "    if Ss.empty:\n",
    "        continue\n",
    "\n",
    "    D = agg_diurnal(Ss).copy()\n",
    "    D = D.dropna(subset=[\"median\"])\n",
    "    if D.empty:\n",
    "        continue\n",
    "\n",
    "    # pic diurne saisonnier\n",
    "    idx_max = D[\"median\"].idxmax()\n",
    "    peak_val = float(D.loc[idx_max, \"median\"])\n",
    "    peak_slot = int(D.loc[idx_max, \"slot\"])\n",
    "    peak_lt   = _slot_to_lt_str(peak_slot)\n",
    "\n",
    "    # minimum saisonnier\n",
    "    idx_min = D[\"median\"].idxmin()\n",
    "    min_val = float(D.loc[idx_min, \"median\"])\n",
    "    min_slot = int(D.loc[idx_min, \"slot\"])\n",
    "    min_lt   = _slot_to_lt_str(min_slot)\n",
    "\n",
    "    day_night_range = peak_val - min_val\n",
    "\n",
    "    D[\"lt_hour\"] = D[\"slot\"].apply(_slot_to_lt_h)\n",
    "    pre_dawn = D[(D[\"lt_hour\"] >= 0.0) & (D[\"lt_hour\"] < 4.0)]\n",
    "    afternoon = D[(D[\"lt_hour\"] >= 12.0) & (D[\"lt_hour\"] < 18.0)]\n",
    "\n",
    "    pre_dawn_med = float(pre_dawn[\"median\"].mean()) if not pre_dawn.empty else np.nan\n",
    "    aft_med      = float(afternoon[\"median\"].mean()) if not afternoon.empty else np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"season\": sname,\n",
    "        \"peak_median_TECU\": peak_val,\n",
    "        \"lt_of_peak\": peak_lt,\n",
    "        \"min_median_TECU\": min_val,\n",
    "        \"lt_of_min\": min_lt,\n",
    "        \"day_night_range_TECU\": day_night_range,\n",
    "        \"pre_dawn_median_00_04_TECU\": pre_dawn_med,\n",
    "        \"afternoon_median_12_18_TECU\": aft_med,\n",
    "    })\n",
    "\n",
    "seasonal_diurnal_stats = pd.DataFrame(rows).set_index(\"season\").loc[order].reset_index()\n",
    "\n",
    "print(\"=== Seasonal diurnal median VTEC stats (quiet QSL–GIM20) ===\")\n",
    "print(seasonal_diurnal_stats.to_string(index=False,\n",
    "      float_format=lambda x: f\"{x:6.2f}\"))\n",
    "\n",
    "print(\"\\n--- Key diagnostics for text ---\")\n",
    "for _, r in seasonal_diurnal_stats.iterrows():\n",
    "    print(f\"{r['season']}: peak median ≈ {r['peak_median_TECU']:.2f} TECU at {r['lt_of_peak']} LT; \"\n",
    "          f\"night min ≈ {r['min_median_TECU']:.2f} TECU at {r['lt_of_min']} LT; \"\n",
    "          f\"day–night range ≈ {r['day_night_range_TECU']:.2f} TECU; \"\n",
    "          f\"pre-dawn (00–04 LT) median ≈ {r['pre_dawn_median_00_04_TECU']:.2f} TECU; \"\n",
    "          f\"afternoon (12–18 LT) median ≈ {r['afternoon_median_12_18_TECU']:.2f} TECU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b48b3-4bc7-4a40-b847-acaaa4f74294",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 4 — HEURE DU MAX QUOTIDIEN (HISTOGRAMME, LT)\n",
    "# ==========================================\n",
    "# pour chaque jour quiet : slot du max (si plusieurs, dernier)\n",
    "idx = S.groupby(\"date_utc\")[VTEC_COL].idxmax()\n",
    "daily_max = S.loc[idx, [\"date_utc\",\"slot\",VTEC_COL]].sort_values(\"date_utc\")\n",
    "# convertir slot en heure locale (LT) lisible\n",
    "hours = daily_max[\"slot\"]/2.0  # 0..23.5\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.hist(hours, bins=np.arange(-0.25,24.75,0.5), edgecolor='k', alpha=0.7)\n",
    "def _set_xticks_30min(ax):\n",
    "    ax.set_xlim(-1, 24)\n",
    "    ax.set_xticks(np.arange(0, 24, 4))\n",
    "    ax.set_xticklabels([f\"{h:02d}\" for h in range(0, 24, 4)], rotation=0)\n",
    "#label = sname\n",
    "ax.set_ylabel(\"Count of days\", weight='bold')\n",
    "    \n",
    "_set_xticks_30min(ax)\n",
    "# style ticks\n",
    "for t in ax.yaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "for t in ax.xaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    \n",
    "ax.grid(alpha=0.3)\n",
    "#ax.set_xticks(np.arange(0,24,2)); ax.set_xticklabels([f\"{h:02d}:00\" for h in range(0,24,2)])\n",
    "#ax.set_xlim(-0.5, 23.5); ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_title(\"Distribution of Local-Time of the Daily VTEC Maximum on Quiet Days\", weight='bold')\n",
    "ax.set_xlabel(\"Local Time (LT)\", weight='bold');\n",
    "#plt.show()\n",
    "out = OUTDIR_FIG/\"Low_solar_activity_QUIET_hist_hour_of_daily_max_LT_MS.png\"\n",
    "fig.savefig(out, dpi=300); plt.close(fig)\n",
    "print(\"Saved:\", out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf182c6-03bc-4350-b424-719937ac878f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pytz\n",
    "\n",
    "# ============================================\n",
    "# Histogram + seasonal diagnostics of the local\n",
    "# time of the daily VTEC maximum (quiet/low-solar subset)\n",
    "# ============================================\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "LOCAL_TZ     = \"Africa/Casablanca\"\n",
    "VTEC_MAX_COL = \"VTEC_max\"      # amplitude of daily max on the 30-min grid\n",
    "TIME_COL_UTC = \"max_ts_utc\"    # timestamp of daily max in UTC (tz-aware)\n",
    "\n",
    "FIG_DIR = Path(\"figures/quiet\")\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_FIG = FIG_DIR / \"TEC09_low_solar_quiet_hist_hour_of_daily_max_LT_MS.png\"\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "def hist_fwhm(centers: np.ndarray, counts: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Simple FWHM (full width at half-maximum) approximation for a 1D histogram.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    centers : array-like\n",
    "        Bin centers (same length as `counts`).\n",
    "    counts : array-like\n",
    "        Bin heights (e.g., from np.histogram or plt.hist).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Approximate FWHM in the same units as `centers`, or NaN if undefined.\n",
    "    \"\"\"\n",
    "    counts = np.asarray(counts, float)\n",
    "    centers = np.asarray(centers, float)\n",
    "\n",
    "    if counts.size == 0:\n",
    "        return np.nan\n",
    "\n",
    "    peak = counts.max()\n",
    "    if peak <= 0:\n",
    "        return np.nan\n",
    "\n",
    "    half = peak / 2.0\n",
    "    mask = counts >= half\n",
    "    if not np.any(mask):\n",
    "        return np.nan\n",
    "\n",
    "    xs = centers[mask]\n",
    "    if xs.size == 1:\n",
    "        # Only one bin above half-maximum\n",
    "        return 0.0\n",
    "\n",
    "    return xs[-1] - xs[0]\n",
    "\n",
    "\n",
    "# ====== PREPARE DAILY DATAFRAME (df_kept MUST EXIST) ======\n",
    "# df_kept is assumed to contain the \"quiet & low-solar & |offset|<20\" subset\n",
    "df_daily = df_kept.copy()\n",
    "\n",
    "# Ensure UTC timestamp column for the daily max is tz-aware UTC\n",
    "df_daily[TIME_COL_UTC] = pd.to_datetime(df_daily[TIME_COL_UTC], utc=True, errors=\"coerce\")\n",
    "\n",
    "# Convert daily max timestamp to local time and compute local hour\n",
    "tz = pytz.timezone(LOCAL_TZ)\n",
    "df_daily[\"max_ts_lt\"] = df_daily[TIME_COL_UTC].dt.tz_convert(tz)\n",
    "df_daily[\"max_hour_lt\"] = (\n",
    "    df_daily[\"max_ts_lt\"].dt.hour\n",
    "    + df_daily[\"max_ts_lt\"].dt.minute / 60.0\n",
    ")\n",
    "\n",
    "# Month and DOY (optional)\n",
    "df_daily[\"month\"] = df_daily[\"max_ts_lt\"].dt.month\n",
    "df_daily[\"doy\"] = df_daily[\"max_ts_lt\"].dt.dayofyear\n",
    "\n",
    "# Basic NaN filtering\n",
    "df_daily = df_daily[\n",
    "    np.isfinite(df_daily[\"max_hour_lt\"]) &\n",
    "    np.isfinite(df_daily[VTEC_MAX_COL])\n",
    "].copy()\n",
    "\n",
    "if df_daily.empty:\n",
    "    print(\"df_daily is empty after filtering (no valid daily maxima).\")\n",
    "else:\n",
    "    # ====== 3-PANEL FIGURE ======\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(\n",
    "        3, 1, figsize=(10, 9),\n",
    "        gridspec_kw={\"height_ratios\": [2.0, 1.3, 1.3]}\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1) Histogram of local time of daily max VTEC (LT)\n",
    "    # --------------------------------------------------\n",
    "    h = df_daily[\"max_hour_lt\"].values\n",
    "\n",
    "    # 30-min bins from 0 to 24h\n",
    "    bins = np.arange(0.0, 24.0 + 0.5, 0.5)\n",
    "    counts, bin_edges, _ = ax1.hist(\n",
    "        h,\n",
    "        bins=bins,\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.7,\n",
    "        label=\"Daily max count\",\n",
    "    )\n",
    "    centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "    # Line connecting bin tops\n",
    "    ax1.plot(\n",
    "        centers,\n",
    "        counts,\n",
    "        \"-o\",\n",
    "        linewidth=1.5,\n",
    "        markersize=4,\n",
    "        label=\"Bin-top curve\",\n",
    "    )\n",
    "\n",
    "    # Mode, FWHM, peak amplitude\n",
    "    if counts.sum() > 0:\n",
    "        idx_peak = int(np.argmax(counts))\n",
    "        mode_hour = centers[idx_peak]\n",
    "        median_hour = df_daily[\"max_hour_lt\"].median()\n",
    "        peak_days = int(counts[idx_peak])\n",
    "        fwhm = hist_fwhm(centers, counts)\n",
    "\n",
    "        print(\n",
    "            f\"Mode ≈ {mode_hour:.2f} LT, \"\n",
    "            f\"median ≈ {median_hour:.2f} LT, \"\n",
    "            f\"FWHM ≈ {fwhm:.2f} h, \"\n",
    "            f\"peak = {peak_days} days.\"\n",
    "        )\n",
    "\n",
    "        stats_label = (\n",
    "            f\"Mode ≈ {mode_hour:4.1f} h LT, \"\n",
    "            f\"FWHM ≈ {fwhm:3.1f} h, \"\n",
    "            f\"peak = {peak_days} days\"\n",
    "        )\n",
    "        ax1.legend(title=stats_label, loc=\"upper left\", fontsize=10)\n",
    "    else:\n",
    "        ax1.legend(loc=\"upper left\", fontsize=9)\n",
    "\n",
    "    ax1.set_xlim(0, 24)\n",
    "    ax1.set_xticks(np.arange(0, 25, 2))\n",
    "    ax1.set_ylabel(\"Number of days\", fontweight=\"bold\")\n",
    "    ax1.set_xlabel(\"Local Time (LT)\", fontweight=\"bold\")\n",
    "    ax1.set_title(\n",
    "        \"Local time of daily VTEC maximum (quiet, low-solar subset)\",\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    for t in ax1.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10)\n",
    "        t.set_color(\"black\")\n",
    "        t.set_weight(\"bold\")\n",
    "    for t in ax1.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10)\n",
    "        t.set_color(\"black\")\n",
    "        t.set_weight(\"bold\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2) Daily max amplitude vs month (scatter + median)\n",
    "    # --------------------------------------------------\n",
    "    x_month = df_daily[\"month\"].values\n",
    "    y_vtec = df_daily[VTEC_MAX_COL].values\n",
    "\n",
    "    ax2.scatter(\n",
    "        x_month,\n",
    "        y_vtec,\n",
    "        color=\"k\",\n",
    "        alpha=0.4,\n",
    "        s=15,\n",
    "        label=\"Daily maxima\",\n",
    "    )\n",
    "\n",
    "    month_median_vtec = (\n",
    "        df_daily.groupby(\"month\")[VTEC_MAX_COL]\n",
    "        .median()\n",
    "        .reindex(np.arange(1, 13))\n",
    "    )\n",
    "\n",
    "    ax2.plot(\n",
    "        np.arange(1, 13),\n",
    "        month_median_vtec.values,\n",
    "        \"-o\",\n",
    "        linewidth=2,\n",
    "        label=\"Monthly median max\",\n",
    "    )\n",
    "\n",
    "    ax2.set_xlim(0.5, 12.5)\n",
    "    ax2.set_xticks(np.arange(1, 13))\n",
    "    ax2.set_xticklabels(\n",
    "        [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "         \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "    )\n",
    "    ax2.set_ylabel(\"Daily max VTEC [TECU]\", fontweight=\"bold\")\n",
    "    ax2.set_xlabel(\"Month of year\", fontweight=\"bold\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend(loc=\"upper center\", fontsize=9)\n",
    "\n",
    "    for t in ax2.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10)\n",
    "        t.set_color(\"black\")\n",
    "        t.set_weight(\"bold\")\n",
    "    for t in ax2.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10)\n",
    "        t.set_color(\"black\")\n",
    "        t.set_weight(\"bold\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3) Local time of daily max vs month (scatter + median)\n",
    "    # --------------------------------------------------\n",
    "    y_hour = df_daily[\"max_hour_lt\"].values\n",
    "\n",
    "    ax3.scatter(\n",
    "        x_month,\n",
    "        y_hour,\n",
    "        color=\"k\",\n",
    "        alpha=0.4,\n",
    "        s=15,\n",
    "        label=\"Daily peak time\",\n",
    "    )\n",
    "\n",
    "    month_median_hour = (\n",
    "        df_daily.groupby(\"month\")[\"max_hour_lt\"]\n",
    "        .median()\n",
    "        .reindex(np.arange(1, 13))\n",
    "    )\n",
    "\n",
    "    ax3.plot(\n",
    "        np.arange(1, 13),\n",
    "        month_median_hour.values,\n",
    "        \"-o\",\n",
    "        linewidth=2,\n",
    "        label=\"Monthly median time\",\n",
    "    )\n",
    "\n",
    "    ax3.set_xlim(0.5, 12.5)\n",
    "    ax3.set_xticks(np.arange(1, 13))\n",
    "    ax3.set_xticklabels(\n",
    "        [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "         \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "    )\n",
    "    ax3.set_xlabel(\"Month of year\", fontweight=\"bold\")\n",
    "    ax3.set_ylabel(\"Local time of daily max [LT]\", fontweight=\"bold\")\n",
    "    ax3.set_ylim(0, 24)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend(loc=\"lower center\", fontsize=9)\n",
    "\n",
    "    for t in ax3.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10)\n",
    "        t.set_color(\"black\")\n",
    "        t.set_weight(\"bold\")\n",
    "    for t in ax3.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10)\n",
    "        t.set_color(\"black\")\n",
    "        t.set_weight(\"bold\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(OUT_FIG, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", OUT_FIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f0de0-cabd-4ad4-a2ea-91adf5353ad4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# seasonal peak hour variability\n",
    "df_season = df_daily.copy()\n",
    "df_season[\"month\"] = df_season[\"max_ts_lt\"].dt.month\n",
    "\n",
    "def month_to_season(m):\n",
    "    if m in (12, 1, 2):\n",
    "        return \"DJF\"\n",
    "    elif m in (3, 4, 5):\n",
    "        return \"MAM\"\n",
    "    elif m in (6, 7, 8):\n",
    "        return \"JJA\"\n",
    "    else:\n",
    "        return \"SON\"\n",
    "\n",
    "df_season[\"season\"] = df_season[\"month\"].apply(month_to_season)\n",
    "\n",
    "# Median and IQR of peak time per season\n",
    "def iqr(x):\n",
    "    x = np.asarray(x, float)\n",
    "    return np.nanpercentile(x, 75) - np.nanpercentile(x, 25)\n",
    "\n",
    "season_stats = (df_season\n",
    "                .groupby(\"season\")[\"max_hour_lt\"]\n",
    "                .agg([\"count\", \"median\", iqr])\n",
    "                .reset_index())\n",
    "print(season_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2189dd-2fbe-43ac-ac65-7060910e842c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Daily peak VTEC amplitude diagnostics\n",
    "#  - Works on df_kept (quiet, low-solar, |offset|<20 subset)\n",
    "#  - Prints global and monthly statistics for VTEC maxima\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --------- CONFIG ---------\n",
    "VTEC_MAX_COL = \"VTEC_max_from_30min\"   # daily amplitude of the VTEC maximum\n",
    "TIME_COL_UTC = \"max_ts_utc\"            # UTC timestamp of the daily maximum\n",
    "# ---------------------------\n",
    "\n",
    "# df_kept is assumed to be pre-computed:\n",
    "# \"quiet & low-solar & |gim_offset_tecu| < 20\" subset\n",
    "df_daily = df_kept.copy()\n",
    "\n",
    "# Ensure proper types\n",
    "df_daily[VTEC_MAX_COL] = pd.to_numeric(df_daily[VTEC_MAX_COL], errors=\"coerce\")\n",
    "df_daily[TIME_COL_UTC] = pd.to_datetime(df_daily[TIME_COL_UTC], utc=True, errors=\"coerce\")\n",
    "\n",
    "# Derive month if not already present\n",
    "if \"month\" not in df_daily.columns:\n",
    "    df_daily[\"month\"] = df_daily[TIME_COL_UTC].dt.month\n",
    "\n",
    "# Drop NaNs on the amplitude\n",
    "df_daily = df_daily[np.isfinite(df_daily[VTEC_MAX_COL])].copy()\n",
    "\n",
    "if df_daily.empty:\n",
    "    print(\"df_daily is empty after filtering valid daily VTEC maxima.\")\n",
    "else:\n",
    "    # ----- 1) Global range of daily maxima -----\n",
    "    vtec_min = df_daily[VTEC_MAX_COL].min()\n",
    "    vtec_max = df_daily[VTEC_MAX_COL].max()\n",
    "    vtec_p05 = np.nanpercentile(df_daily[VTEC_MAX_COL], 5)\n",
    "    vtec_p95 = np.nanpercentile(df_daily[VTEC_MAX_COL], 95)\n",
    "\n",
    "    print(\"Global daily peak VTEC range (quiet, low-solar subset):\")\n",
    "    print(f\"  min       = {vtec_min:.2f} TECU\")\n",
    "    print(f\"  max       = {vtec_max:.2f} TECU\")\n",
    "    print(f\"  5th perc  = {vtec_p05:.2f} TECU  (robust lower bound)\")\n",
    "    print(f\"  95th perc = {vtec_p95:.2f} TECU  (robust upper bound)\")\n",
    "    print(\"\")\n",
    "\n",
    "    # ----- 2) Monthly medians of daily maxima -----\n",
    "    month_median = (\n",
    "        df_daily\n",
    "        .groupby(\"month\")[VTEC_MAX_COL]\n",
    "        .median()\n",
    "        .reindex(np.arange(1, 13))\n",
    "    )\n",
    "    month_count = (\n",
    "        df_daily\n",
    "        .groupby(\"month\")[VTEC_MAX_COL]\n",
    "        .count()\n",
    "        .reindex(np.arange(1, 13))\n",
    "    )\n",
    "\n",
    "    month_stats = pd.DataFrame({\n",
    "        \"month\": np.arange(1, 13),\n",
    "        \"n_days\": month_count.values,\n",
    "        \"median_VTEC_max\": month_median.values,\n",
    "    })\n",
    "\n",
    "    month_name = {\n",
    "        1: \"Jan\", 2: \"Feb\", 3: \"Mar\", 4: \"Apr\",\n",
    "        5: \"May\", 6: \"Jun\", 7: \"Jul\", 8: \"Aug\",\n",
    "        9: \"Sep\", 10: \"Oct\", 11: \"Nov\", 12: \"Dec\",\n",
    "    }\n",
    "    month_stats[\"name\"] = month_stats[\"month\"].map(month_name)\n",
    "\n",
    "    print(\"Monthly median of daily VTEC maxima (quiet, low-solar subset):\")\n",
    "    print(month_stats.to_string(index=False, float_format=lambda x: f\"{x:6.2f}\"))\n",
    "    print(\"\")\n",
    "\n",
    "    # ----- 3) Months / seasons with largest and smallest medians -----\n",
    "\n",
    "    # Month with largest median daily maximum (typically equinox/summer)\n",
    "    idx_max = month_median.idxmax()\n",
    "    vtec_equinox_summer = month_median.max()\n",
    "    print(\"Largest monthly median daily-peak VTEC:\")\n",
    "    print(f\"  month = {idx_max} ({month_name[idx_max]}), \"\n",
    "          f\"median = {vtec_equinox_summer:.2f} TECU\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Winter: DJF (Dec–Jan–Feb) → minimum median among these months\n",
    "    winter_months = [12, 1, 2]\n",
    "    winter_medians = month_median.loc[winter_months].dropna()\n",
    "\n",
    "    if not winter_medians.empty:\n",
    "        w_idx_min = winter_medians.idxmin()\n",
    "        vtec_winter = winter_medians.min()\n",
    "        print(\"Winter (DJF) monthly median daily peaks:\")\n",
    "        for m in winter_months:\n",
    "            if not np.isnan(month_median.loc[m]):\n",
    "                print(f\"  {m:2d} ({month_name[m]}): \"\n",
    "                      f\"median = {month_median.loc[m]:.2f} TECU\")\n",
    "        print(f\"Lowest winter monthly median peak VTEC:\")\n",
    "        print(f\"  month = {w_idx_min} ({month_name[w_idx_min]}), \"\n",
    "              f\"median = {vtec_winter:.2f} TECU\")\n",
    "    else:\n",
    "        print(\"No data for winter months (DJF) in monthly medians.\")\n",
    "\n",
    "    # ----- 4) Ready-to-use numbers for the text (e.g. LaTeX paragraph) -----\n",
    "    print(\"\\n--- Summary numbers for the manuscript ---\")\n",
    "    print(f\"Use VTEC_min ≈ {vtec_p05:.1f} TECU and \"\n",
    "          f\"VTEC_max ≈ {vtec_p95:.1f} TECU as a robust daily-peak range.\")\n",
    "    print(f\"Use VTEC_equinox/summer ≈ {vtec_equinox_summer:.1f} TECU \"\n",
    "          f\"in {month_name[idx_max]} (month with largest median peak).\")\n",
    "    if not winter_medians.empty:\n",
    "        print(f\"Use VTEC_winter ≈ {vtec_winter:.1f} TECU \"\n",
    "              f\"in {month_name[w_idx_min]} for the lowest winter monthly median.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7186c81-4e8a-4a3f-9542-17481b313488",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 6b — Local-time boxplots (2 h bins)\n",
    "# Quiet days (QSL–GIM20 subset)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We assume the following are already defined upstream:\n",
    "#   - S          : 30-min VTEC time series (quiet / low-solar / |offset|<20 subset)\n",
    "#   - VTEC_COL   : column name for VTEC in S\n",
    "#   - OUTDIR_FIG : base output directory for figures\n",
    "\n",
    "# ---- Build 2 h bins from 30-min slots (0..47 → 0, 2, 4, ..., 22) ----\n",
    "S_hour = S.copy()\n",
    "S_hour[\"hour2\"] = (S_hour[\"slot\"] // 4) * 2  # 4 slots of 30 min → 2 h bin\n",
    "\n",
    "hours2 = np.arange(0, 24, 2)  # 0, 2, ..., 22\n",
    "\n",
    "# Collect data for each 2 h bin\n",
    "data_h = [\n",
    "    S_hour.loc[S_hour[\"hour2\"] == h, VTEC_COL].dropna().to_numpy()\n",
    "    for h in hours2\n",
    "]\n",
    "has_data = [len(v) > 0 for v in data_h]\n",
    "\n",
    "# Mean VTEC per 2 h bin (for the overlaid black curve)\n",
    "mh = (\n",
    "    S_hour.groupby(\"hour2\", as_index=False)[VTEC_COL]\n",
    "          .mean()\n",
    "          .set_index(\"hour2\")\n",
    "          .reindex(hours2)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "# Positions of box centers: 1..N for bins that actually have data\n",
    "pos  = [i + 1 for i, ok in enumerate(has_data) if ok]\n",
    "dat  = [v for v, ok in zip(data_h, has_data) if ok]\n",
    "labs = [h for h, ok in zip(hours2, has_data) if ok]\n",
    "\n",
    "# Boxplots (2 h LT bins)\n",
    "if dat:\n",
    "    ax.boxplot(\n",
    "        dat,\n",
    "        positions=pos,\n",
    "        patch_artist=True,\n",
    "        showmeans=True,\n",
    "        whis=(5, 95),  # 5–95 % range as whiskers\n",
    "        meanprops=dict(\n",
    "            marker=\"D\",\n",
    "            markersize=4,\n",
    "            markerfacecolor=\"black\",\n",
    "            markeredgecolor=\"white\"\n",
    "        ),\n",
    "        boxprops=dict(\n",
    "            facecolor=\"#c7e9ff\",\n",
    "            edgecolor=\"#1f4d7a\",\n",
    "            linewidth=1.2\n",
    "        ),\n",
    "        medianprops=dict(\n",
    "            color=\"crimson\",\n",
    "            linewidth=1.8\n",
    "        ),\n",
    "        whiskerprops=dict(\n",
    "            color=\"#1f4d7a\",\n",
    "            linewidth=1.0,\n",
    "            linestyle=\"--\"\n",
    "        ),\n",
    "        capprops=dict(\n",
    "            color=\"#1f4d7a\",\n",
    "            linewidth=1.0\n",
    "        ),\n",
    "        flierprops=dict(\n",
    "            marker=\"x\",\n",
    "            markersize=3,\n",
    "            markeredgecolor=\"gray\",\n",
    "            markerfacecolor=\"none\",\n",
    "            alpha=0.5\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# Overlay the mean VTEC per 2 h bin (aligned with box centers)\n",
    "ax.plot(\n",
    "    np.arange(1, len(hours2) + 1),\n",
    "    mh[VTEC_COL].to_numpy(),\n",
    "    color=\"black\",\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    markersize=5,\n",
    "    label=\"Mean\"\n",
    ")\n",
    "\n",
    "# Axis ticks and style\n",
    "ax.set_xlim(0.5, len(hours2) + 0.5)\n",
    "ax.set_xticks(np.arange(1, len(hours2) + 1))\n",
    "ax.set_xticklabels([f\"{h:02d}\" for h in hours2])\n",
    "\n",
    "for tick in ax.yaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12)\n",
    "    tick.set_color(\"black\")\n",
    "    tick.set_weight(\"bold\")\n",
    "\n",
    "for tick in ax.xaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12)\n",
    "    tick.set_color(\"black\")\n",
    "    tick.set_weight(\"bold\")\n",
    "\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(frameon=False, loc=\"upper left\")\n",
    "\n",
    "# Global title and labels (consistent with seasonal/monthly boxplots)\n",
    "fig.text(\n",
    "    0.5, 0.92,\n",
    "    \"Quiet-time VTEC distribution by 2 h local-time bins (QSL–GIM20)\",\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\"\n",
    ")\n",
    "fig.text(\n",
    "    0.5, 0.01,\n",
    "    \"Local time (LT)\",\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\"\n",
    ")\n",
    "fig.text(\n",
    "    0.04, 0.5,\n",
    "    \"TEC [TECU]\",\n",
    "    va=\"center\",\n",
    "    rotation=\"vertical\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "out = OUTDIR_FIG / \"TEC08_Low_solar_activity_QUIET_boxplot_by_2h_MS.png\"\n",
    "fig.savefig(out, dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bdaa38-7eae-4d2e-bfa2-18b9d391a997",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL X — VTEC stats by 2 h local-time bins (QSL–GIM20)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "# -------- CONFIG --------\n",
    "TIME_COL       = \"time\"          # 30-min UTC timestamp column in the input dataframe\n",
    "VTEC_COL       = \"VTEC_median\"   # 30-min VTEC column\n",
    "QUIET_FLAG_COL = None            # e.g. \"quiet_QSL_GIM20\" if you have such a boolean flag; otherwise leave as None\n",
    "LOCAL_TZ       = \"Africa/Casablanca\"\n",
    "# ------------------------\n",
    "\n",
    "# Start from the 30-min climatology dataframe built earlier\n",
    "# (replace `S` by your actual 30-min dataframe if needed)\n",
    "df = S.copy()\n",
    "\n",
    "# Optionally restrict to quiet QSL–GIM20 days if a boolean flag column exists\n",
    "if QUIET_FLAG_COL is not None and QUIET_FLAG_COL in df.columns:\n",
    "    df = df[df[QUIET_FLAG_COL] == True].copy()\n",
    "\n",
    "# Parse UTC timestamps and convert to local time\n",
    "df[TIME_COL] = pd.to_datetime(df[TIME_COL], utc=True, errors=\"coerce\")\n",
    "tz = pytz.timezone(LOCAL_TZ)\n",
    "df[\"ts_lt\"] = df[TIME_COL].dt.tz_convert(tz)\n",
    "\n",
    "# Local time in hours (float)\n",
    "df[\"lt_hour\"] = df[\"ts_lt\"].dt.hour + df[\"ts_lt\"].dt.minute / 60.0\n",
    "\n",
    "# Define 2 h LT bins: 0–2, 2–4, ..., 22–24\n",
    "df[\"lt_bin_start\"] = (2 * np.floor(df[\"lt_hour\"] / 2)).astype(int)\n",
    "df.loc[df[\"lt_bin_start\"] == 24, \"lt_bin_start\"] = 22  # safety (should not really occur)\n",
    "\n",
    "# Drop obvious NaNs\n",
    "df[VTEC_COL] = pd.to_numeric(df[VTEC_COL], errors=\"coerce\")\n",
    "df = df[np.isfinite(df[VTEC_COL]) & np.isfinite(df[\"lt_bin_start\"])].copy()\n",
    "\n",
    "# Helper: interquartile range\n",
    "def iqr(x: pd.Series | np.ndarray) -> float:\n",
    "    x = np.asarray(x, float)\n",
    "    if x.size == 0:\n",
    "        return np.nan\n",
    "    return np.nanpercentile(x, 75) - np.nanpercentile(x, 25)\n",
    "\n",
    "# Aggregate by 2 h LT bin\n",
    "stats = (\n",
    "    df.groupby(\"lt_bin_start\")[VTEC_COL]\n",
    "      .agg(count=\"count\",\n",
    "           median=\"median\",\n",
    "           iqr=iqr)\n",
    "      .reset_index()\n",
    "      .sort_values(\"lt_bin_start\")\n",
    ")\n",
    "\n",
    "# Human-readable bin labels like \"00–02\", \"02–04\", ...\n",
    "def bin_label(h: int) -> str:\n",
    "    return f\"{h:02d}–{(h + 2) % 24:02d}\"\n",
    "\n",
    "stats[\"LT_bin\"] = stats[\"lt_bin_start\"].apply(bin_label)\n",
    "\n",
    "print(\"VTEC distribution by 2-hour local-time bins (QSL–GIM20 subset):\")\n",
    "print(\n",
    "    stats[[\"LT_bin\", \"count\", \"median\", \"iqr\"]]\n",
    "    .to_string(index=False, float_format=lambda x: f\"{x:6.2f}\")\n",
    ")\n",
    "\n",
    "# ---- Extract a few key bins for text / paper use ----\n",
    "def get_bin_value(h_start: int) -> tuple[float, float]:\n",
    "    row = stats.loc[stats[\"lt_bin_start\"] == h_start]\n",
    "    if row.empty:\n",
    "        return np.nan, np.nan\n",
    "    return float(row[\"median\"].iloc[0]), float(row[\"iqr\"].iloc[0])\n",
    "\n",
    "# Example bins (adapt as needed):\n",
    "med_06_08, iqr_06_08 = get_bin_value(6)   # 06–08 LT\n",
    "med_14_16, iqr_14_16 = get_bin_value(14)  # 14–16 LT\n",
    "med_00_02, iqr_00_02 = get_bin_value(0)   # 00–02 LT\n",
    "med_02_04, iqr_02_04 = get_bin_value(2)   # 02–04 LT\n",
    "\n",
    "print(\"\\n--- Key values for text ---\")\n",
    "print(f\"Median VTEC 06–08 LT  ≈ {med_06_08:.2f} TECU (IQR ≈ {iqr_06_08:.2f} TECU)\")\n",
    "print(f\"Median VTEC 14–16 LT  ≈ {med_14_16:.2f} TECU (IQR ≈ {iqr_14_16:.2f} TECU)\")\n",
    "print(f\"Median VTEC 00–02 LT  ≈ {med_00_02:.2f} TECU (IQR ≈ {iqr_00_02:.2f} TECU)\")\n",
    "print(f\"Median VTEC 02–04 LT  ≈ {med_02_04:.2f} TECU (IQR ≈ {iqr_02_04:.2f} TECU)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c3197-6d7f-4269-8346-0800796459cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL N — Combined ECDF (3 local times) + exceedance (20/30/40 TECU)\n",
    "# Requires:\n",
    "#   - S: 30-min VTEC climatology dataframe (QSL–GIM20 subset)\n",
    "#   - VTEC_COL: name of the VTEC 30-min column in S\n",
    "#   - OUTDIR_FIG: output directory (Path)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ecdf(x: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Simple empirical CDF:\n",
    "      x: 1D array of values (NaN allowed)\n",
    "    Returns:\n",
    "      x_sorted, F(x) = i/N\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    if x.size == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    x_sorted = np.sort(x)\n",
    "    y = np.arange(1, x_sorted.size + 1) / x_sorted.size\n",
    "    return x_sorted, y\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "# Slots corresponding to 09:00, 12:00, 15:00 LT (30-min grid: slot = 2*hour)\n",
    "LABELS_ECDF = {\"09:00\": 18, \"12:00\": 24, \"15:00\": 30}\n",
    "# VTEC exceedance thresholds (TECU)\n",
    "THRESHOLDS  = [20, 30, 40]\n",
    "OUT_FIG     = OUTDIR_FIG / \"Low_solar_activity_QUIET_ECDF_exceedance_MS.png\"\n",
    "# -----------------------------\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    2, 1, figsize=(8, 8),\n",
    "    gridspec_kw={\"height_ratios\": [1.1, 1.0]}\n",
    ")\n",
    "\n",
    "# ===================== TOP PANEL: ECDF ======================\n",
    "quantiles = {}\n",
    "\n",
    "for label, slot in LABELS_ECDF.items():\n",
    "    vals = S.loc[S[\"slot\"] == slot, VTEC_COL].to_numpy()\n",
    "    x, y = ecdf(vals)\n",
    "    if x.size:\n",
    "        ax1.plot(x, y, lw=3, label=label)\n",
    "\n",
    "        # Store a few quantiles for later use in the text if needed\n",
    "        p50 = np.nanpercentile(vals, 50)\n",
    "        p75 = np.nanpercentile(vals, 75)\n",
    "        p90 = np.nanpercentile(vals, 90)\n",
    "        quantiles[label] = (p50, p75, p90)\n",
    "\n",
    "# Axis styling for ECDF\n",
    "# Use a robust upper x-limit based on the 99th percentile\n",
    "x_max = max(50, float(np.nanpercentile(S[VTEC_COL], 99)))\n",
    "ax1.set_xlim(0, x_max)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.legend(frameon=True, title=\"Local time\")\n",
    "\n",
    "for t in ax1.yaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color(\"black\"); t.set_weight(\"bold\")\n",
    "for t in ax1.xaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color(\"black\"); t.set_weight(\"bold\")\n",
    "\n",
    "ax1.set_ylabel(\"CDF of VTEC\", weight=\"bold\")\n",
    "ax1.set_title(\n",
    "    \"(a) Empirical CDF of VTEC at 09:00, 12:00, and 15:00 LT\",\n",
    "    loc=\"left\", weight=\"bold\"\n",
    ")\n",
    "\n",
    "# ================= BOTTOM PANEL: EXCEEDANCE ==================\n",
    "# Group by slot (0..47) and count available samples\n",
    "g   = S.groupby(\"slot\")[VTEC_COL]\n",
    "den = g.count().rename(\"N\")  # denominator per slot\n",
    "\n",
    "def slot_ticks_2h_local(ax):\n",
    "    \"\"\"\n",
    "    Place ticks every 2 h in local time on the x-axis.\n",
    "    Assumes:\n",
    "      slot ∈ [0..47], 1 slot = 30 min, LT [h] = slot * 0.5\n",
    "    \"\"\"\n",
    "    slots_2h = np.arange(0, 48, 4)  # 4 slots = 2 h\n",
    "    labels = [f\"{int(0.5 * s):02d}:00\" for s in slots_2h]\n",
    "    ax.set_xlim(0, 47)\n",
    "    ax.set_xticks(slots_2h)\n",
    "    ax.set_xticklabels(labels)\n",
    "\n",
    "# Exceedance probability curves for each threshold\n",
    "for thr in THRESHOLDS:\n",
    "    hits = S.assign(hit=S[VTEC_COL] >= thr).groupby(\"slot\")[\"hit\"].sum()\n",
    "    p = (hits / den).reindex(np.arange(48)).values  # probability per slot\n",
    "    ax2.plot(\n",
    "        np.arange(48), p,\n",
    "        \"-o\", ms=3, lw=2,\n",
    "        label=f\"VTEC ≥ {thr} TECU\"\n",
    "    )\n",
    "\n",
    "slot_ticks_2h_local(ax2)\n",
    "ax2.set_ylim(0, 0.4)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "for t in ax2.yaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color(\"black\"); t.set_weight(\"bold\")\n",
    "for t in ax2.xaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color(\"black\"); t.set_weight(\"bold\")\n",
    "\n",
    "ax2.set_xlabel(\"Local Time (LT)\", weight=\"bold\")\n",
    "ax2.set_ylabel(\"Probability\",    weight=\"bold\")\n",
    "ax2.legend(frameon=True)\n",
    "ax2.set_title(\n",
    "    \"(b) Probability of VTEC exceeding fixed thresholds\",\n",
    "    loc=\"left\", weight=\"bold\"\n",
    ")\n",
    "\n",
    "# ===== Global layout and save =====\n",
    "fig.tight_layout(rect=[0.03, 0.03, 0.97, 0.95])\n",
    "fig.suptitle(\n",
    "    \"VTEC distributions and exceedance probabilities at Oukaimeden (QSL–GIM20 subset)\",\n",
    "    y=0.98, fontsize=12, weight=\"bold\"\n",
    ")\n",
    "\n",
    "fig.savefig(OUT_FIG, dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Saved combined figure:\", OUT_FIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc75bd-66e2-47d4-852c-3f5fa1114b32",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL N — Yearly anomalies (diurnal median – quiet-time climatology)\n",
    "# Requires:\n",
    "#   - S: 30-min VTEC dataframe (QSL–GIM20 subset) with columns [\"slot\",\"date_utc\", VTEC_COL]\n",
    "#   - df_kept: daily subset used to select years (has \"date_utc\")\n",
    "#   - agg_diurnal(): function returning diurnal statistics per slot (0..47)\n",
    "#   - slot_ticks_2h(ax): helper to put 2-hour LT ticks on x-axis (0..47 → 0–24 h)\n",
    "#   - OUTDIR_FIG: output directory (Path)\n",
    "# ==========================================\n",
    "CLIM = (\n",
    "    agg_diurnal(S)[[\"slot\", \"median\"]]\n",
    "    .rename(columns={\"median\": \"clim_median\"})\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(6, 2, figsize=(12, 8), squeeze=False)\n",
    "\n",
    "# Unique years present in df_kept\n",
    "years = sorted({pd.Timestamp(d).year for d in df_kept[\"date_utc\"]})\n",
    "\n",
    "for i, y in enumerate(years):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "\n",
    "    # Subset S for year y\n",
    "    Sy = S[pd.to_datetime(S[\"date_utc\"]).dt.year == y]\n",
    "    Dy = agg_diurnal(Sy)[[\"slot\", \"median\"]].merge(CLIM, on=\"slot\", how=\"left\")\n",
    "\n",
    "    # Anomaly = yearly diurnal median – quiet-time climatological median\n",
    "    Dy[\"anom\"] = Dy[\"median\"] - Dy[\"clim_median\"]\n",
    "\n",
    "    ax.axhline(0, color=\"k\", lw=3, ls=\"--\")\n",
    "    ax.plot(Dy[\"slot\"], Dy[\"anom\"], \"-\", lw=2)\n",
    "\n",
    "    # Style ticks\n",
    "    for t in ax.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10)\n",
    "        t.set_color(\"black\")\n",
    "        t.set_weight(\"bold\")\n",
    "    for t in ax.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10)\n",
    "        t.set_color(\"black\")\n",
    "        t.set_weight(\"bold\")\n",
    "\n",
    "    slot_ticks_2h(ax)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    ax.set_title(str(y), fontweight=\"bold\", y=0.75)\n",
    "    ax.set_ylim(-5, 50)\n",
    "    ax.set_yticks(np.arange(0, 49, 15))\n",
    "\n",
    "# Remove bottom-right (unused) panel\n",
    "fig.delaxes(axes[-1, 1])\n",
    "\n",
    "# ----- X-tick visibility logic -----\n",
    "rows, cols = axes.shape\n",
    "\n",
    "# 1) Hide all x labels by default\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        axes[r, c].tick_params(axis=\"x\", labelbottom=False)\n",
    "\n",
    "# 2) Show x labels on bottom-left panel\n",
    "axes[rows - 1, 0].tick_params(axis=\"x\", labelbottom=True)\n",
    "\n",
    "# 3) Find lowest existing panel on the right column and show x labels\n",
    "right_row = None\n",
    "for r in range(rows - 1, -1, -1):\n",
    "    if axes[r, 1] in fig.axes:  # panel not removed\n",
    "        right_row = r\n",
    "        break\n",
    "\n",
    "if right_row is not None:\n",
    "    axes[right_row, 1].tick_params(axis=\"x\", labelbottom=True)\n",
    "\n",
    "# Global layout and labels\n",
    "plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "fig.text(\n",
    "    0.5, 0.9,\n",
    "    \"VTEC anomaly of diurnal median relative to quiet-time climatology\",\n",
    "    ha=\"center\", fontsize=12, weight=\"bold\"\n",
    ")\n",
    "fig.text(\n",
    "    0.5, 0.05,\n",
    "    \"Local Time (LT)\",\n",
    "    ha=\"center\", fontsize=12, weight=\"bold\"\n",
    ")\n",
    "fig.text(\n",
    "    0.07, 0.5,\n",
    "    \"VTEC anomaly [TECU]\",\n",
    "    va=\"center\", rotation=\"vertical\",\n",
    "    fontsize=12, weight=\"bold\"\n",
    ")\n",
    "\n",
    "out = OUTDIR_FIG / \"Low_solar_activity_QUIET_yearly_anomaly_vs_climatology_MS.png\"\n",
    "fig.savefig(out, dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fd72c-bf8f-4ab2-9c19-164091264175",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================================\n",
    "# CELL N — Yearly diagnostics of diurnal anomalies\n",
    "# (diurnal median – multi-year quiet-time climatology)\n",
    "#\n",
    "# Requirements:\n",
    "#   - S: 30-min VTEC dataframe (QSL–GIM20 subset) with columns:\n",
    "#       [\"slot\", \"date_utc\", VTEC_COL, ...]\n",
    "#   - df_kept: daily subset (quiet, low solar, |offset|<20) with \"date_utc\"\n",
    "#   - agg_diurnal(S): returns diurnal statistics per slot (0..47),\n",
    "#       including a \"median\" column\n",
    "# ==========================================\n",
    "\n",
    "# Multi-year quiet-time diurnal climatology (median vs slot)\n",
    "CLIM = (\n",
    "    agg_diurnal(S)[[\"slot\", \"median\"]]\n",
    "    .rename(columns={\"median\": \"clim_median\"})\n",
    ")\n",
    "\n",
    "# List of years present in df_kept\n",
    "years = sorted({pd.Timestamp(d).year for d in df_kept[\"date_utc\"]})\n",
    "\n",
    "\n",
    "def slot_to_lt(slot: int) -> str:\n",
    "    \"\"\"\n",
    "    Convert a 30-min slot index (0..47) to local time \"HH:MM\",\n",
    "    assuming slot * 0.5 h since midnight.\n",
    "    \"\"\"\n",
    "    h_float = 0.5 * slot\n",
    "    h = int(h_float)\n",
    "    m = int(round((h_float - h) * 60))\n",
    "    return f\"{h:02d}:{m:02d}\"\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for y in years:\n",
    "    # Subset S for year y\n",
    "    Sy = S[pd.to_datetime(S[\"date_utc\"]).dt.year == y].copy()\n",
    "    if Sy.empty:\n",
    "        continue\n",
    "\n",
    "    # Yearly diurnal median and anomaly vs climatology\n",
    "    Dy = (\n",
    "        agg_diurnal(Sy)[[\"slot\", \"median\"]]\n",
    "        .merge(CLIM, on=\"slot\", how=\"left\")\n",
    "    )\n",
    "    Dy[\"anom\"] = Dy[\"median\"] - Dy[\"clim_median\"]\n",
    "\n",
    "    # 1) Maximum anomaly and its local time\n",
    "    max_anom = float(Dy[\"anom\"].max())\n",
    "    idx_max = Dy[\"anom\"].idxmax()\n",
    "    slot_max = int(Dy.loc[idx_max, \"slot\"])\n",
    "    lt_max = slot_to_lt(slot_max)\n",
    "\n",
    "    # 2) Minimum anomaly and its local time\n",
    "    min_anom = float(Dy[\"anom\"].min())\n",
    "    idx_min = Dy[\"anom\"].idxmin()\n",
    "    slot_min = int(Dy.loc[idx_min, \"slot\"])\n",
    "    lt_min = slot_to_lt(slot_min)\n",
    "\n",
    "    # 3) Mean anomaly over the full diurnal cycle (48 slots)\n",
    "    mean_anom_all = float(Dy[\"anom\"].mean())\n",
    "\n",
    "    # 4) Mean anomaly over the afternoon window (e.g. 12–18 LT → slots 24..36)\n",
    "    aft = Dy[(Dy[\"slot\"] >= 24) & (Dy[\"slot\"] <= 36)]\n",
    "    mean_anom_aft = float(aft[\"anom\"].mean()) if not aft.empty else np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"year\": y,\n",
    "        \"max_anom_TECU\": max_anom,\n",
    "        \"lt_of_max\": lt_max,\n",
    "        \"min_anom_TECU\": min_anom,\n",
    "        \"lt_of_min\": lt_min,\n",
    "        \"mean_anom_all_TECU\": mean_anom_all,\n",
    "        \"mean_anom_12_18LT_TECU\": mean_anom_aft,\n",
    "    })\n",
    "\n",
    "anom_stats = pd.DataFrame(rows).sort_values(\"year\")\n",
    "\n",
    "# Nicely formatted output for the paper\n",
    "print(\"Yearly diurnal VTEC anomalies relative to quiet-time climatology:\")\n",
    "print(\n",
    "    anom_stats.to_string(\n",
    "        index=False,\n",
    "        float_format=lambda x: f\"{x:6.2f}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compact summary for LaTeX text\n",
    "print(\"\\n--- Summary for LaTeX paragraph ---\")\n",
    "\n",
    "y_max_global = anom_stats.loc[anom_stats[\"max_anom_TECU\"].idxmax(), \"year\"]\n",
    "max_global = anom_stats[\"max_anom_TECU\"].max()\n",
    "lt_max_global = anom_stats.loc[anom_stats[\"max_anom_TECU\"].idxmax(), \"lt_of_max\"]\n",
    "print(\n",
    "    f\"Largest positive anomaly: {max_global:.2f} TECU in {y_max_global} \"\n",
    "    f\"(at local time {lt_max_global}).\"\n",
    ")\n",
    "\n",
    "y_min_global = anom_stats.loc[anom_stats[\"min_anom_TECU\"].idxmin(), \"year\"]\n",
    "min_global = anom_stats[\"min_anom_TECU\"].min()\n",
    "lt_min_global = anom_stats.loc[anom_stats[\"min_anom_TECU\"].idxmin(), \"lt_of_min\"]\n",
    "print(\n",
    "    f\"Largest negative anomaly: {min_global:.2f} TECU in {y_min_global} \"\n",
    "    f\"(at local time {lt_min_global}).\"\n",
    ")\n",
    "\n",
    "print(\"\\nAfternoon (12–18 LT) mean anomalies by year:\")\n",
    "for _, r in anom_stats.iterrows():\n",
    "    print(\n",
    "        f\"  {int(r['year'])}: mean anomaly 12–18 LT \"\n",
    "        f\"≈ {r['mean_anom_12_18LT_TECU']:.2f} TECU\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653fe199-83b6-4725-83b6-750e424a8cae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 10 — Monthly & seasonal boxplots + mean (quiet days)\n",
    "# ==========================================\n",
    "import calendar\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------- PARAMS ---------\n",
    "TIME_COL  = \"date_utc\"\n",
    "VTEC_COL  = \"VTEC_median\"\n",
    "LABEL_COL = \"geomag_label_gfz_QDNQ\"   # 'Q', 'D', 'NQ'\n",
    "START     = pd.Timestamp(\"2015-10-01\", tz=\"UTC\")\n",
    "END       = pd.Timestamp(\"2025-09-26\", tz=\"UTC\")\n",
    "# --------------------------\n",
    "\n",
    "# Work on a copy of the daily dataframe `df`\n",
    "daily_q = df.copy()\n",
    "\n",
    "# Ensure time column is proper UTC datetime and apply time window\n",
    "daily_q[TIME_COL] = pd.to_datetime(daily_q[TIME_COL], utc=True, errors=\"coerce\")\n",
    "daily_q = daily_q[(daily_q[TIME_COL] >= START) & (daily_q[TIME_COL] <= END)].copy()\n",
    "\n",
    "# If you want to enforce QSL–GIM20 here, uncomment:\n",
    "# daily_q = daily_q[daily_q[LABEL_COL] == \"Q\"].copy()\n",
    "# daily_q = daily_q[pd.to_numeric(daily_q[\"gim_offset_tecu\"], errors=\"coerce\").abs() <= 20].copy()\n",
    "\n",
    "# Derive month index\n",
    "daily_q[\"month\"] = daily_q[TIME_COL].dt.month\n",
    "\n",
    "# -------- MONTHLY (all years combined) --------\n",
    "month_labels = [calendar.month_abbr[m] for m in range(1, 13)]\n",
    "all_months = np.arange(1, 13)\n",
    "\n",
    "# Gather per-month VTEC samples\n",
    "data_bp = [\n",
    "    daily_q.loc[daily_q[\"month\"] == m, VTEC_COL].dropna().to_numpy()\n",
    "    for m in all_months\n",
    "]\n",
    "has_data = [len(v) > 0 for v in data_bp]\n",
    "\n",
    "# Monthly mean for the black curve\n",
    "mm = (\n",
    "    daily_q.groupby(\"month\", as_index=False)[VTEC_COL]\n",
    "    .mean()\n",
    "    .set_index(\"month\")\n",
    "    .reindex(all_months)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "pos = [m for m, ok in zip(all_months, has_data) if ok]\n",
    "dat = [v for v, ok in zip(data_bp, has_data) if ok]\n",
    "\n",
    "if dat:\n",
    "    ax.boxplot(\n",
    "        dat,\n",
    "        positions=pos,\n",
    "        patch_artist=True,\n",
    "        showmeans=True,\n",
    "        whis=(5, 95),\n",
    "        meanprops=dict(\n",
    "            marker=\"D\",\n",
    "            markersize=4,\n",
    "            markerfacecolor=\"black\",\n",
    "            markeredgecolor=\"white\",\n",
    "        ),\n",
    "        boxprops=dict(\n",
    "            facecolor=\"#c7e9ff\",\n",
    "            edgecolor=\"#1f4d7a\",\n",
    "            linewidth=1.2,\n",
    "        ),\n",
    "        medianprops=dict(color=\"crimson\", linewidth=1.8),\n",
    "        whiskerprops=dict(\n",
    "            color=\"#1f4d7a\",\n",
    "            linewidth=1.0,\n",
    "            linestyle=\"--\",\n",
    "        ),\n",
    "        capprops=dict(color=\"#1f4d7a\", linewidth=1.0),\n",
    "        flierprops=dict(\n",
    "            marker=\"x\",\n",
    "            markersize=3,\n",
    "            markeredgecolor=\"gray\",\n",
    "            markerfacecolor=\"none\",\n",
    "            alpha=0.5,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# Monthly mean curve on top of the boxes\n",
    "ax.plot(\n",
    "    all_months,\n",
    "    mm[VTEC_COL].to_numpy(),\n",
    "    color=\"black\",\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    markersize=5,\n",
    "    label=\"Mean\",\n",
    ")\n",
    "\n",
    "# Styling\n",
    "for tick in ax.yaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12)\n",
    "    tick.set_color(\"black\")\n",
    "    tick.set_weight(\"bold\")\n",
    "for tick in ax.xaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12)\n",
    "    tick.set_color(\"black\")\n",
    "    tick.set_weight(\"bold\")\n",
    "\n",
    "ax.set_xlim(0.5, 12.5)\n",
    "ax.set_xticks(all_months)\n",
    "ax.set_xticklabels(month_labels)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(frameon=False, loc=\"upper left\")\n",
    "\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.92,\n",
    "    \"Quiet days monthly median and mean from Oct 2015 to Sep 2025\",\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.00,\n",
    "    \"Month\",\n",
    "    ha=\"center\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "fig.text(\n",
    "    0.04,\n",
    "    0.5,\n",
    "    \"TEC [TECU]\",\n",
    "    va=\"center\",\n",
    "    rotation=\"vertical\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "out = OUTDIR_FIG / \"Low_solar_activity_QUIET_monthly_median_boxplot_means_curve_by_LT_MS.png\"\n",
    "fig.savefig(out, dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out)\n",
    "\n",
    "# -------- SEASONAL (all years combined) --------\n",
    "def month_to_season(m: int) -> str:\n",
    "    if m in (12, 1, 2):\n",
    "        return \"DJF\"\n",
    "    if m in (3, 4, 5):\n",
    "        return \"MAM\"\n",
    "    if m in (6, 7, 8):\n",
    "        return \"JJA\"\n",
    "    return \"SON\"\n",
    "\n",
    "daily_q[\"season\"] = daily_q[\"month\"].map(month_to_season)\n",
    "\n",
    "season_order = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "\n",
    "data_s = [\n",
    "    daily_q.loc[daily_q[\"season\"] == s, VTEC_COL].dropna().to_numpy()\n",
    "    for s in season_order\n",
    "]\n",
    "has_s = [len(v) > 0 for v in data_s]\n",
    "\n",
    "# Seasonal mean for the black curve\n",
    "ms = (\n",
    "    daily_q.groupby(\"season\", as_index=False)[VTEC_COL]\n",
    "    .mean()\n",
    "    .set_index(\"season\")\n",
    "    .reindex(season_order)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "\n",
    "pos = [i + 1 for i, ok in enumerate(has_s) if ok]\n",
    "dat = [v for v, ok in zip(data_s, has_s) if ok]\n",
    "\n",
    "if dat:\n",
    "    ax.boxplot(\n",
    "        dat,\n",
    "        positions=pos,\n",
    "        patch_artist=True,\n",
    "        showmeans=True,\n",
    "        whis=(5, 95),\n",
    "        meanprops=dict(\n",
    "            marker=\"D\",\n",
    "            markersize=4,\n",
    "            markerfacecolor=\"black\",\n",
    "            markeredgecolor=\"white\",\n",
    "        ),\n",
    "        boxprops=dict(\n",
    "            facecolor=\"#c7e9ff\",\n",
    "            edgecolor=\"#1f4d7a\",\n",
    "            linewidth=1.2,\n",
    "        ),\n",
    "        medianprops=dict(color=\"crimson\", linewidth=1.8),\n",
    "        whiskerprops=dict(\n",
    "            color=\"#1f4d7a\",\n",
    "            linewidth=1.0,\n",
    "            linestyle=\"--\",\n",
    "        ),\n",
    "        capprops=dict(color=\"#1f4d7a\", linewidth=1.0),\n",
    "        flierprops=dict(\n",
    "            marker=\"x\",\n",
    "            markersize=3,\n",
    "            markeredgecolor=\"gray\",\n",
    "            markerfacecolor=\"none\",\n",
    "            alpha=0.5,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# Seasonal mean curve\n",
    "ax.plot(\n",
    "    np.arange(1, 5),\n",
    "    ms[VTEC_COL].to_numpy(),\n",
    "    color=\"black\",\n",
    "    marker=\"o\",\n",
    "    linewidth=3,\n",
    "    markersize=5,\n",
    "    label=\"Mean\",\n",
    ")\n",
    "\n",
    "# Styling\n",
    "for tick in ax.yaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12)\n",
    "    tick.set_color(\"black\")\n",
    "    tick.set_weight(\"bold\")\n",
    "for tick in ax.xaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12)\n",
    "    tick.set_color(\"black\")\n",
    "    tick.set_weight(\"bold\")\n",
    "\n",
    "ax.set_xlim(0.5, 4.5)\n",
    "ax.set_xticks(np.arange(1, 5))\n",
    "ax.set_xticklabels(season_order)\n",
    "ax.legend(frameon=False, loc=\"upper left\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.92,\n",
    "    \"Quiet days seasonal median and mean from Oct 2015 to Sep 2025\",\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.001,\n",
    "    \"Season\",\n",
    "    ha=\"center\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "fig.text(\n",
    "    0.04,\n",
    "    0.5,\n",
    "    \"TEC [TECU]\",\n",
    "    va=\"center\",\n",
    "    rotation=\"vertical\",\n",
    "    fontsize=15,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "out = OUTDIR_FIG / \"Low_solar_activity_QUIET_seasonal_median_boxplot_means_curve_by_LT_MS.png\"\n",
    "fig.savefig(out, dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd06d5-aebf-421e-aa6a-b8590c9e4b9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 10b — Numeric stats for monthly & seasonal boxplots (quiet days)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import calendar\n",
    "\n",
    "VTEC_COL = \"VTEC_median\"  # consistent with the previous cell\n",
    "\n",
    "# Start from the same daily dataframe used in CELL 10 (quiet subset)\n",
    "daily_stats = daily_q.copy()\n",
    "\n",
    "# Ensure we have a proper datetime column\n",
    "if \"date_utc\" in daily_stats.columns:\n",
    "    daily_stats[\"date_utc\"] = pd.to_datetime(daily_stats[\"date_utc\"], utc=True, errors=\"coerce\")\n",
    "elif \"date\" in daily_stats.columns:\n",
    "    daily_stats[\"date_utc\"] = pd.to_datetime(daily_stats[\"date\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# Ensure month and season exist\n",
    "if \"month\" not in daily_stats.columns:\n",
    "    daily_stats[\"month\"] = daily_stats[\"date_utc\"].dt.month\n",
    "\n",
    "def month_to_season(m: int) -> str:\n",
    "    if m in (12, 1, 2):\n",
    "        return \"DJF\"\n",
    "    if m in (3, 4, 5):\n",
    "        return \"MAM\"\n",
    "    if m in (6, 7, 8):\n",
    "        return \"JJA\"\n",
    "    return \"SON\"\n",
    "\n",
    "if \"season\" not in daily_stats.columns:\n",
    "    daily_stats[\"season\"] = daily_stats[\"month\"].map(month_to_season)\n",
    "\n",
    "# ---------- 1) MONTHLY STATS ----------\n",
    "def iqr(x):\n",
    "    x = np.asarray(x, float)\n",
    "    return np.nanpercentile(x, 75) - np.nanpercentile(x, 25)\n",
    "\n",
    "monthly_stats = (\n",
    "    daily_stats.groupby(\"month\")[VTEC_COL]\n",
    "    .agg(\n",
    "        n_days=\"count\",\n",
    "        median=\"median\",\n",
    "        mean=\"mean\",\n",
    "        iqr=iqr,\n",
    "        p5=lambda x: np.nanpercentile(x, 5),\n",
    "        p95=lambda x: np.nanpercentile(x, 95),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "monthly_stats[\"month_name\"] = monthly_stats[\"month\"].apply(lambda m: calendar.month_abbr[m])\n",
    "\n",
    "print(\"\\n=== Monthly stats of daily median VTEC (quiet QSL–GIM20) ===\")\n",
    "print(monthly_stats.to_string(index=False, float_format=lambda v: f\"{v:5.2f}\"))\n",
    "\n",
    "# Month with maximum / minimum median\n",
    "idx_max_m = monthly_stats[\"median\"].idxmax()\n",
    "idx_min_m = monthly_stats[\"median\"].idxmin()\n",
    "\n",
    "m_max_row = monthly_stats.loc[idx_max_m]\n",
    "m_min_row = monthly_stats.loc[idx_min_m]\n",
    "\n",
    "print(\"\\n--- Key monthly values for LaTeX paragraph ---\")\n",
    "print(\n",
    "    f\"Highest monthly median VTEC: {m_max_row['median']:.2f} TECU in {m_max_row['month_name']} \"\n",
    "    f\"(mean ≈ {m_max_row['mean']:.2f} TECU, IQR ≈ {m_max_row['iqr']:.2f} TECU).\"\n",
    ")\n",
    "print(\n",
    "    f\"Lowest monthly median VTEC:  {m_min_row['median']:.2f} TECU in {m_min_row['month_name']} \"\n",
    "    f\"(mean ≈ {m_min_row['mean']:.2f} TECU, IQR ≈ {m_min_row['iqr']:.2f} TECU).\"\n",
    ")\n",
    "\n",
    "# Months with largest / smallest IQR\n",
    "idx_max_iqr_m = monthly_stats[\"iqr\"].idxmax()\n",
    "idx_min_iqr_m = monthly_stats[\"iqr\"].idxmin()\n",
    "iqr_max_row = monthly_stats.loc[idx_max_iqr_m]\n",
    "iqr_min_row = monthly_stats.loc[idx_min_iqr_m]\n",
    "\n",
    "print(\n",
    "    f\"Largest monthly spread (IQR): {iqr_max_row['iqr']:.2f} TECU in {iqr_max_row['month_name']}.\"\n",
    ")\n",
    "print(\n",
    "    f\"Smallest monthly spread (IQR): {iqr_min_row['iqr']:.2f} TECU in {iqr_min_row['month_name']}.\"\n",
    ")\n",
    "\n",
    "# Simple skewness proxy (mean–median) to identify tails\n",
    "monthly_stats[\"skew_proxy\"] = monthly_stats[\"mean\"] - monthly_stats[\"median\"]\n",
    "idx_max_skew = monthly_stats[\"skew_proxy\"].idxmax()\n",
    "idx_min_skew = monthly_stats[\"skew_proxy\"].idxmin()\n",
    "\n",
    "skew_max_row = monthly_stats.loc[idx_max_skew]\n",
    "skew_min_row = monthly_stats.loc[idx_min_skew]\n",
    "\n",
    "print(\n",
    "    \"Largest positive mean–median difference (right tail): \"\n",
    "    f\"{skew_max_row['skew_proxy']:.2f} TECU in {skew_max_row['month_name']}.\"\n",
    ")\n",
    "print(\n",
    "    \"Largest negative mean–median difference (left tail): \"\n",
    "    f\"{skew_min_row['skew_proxy']:.2f} TECU in {skew_min_row['month_name']}.\"\n",
    ")\n",
    "\n",
    "# ---------- 2) SEASONAL STATS ----------\n",
    "seasonal_stats = (\n",
    "    daily_stats.groupby(\"season\")[VTEC_COL]\n",
    "    .agg(\n",
    "        n_days=\"count\",\n",
    "        median=\"median\",\n",
    "        mean=\"mean\",\n",
    "        iqr=iqr,\n",
    "        p5=lambda x: np.nanpercentile(x, 5),\n",
    "        p95=lambda x: np.nanpercentile(x, 95),\n",
    "    )\n",
    "    .reindex([\"DJF\", \"MAM\", \"JJA\", \"SON\"])  # canonical order\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\n=== Seasonal stats of daily median VTEC (quiet QSL–GIM20) ===\")\n",
    "print(seasonal_stats.to_string(index=False, float_format=lambda v: f\"{v:5.2f}\"))\n",
    "\n",
    "idx_max_s = seasonal_stats[\"median\"].idxmax()\n",
    "idx_min_s = seasonal_stats[\"median\"].idxmin()\n",
    "s_max_row = seasonal_stats.loc[idx_max_s]\n",
    "s_min_row = seasonal_stats.loc[idx_min_s]\n",
    "\n",
    "print(\"\\n--- Key seasonal values for LaTeX paragraph ---\")\n",
    "print(\n",
    "    f\"Highest seasonal median VTEC: {s_max_row['median']:.2f} TECU in {s_max_row['season']} \"\n",
    "    f\"(mean ≈ {s_max_row['mean']:.2f} TECU, IQR ≈ {s_max_row['iqr']:.2f} TECU).\"\n",
    ")\n",
    "print(\n",
    "    f\"Lowest seasonal median VTEC:  {s_min_row['median']:.2f} TECU in {s_min_row['season']} \"\n",
    "    f\"(mean ≈ {s_min_row['mean']:.2f} TECU, IQR ≈ {s_min_row['iqr']:.2f} TECU).\"\n",
    ")\n",
    "\n",
    "# Skewness proxy by season\n",
    "seasonal_stats[\"skew_proxy\"] = seasonal_stats[\"mean\"] - seasonal_stats[\"median\"]\n",
    "idx_max_skew_s = seasonal_stats[\"skew_proxy\"].idxmax()\n",
    "idx_min_skew_s = seasonal_stats[\"skew_proxy\"].idxmin()\n",
    "\n",
    "sskew_max_row = seasonal_stats.loc[idx_max_skew_s]\n",
    "sskew_min_row = seasonal_stats.loc[idx_min_skew_s]\n",
    "\n",
    "print(\n",
    "    f\"Largest seasonal mean–median difference: {sskew_max_row['skew_proxy']:.2f} TECU in {sskew_max_row['season']}.\"\n",
    ")\n",
    "print(\n",
    "    f\"Smallest seasonal mean–median difference: {sskew_min_row['skew_proxy']:.2f} TECU in {sskew_min_row['season']}.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10197fa7-dd82-4f63-9ce7-d0fb6b61a486",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Robust extraction of the northern EIA crest latitude around OUCA\n",
    "using the custom read_ionex() reader.\n",
    "\"\"\"\n",
    "\n",
    "# ================== CELL 0 — IMPORTS & CONFIG ==================\n",
    "import io\n",
    "import subprocess\n",
    "from datetime import date, datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "# ---- Paths ----\n",
    "DEC_DIR = Path(\"\\data\\IONEX\\IONEX_decompressed\")  # single directory containing all decompressed IONEX files\n",
    "OUT_DAILY = Path(\"\\output_csv\\daily_eia_crest_latitude.csv\")\n",
    "OUT_FIG = Path(\"\\output_figs\\daily_eia_crest_latitude.png\")\n",
    "\n",
    "# ---- OUCA and search geometry ----\n",
    "OUCA_LAT, OUCA_LON = 31.206, -7.866\n",
    "LON_BAND_DEG = 5.0                      # average VTEC in [lon - 5°, lon + 5°]\n",
    "SEARCH_LAT_MIN, SEARCH_LAT_MAX = 0.0, 50.0  # crest search window (North)\n",
    "\n",
    "# ---- Local-time filtering ----\n",
    "ONLY_AFTERNOON_LT = False      # set True to restrict to LT_HOURS_WINDOW\n",
    "LT_TZ = pytz.timezone(\"Africa/Casablanca\")\n",
    "LT_HOURS_WINDOW = (4, 20)      # local-time window if ONLY_AFTERNOON_LT is True\n",
    "\n",
    "# ---- Date range ----\n",
    "START = date(2015, 10, 1)\n",
    "END = date(2025, 9, 26)\n",
    "\n",
    "# ==============================================================\n",
    "# CELL 1 — IONEX UTILITIES (unchanged logic)\n",
    "# ==============================================================\n",
    "\n",
    "def _open_text(p: Path) -> io.StringIO:\n",
    "    \"\"\"\n",
    "    Open an IONEX file (plain, .gz, or .Z) and return a text stream.\n",
    "    \"\"\"\n",
    "    p = Path(p)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(p)\n",
    "\n",
    "    ext = p.suffix.lower()\n",
    "    if ext == \".gz\":\n",
    "        out = subprocess.run([\"gzip\", \"-dc\", str(p)], capture_output=True)\n",
    "        if out.returncode != 0:\n",
    "            raise RuntimeError(\"gzip -dc failed\")\n",
    "        return io.StringIO(out.stdout.decode(\"ascii\", \"ignore\"))\n",
    "\n",
    "    if ext == \".z\":\n",
    "        # try gzip -dc first\n",
    "        gz = subprocess.run([\"gzip\", \"-dc\", str(p)], capture_output=True)\n",
    "        if gz.returncode == 0 and gz.stdout:\n",
    "            return io.StringIO(gz.stdout.decode(\"ascii\", \"ignore\"))\n",
    "        # fallback: 7z\n",
    "        sz = subprocess.run([\"7z\", \"e\", \"-so\", str(p)], capture_output=True)\n",
    "        if sz.returncode != 0:\n",
    "            raise RuntimeError(\"7z -so failed\")\n",
    "        return io.StringIO(sz.stdout.decode(\"ascii\", \"ignore\"))\n",
    "\n",
    "    # plain text\n",
    "    return io.StringIO(p.read_text(encoding=\"ascii\", errors=\"ignore\"))\n",
    "\n",
    "\n",
    "def ionex_first_epoch_date(path: Path) -> date | None:\n",
    "    \"\"\"\n",
    "    Return the date of the first IONEX epoch (EPOCH OF FIRST MAP) in the file,\n",
    "    or None if it cannot be read.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = _open_text(path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    for _ in range(400):\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        if \"EPOCH OF FIRST MAP\" in line:\n",
    "            yr, mo, dy, hh, mm, ss = map(int, line[:60].split()[:6])\n",
    "            return datetime(yr, mo, dy, hh, mm, ss, tzinfo=timezone.utc).date()\n",
    "        if \"END OF HEADER\" in line:\n",
    "            break\n",
    "    return None\n",
    "\n",
    "\n",
    "def read_ionex(path: Path):\n",
    "    \"\"\"\n",
    "    Read a single IONEX file and return:\n",
    "        times (UTC, tz-aware), latitudes, longitudes, TEC[time, lat, lon]\n",
    "    TEC values are in TECU (scaling by 10^EXPONENT).\n",
    "    \"\"\"\n",
    "    f = _open_text(path)\n",
    "\n",
    "    exp = -1\n",
    "    lat1 = lat2 = dlat = None\n",
    "    lon1 = lon2 = dlon = None\n",
    "\n",
    "    # ---- header ----\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            raise ValueError(\"Incomplete IONEX header\")\n",
    "\n",
    "        if \"EXPONENT\" in line:\n",
    "            s = line[:8].strip()\n",
    "            exp = int(s) if s else -1\n",
    "\n",
    "        if \"LAT1 / LAT2 / DLAT\" in line:\n",
    "            lat1, lat2, dlat = map(float, line[:60].split()[:3])\n",
    "\n",
    "        if \"LON1 / LON2 / DLON\" in line:\n",
    "            lon1, lon2, dlon = map(float, line[:60].split()[:3])\n",
    "\n",
    "        if \"END OF HEADER\" in line:\n",
    "            break\n",
    "\n",
    "    if None in (lat1, lat2, dlat, lon1, lon2, dlon):\n",
    "        raise ValueError(\"Grid definition missing in IONEX header\")\n",
    "\n",
    "    nlat = int(round((lat2 - lat1) / dlat)) + 1\n",
    "    nlon = int(round((lon2 - lon1) / dlon)) + 1\n",
    "    lats = np.linspace(lat1, lat2, nlat)\n",
    "    lons = np.linspace(lon1, lon2, nlon)\n",
    "\n",
    "    times = []\n",
    "    maps = []\n",
    "\n",
    "    # ---- TEC maps ----\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        if \"START OF TEC MAP\" in line:\n",
    "            # epoch line\n",
    "            line = f.readline()\n",
    "            while line and \"EPOCH OF CURRENT MAP\" not in line:\n",
    "                line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "\n",
    "            yr, mo, dy, hh, mm, ss = map(int, line[:60].split()[:6])\n",
    "            t = pd.Timestamp(datetime(yr, mo, dy, hh, mm, ss, tzinfo=timezone.utc))\n",
    "\n",
    "            tec = np.full((nlat, nlon), np.nan)\n",
    "            bad = False\n",
    "\n",
    "            for ilat in range(nlat):\n",
    "                hdr = f.readline()\n",
    "                if not hdr or \"LAT/LON1/LON2/DLON/H\" not in hdr:\n",
    "                    bad = True\n",
    "                    break\n",
    "\n",
    "                vals = []\n",
    "                while len(vals) < nlon:\n",
    "                    data = f.readline()\n",
    "                    if (\n",
    "                        not data\n",
    "                        or (\"START OF\" in data)\n",
    "                        or (\"END OF\" in data)\n",
    "                        or (\"LAT/LON1\" in data)\n",
    "                    ):\n",
    "                        bad = True\n",
    "                        break\n",
    "\n",
    "                    chunks = [data[i : i + 5] for i in range(0, len(data.rstrip()), 5)]\n",
    "                    for c in chunks:\n",
    "                        c = c.strip().upper()\n",
    "                        if c == \"\" or c == \"9999\":\n",
    "                            vals.append(np.nan)\n",
    "                        else:\n",
    "                            try:\n",
    "                                vals.append(float(c) * (10.0 ** exp))\n",
    "                            except Exception:\n",
    "                                vals.append(np.nan)\n",
    "                        if len(vals) == nlon:\n",
    "                            break\n",
    "\n",
    "                if bad:\n",
    "                    break\n",
    "\n",
    "                if len(vals) < nlon:\n",
    "                    vals += [np.nan] * (nlon - len(vals))\n",
    "                tec[ilat, :] = vals\n",
    "\n",
    "            if bad:\n",
    "                # skip until the end of this TEC MAP\n",
    "                x = hdr\n",
    "                while x:\n",
    "                    if \"END OF TEC MAP\" in x:\n",
    "                        break\n",
    "                    x = f.readline()\n",
    "                continue\n",
    "\n",
    "            times.append(t)\n",
    "            maps.append(tec)\n",
    "\n",
    "    if not maps:\n",
    "        raise ValueError(\"No TEC map found in file\")\n",
    "\n",
    "    TEC = np.stack(maps, axis=0)\n",
    "\n",
    "    # normalize longitude to [-180, 180)\n",
    "    if lons.min() >= 0 and lons.max() > 180:\n",
    "        order = np.argsort(((lons + 180) % 360) - 180)\n",
    "        lons = (((lons + 180) % 360) - 180)[order]\n",
    "        TEC = TEC[:, :, order]\n",
    "\n",
    "    # ensure latitudes are ascending\n",
    "    if lats[0] > lats[-1]:\n",
    "        lats = lats[::-1]\n",
    "        TEC = TEC[:, ::-1, :]\n",
    "\n",
    "    times = pd.to_datetime(times, utc=True)\n",
    "    return times, lats, lons, TEC\n",
    "\n",
    "\n",
    "def product_window(day: date) -> str:\n",
    "    \"\"\"\n",
    "    Select the IONEX product window for a given day:\n",
    "        - 'OLD'    : legacy CODG products\n",
    "        - 'OPSFIN' : final OPSFIN GIM\n",
    "        - 'OPSRAP' : rapid OPSRAP GIM\n",
    "    \"\"\"\n",
    "    if day <= date(2022, 11, 27):  # DOY <= 330\n",
    "        return \"OLD\"\n",
    "    if day <= date(2025, 9, 20):   # OPSFIN window\n",
    "        return \"OPSFIN\"\n",
    "    return \"OPSRAP\"\n",
    "\n",
    "\n",
    "def pick_ionex_for_day(day: date) -> Path | None:\n",
    "    \"\"\"\n",
    "    Pick the best IONEX file for a given day, using:\n",
    "      - CODG (legacy) for the OLD window\n",
    "      - COD0OPSFIN / COD0OPSRAP GIM products afterwards.\n",
    "    Returns the matching Path, or None if nothing is found.\n",
    "    \"\"\"\n",
    "    yy = f\"{day.year % 100:02d}\"\n",
    "    doy = f\"{int(pd.Timestamp(day).strftime('%j')):03d}\"\n",
    "    mode = product_window(day)\n",
    "\n",
    "    if mode == \"OLD\":\n",
    "        # canonical CODG names\n",
    "        candidates = [f\"codg{doy}0.{yy}i\", f\"CODG{doy}0.{yy}I\"]\n",
    "        for name in candidates:\n",
    "            p = DEC_DIR / name\n",
    "            if p.exists() and ionex_first_epoch_date(p) == day:\n",
    "                return p\n",
    "\n",
    "        # fallback: any CODG* file for that year whose first epoch matches\n",
    "        for q in DEC_DIR.glob(f\"codg*{yy}i\"):\n",
    "            if ionex_first_epoch_date(q) == day:\n",
    "                return q\n",
    "        for q in DEC_DIR.glob(f\"CODG*{yy}I\"):\n",
    "            if ionex_first_epoch_date(q) == day:\n",
    "                return q\n",
    "        return None\n",
    "\n",
    "    # New OPSFIN / OPSRAP products\n",
    "    if mode == \"OPSFIN\":\n",
    "        patterns = [\n",
    "            f\"COD0OPSFIN_*{day.year}{doy}*_GIM.INX\",\n",
    "            f\"COD0OPSRAP_*{day.year}{doy}*_GIM.INX\",\n",
    "        ]\n",
    "    else:  # OPSRAP priority\n",
    "        patterns = [\n",
    "            f\"COD0OPSRAP_*{day.year}{doy}*_GIM.INX\",\n",
    "            f\"COD0OPSFIN_*{day.year}{doy}*_GIM.INX\",\n",
    "        ]\n",
    "\n",
    "    for pat in patterns:\n",
    "        for q in DEC_DIR.glob(pat):\n",
    "            if ionex_first_epoch_date(q) == day:\n",
    "                return q\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# CELL 2 — EIA CREST UTILITIES\n",
    "# ==============================================================\n",
    "\n",
    "def lon_wrap(x: np.ndarray | float) -> np.ndarray | float:\n",
    "    \"\"\"\n",
    "    Wrap longitude(s) into the [-180, 180) range.\n",
    "    \"\"\"\n",
    "    return (x + 180.0) % 360.0 - 180.0\n",
    "\n",
    "\n",
    "def lon_band_indices(lons: np.ndarray, lon0: float, band_deg: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return indices of longitudes within ±band_deg of lon0 (all in wrapped [-180, 180) frame).\n",
    "    \"\"\"\n",
    "    l = lon_wrap(lons.copy())\n",
    "    lon0 = lon_wrap(lon0)\n",
    "    return np.where(np.abs(l - lon0) <= band_deg)[0]\n",
    "\n",
    "\n",
    "def crest_lat_from_slice(\n",
    "    lat: np.ndarray,\n",
    "    vtec_lat: np.ndarray,\n",
    "    lat_min: float,\n",
    "    lat_max: float,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    From a latitudinal slice vtec_lat(lat), return the latitude of the\n",
    "    maximum (northern EIA crest) within [lat_min, lat_max].\n",
    "    \"\"\"\n",
    "    mask = (lat >= lat_min) & (lat <= lat_max)\n",
    "    if not np.any(mask):\n",
    "        return np.nan\n",
    "\n",
    "    with np.errstate(invalid=\"ignore\"):\n",
    "        idx = np.nanargmax(vtec_lat[mask])\n",
    "\n",
    "    return float(lat[mask][idx])\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# CELL 3 — MAIN LOOP: DAILY EIA CREST LATITUDE AROUND OUCA\n",
    "# ==============================================================\n",
    "\n",
    "rows: list[dict] = []\n",
    "current_day = START\n",
    "n_days = 0\n",
    "\n",
    "while current_day <= END:\n",
    "    ionex_file = pick_ionex_for_day(current_day)\n",
    "    if ionex_file is None:\n",
    "        current_day += timedelta(days=1)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        times, lats, lons, TEC = read_ionex(ionex_file)\n",
    "    except Exception as exc:\n",
    "        print(f\"[WARN] {ionex_file.name}: could not be read -> {exc}\")\n",
    "        current_day += timedelta(days=1)\n",
    "        continue\n",
    "\n",
    "    # longitude band indices ±LON_BAND_DEG around OUCA longitude\n",
    "    j_idx = lon_band_indices(lons, OUCA_LON, LON_BAND_DEG)\n",
    "    if j_idx.size == 0:\n",
    "        current_day += timedelta(days=1)\n",
    "        continue\n",
    "\n",
    "    for k, t in enumerate(times):\n",
    "        t_utc = t.to_pydatetime()\n",
    "\n",
    "        # We allow maps that might spill into previous/next day; the daily\n",
    "        # aggregation will be made in local time (date_lt).\n",
    "        lt = t_utc.astimezone(LT_TZ)\n",
    "        if ONLY_AFTERNOON_LT and not (\n",
    "            LT_HOURS_WINDOW[0] <= lt.hour < LT_HOURS_WINDOW[1]\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # mean VTEC over the longitude band\n",
    "        vlat = np.nanmean(TEC[k][:, j_idx], axis=1)\n",
    "\n",
    "        crest_lat = crest_lat_from_slice(\n",
    "            lats,\n",
    "            vlat,\n",
    "            SEARCH_LAT_MIN,\n",
    "            SEARCH_LAT_MAX,\n",
    "        )\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"epoch_utc\": t_utc,\n",
    "                \"epoch_lt\": lt,\n",
    "                \"date_lt\": lt.date(),\n",
    "                \"crest_lat\": crest_lat,\n",
    "                \"ouca_lat\": OUCA_LAT,\n",
    "                \"crest_minus_ouca_deg\": crest_lat - OUCA_LAT,\n",
    "                \"src_file\": ionex_file.name,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    n_days += 1\n",
    "    current_day += timedelta(days=1)\n",
    "\n",
    "# ==============================================================\n",
    "# CELL 4 — DAILY AGGREGATION & QUICKLOOK FIGURE\n",
    "# ==============================================================\n",
    "\n",
    "if not rows:\n",
    "    print(\"[INFO] No eligible epochs found in the requested date/LT window.\")\n",
    "else:\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # daily median crest latitude and IQR\n",
    "    daily = (\n",
    "        df.groupby(\"date_lt\", as_index=False)\n",
    "        .agg(\n",
    "            crest_lat_med=(\"crest_lat\", \"median\"),\n",
    "            crest_lat_iqr=(\n",
    "                \"crest_lat\",\n",
    "                lambda x: np.nanpercentile(x, 75) - np.nanpercentile(x, 25),\n",
    "            ),\n",
    "            crest_minus_ouca_med=(\"crest_minus_ouca_deg\", \"median\"),\n",
    "            n_epochs=(\"crest_lat\", \"count\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    daily.to_csv(OUT_DAILY, index=False)\n",
    "    print(\n",
    "        f\"[OK] Daily EIA-crest CSV written -> {OUT_DAILY}  | \"\n",
    "        f\"days = {len(daily)}  | IONEX files read = {n_days}\"\n",
    "    )\n",
    "\n",
    "    # quicklook time series of daily median crest latitude\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(\n",
    "        pd.to_datetime(daily[\"date_lt\"]),\n",
    "        daily[\"crest_lat_med\"],\n",
    "        lw=1.2,\n",
    "        label=\"Daily median crest latitude\",\n",
    "    )\n",
    "    ax.axhline(\n",
    "        OUCA_LAT,\n",
    "        ls=\"--\",\n",
    "        color=\"k\",\n",
    "        lw=1.0,\n",
    "        label=\"OUCA latitude\",\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(\"Daily median crest latitude [deg]\")\n",
    "    ax.set_title(\"Northern EIA crest latitude near OUCA longitude\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(OUT_FIG, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"[OK] Quicklook figure written -> {OUT_FIG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384a4fb-0846-4199-8e03-059f1842b10d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute robust diurnal VTEC slopes (morning and evening) from 30-min\n",
    "VTEC data at OUCA using Theil–Sen regression, with local-time windows\n",
    "that vary by month (seasonal windows).\n",
    "\n",
    "This cell/script assumes that you already have a 30-min dataframe\n",
    "`S` in memory with at least:\n",
    "\n",
    "    - a UTC timestamp column named TIME_COL (default: \"time\")\n",
    "    - a 30-min VTEC column named VTEC_COL (default: \"VTEC_median\")\n",
    "\n",
    "Optionally, you may also have a boolean flag column (QUIET_FLAG_COL)\n",
    "marking “quiet” QSL–GIM20 samples, and set KEEP_ONLY_QUIET = True.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "TIME_COL = \"time\"            # 30-min timestamp column (UTC, or convertible to UTC)\n",
    "VTEC_COL = \"VTEC_median\"     # 30-min VTEC column\n",
    "LOCAL_TZ = \"Africa/Casablanca\"\n",
    "\n",
    "# Default windows (kept for reference, main logic uses seasonal_windows_for_month)\n",
    "MORNING_LT = (6.0, 12.0)     # [start, end) in local time\n",
    "EVENING_LT = (17.0, 22.0)\n",
    "\n",
    "KEEP_ONLY_QUIET = False\n",
    "QUIET_FLAG_COL = \"is_QSL_GIM20\"  # optional boolean quiet flag in S\n",
    "\n",
    "OUT_CSV = Path(\"\\output_csv\\monthly_diurnal_slopes_seasonal_windows.csv\")\n",
    "OUT_PNG = Path(\"\\output_figs\\monthly_diurnal_slopes_seasonal_windows.png\")\n",
    "# ----------------------------------------\n",
    "\n",
    "def theil_sen(x, y):\n",
    "    \"\"\"\n",
    "    Robust Theil–Sen slope estimator between x and y (median of all pairwise slopes).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like\n",
    "        1D arrays of the same length.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Theil–Sen slope (NaN if less than 3 valid points).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float)\n",
    "    y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[m]\n",
    "    y = y[m]\n",
    "    if x.size < 3:\n",
    "        return np.nan\n",
    "\n",
    "    slopes = []\n",
    "    for i in range(x.size - 1):\n",
    "        dx = x[i + 1 :] - x[i]\n",
    "        dy = y[i + 1 :] - y[i]\n",
    "        valid = np.abs(dx) > 1e-12\n",
    "        if not np.any(valid):\n",
    "            continue\n",
    "        v = dy[valid] / dx[valid]\n",
    "        if v.size:\n",
    "            slopes.append(v)\n",
    "\n",
    "    if not slopes:\n",
    "        return np.nan\n",
    "\n",
    "    slopes = np.concatenate(slopes)\n",
    "    return np.nanmedian(slopes)\n",
    "\n",
    "\n",
    "def window_slope(df_lt, start_hour, end_hour):\n",
    "    \"\"\"\n",
    "    Compute a Theil–Sen slope of VTEC vs local-time hour within a given LT window.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_lt : DataFrame\n",
    "        Must contain columns 'lt_hour_float' and VTEC_COL.\n",
    "    start_hour, end_hour : float\n",
    "        Local-time window [start_hour, end_hour) in hours.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Theil–Sen slope d(VTEC)/dt in TECU/hour (NaN if not enough points).\n",
    "    \"\"\"\n",
    "    mask = (df_lt[\"lt_hour_float\"] >= start_hour) & (df_lt[\"lt_hour_float\"] < end_hour)\n",
    "    sub = df_lt.loc[mask, [\"lt_hour_float\", VTEC_COL]].dropna()\n",
    "    if len(sub) < 3:\n",
    "        return np.nan\n",
    "    return theil_sen(sub[\"lt_hour_float\"].values, sub[VTEC_COL].values)\n",
    "\n",
    "\n",
    "def seasonal_windows_for_month(month: int):\n",
    "    \"\"\"\n",
    "    Define local-time windows for “morning” and “evening” as a function of month.\n",
    "\n",
    "    These windows are tuned to approximate seasonal changes in sunrise/sunset:\n",
    "\n",
    "    - Extended winter: November (11) → January (1)\n",
    "        morning : 07–12 LT\n",
    "        evening : 16–20 LT\n",
    "\n",
    "    - February, March:\n",
    "        morning : 06–12 LT\n",
    "        evening : 18–21 LT\n",
    "\n",
    "    - April:\n",
    "        morning : 06–14 LT\n",
    "        evening : 19–22 LT\n",
    "\n",
    "    - May:\n",
    "        morning : 06–15 LT\n",
    "        evening : 19–22 LT\n",
    "\n",
    "    - June:\n",
    "        morning : 06–15 LT\n",
    "        evening : 18.5–23 LT\n",
    "\n",
    "    - July, August:\n",
    "        morning : 06–16 LT\n",
    "        evening : 19–23 LT\n",
    "\n",
    "    - September:\n",
    "        morning : 06–14 LT\n",
    "        evening : 18.5–22 LT\n",
    "\n",
    "    - October:\n",
    "        morning : 07–14 LT\n",
    "        evening : 16–21 LT\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (morning_start, morning_end), (evening_start, evening_end)\n",
    "    \"\"\"\n",
    "    if month in (11, 12, 1):\n",
    "        # Nov–Jan\n",
    "        morning = (7.0, 12.0)\n",
    "        evening = (16.0, 20.0)\n",
    "    elif month == 2:\n",
    "        # Feb\n",
    "        morning = (6.0, 12.0)\n",
    "        evening = (18.0, 21.0)\n",
    "    elif month == 3:\n",
    "        # Mar\n",
    "        morning = (6.0, 12.0)\n",
    "        evening = (18.0, 21.0)\n",
    "    elif month == 4:\n",
    "        # Apr\n",
    "        morning = (6.0, 14.0)\n",
    "        evening = (19.0, 22.0)\n",
    "    elif month == 5:\n",
    "        # May\n",
    "        morning = (6.0, 15.0)\n",
    "        evening = (19.0, 22.0)\n",
    "    elif month == 6:\n",
    "        # Jun\n",
    "        morning = (6.0, 15.0)\n",
    "        evening = (18.5, 23.0)\n",
    "    elif month in (7, 8):\n",
    "        # Jul & Aug\n",
    "        morning = (6.0, 16.0)\n",
    "        evening = (19.0, 23.0)\n",
    "    elif month == 9:\n",
    "        # Sep\n",
    "        morning = (6.0, 14.0)\n",
    "        evening = (18.5, 22.0)\n",
    "    else:\n",
    "        # Oct\n",
    "        morning = (7.0, 14.0)\n",
    "        evening = (16.0, 21.0)\n",
    "\n",
    "    return morning, evening\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main driver: compute daily Theil–Sen slopes (morning/evening) in local time,\n",
    "    then aggregate to monthly medians and save both CSV and a quicklook figure.\n",
    "\n",
    "    This assumes a 30-min dataframe `S` is already defined in the notebook/session.\n",
    "    \"\"\"\n",
    "    # Start from existing 30-min dataframe S (already filtered if needed)\n",
    "    df = S.copy()\n",
    "\n",
    "    # Parse UTC timestamps\n",
    "    df[TIME_COL] = pd.to_datetime(df[TIME_COL], utc=True, errors=\"coerce\")\n",
    "\n",
    "    # Optional quiet-day filter\n",
    "    if KEEP_ONLY_QUIET and QUIET_FLAG_COL in df.columns:\n",
    "        df = df[df[QUIET_FLAG_COL] == True].copy()\n",
    "\n",
    "    # Local time conversion\n",
    "    tz = pytz.timezone(LOCAL_TZ)\n",
    "    df[\"ts_lt\"] = df[TIME_COL].dt.tz_convert(tz)\n",
    "    df[\"date_lt\"] = df[\"ts_lt\"].dt.date\n",
    "    df[\"lt_hour_float\"] = df[\"ts_lt\"].dt.hour + df[\"ts_lt\"].dt.minute / 60.0\n",
    "    df[\"month\"] = df[\"ts_lt\"].dt.month\n",
    "    df[\"year\"] = df[\"ts_lt\"].dt.year\n",
    "\n",
    "    # --- Daily slopes with month-dependent windows ---\n",
    "    daily_rows = []\n",
    "\n",
    "    for d, g in df.groupby(\"date_lt\"):\n",
    "        month = int(g[\"month\"].iloc[0])\n",
    "        (m_start, m_end), (e_start, e_end) = seasonal_windows_for_month(month)\n",
    "\n",
    "        s_m = window_slope(g, m_start, m_end)\n",
    "        s_e = window_slope(g, e_start, e_end)\n",
    "\n",
    "        if not np.isfinite(s_m) and not np.isfinite(s_e):\n",
    "            continue\n",
    "\n",
    "        daily_rows.append(\n",
    "            {\n",
    "                \"date_lt\": d,\n",
    "                \"month\": month,\n",
    "                \"year\": g[\"year\"].iloc[0],\n",
    "                \"morning_start_lt\": m_start,\n",
    "                \"morning_end_lt\": m_end,\n",
    "                \"evening_start_lt\": e_start,\n",
    "                \"evening_end_lt\": e_end,\n",
    "                \"slope_morning_tec_per_hour\": s_m,\n",
    "                \"slope_evening_tec_per_hour\": s_e,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    daily = pd.DataFrame(daily_rows)\n",
    "    if daily.empty:\n",
    "        print(\"No daily slopes computed.\")\n",
    "        return\n",
    "\n",
    "    # --- Monthly aggregates of slopes ---\n",
    "    def iqr(x):\n",
    "        x = np.asarray(x, float)\n",
    "        return np.nanpercentile(x, 75) - np.nanpercentile(x, 25)\n",
    "\n",
    "    monthly = (\n",
    "        daily.groupby(\"month\", as_index=False)\n",
    "        .agg(\n",
    "            n_days=(\"date_lt\", \"count\"),\n",
    "            m_med=(\"slope_morning_tec_per_hour\", \"median\"),\n",
    "            m_iqr=(\"slope_morning_tec_per_hour\", iqr),\n",
    "            e_med=(\"slope_evening_tec_per_hour\", \"median\"),\n",
    "            e_iqr=(\"slope_evening_tec_per_hour\", iqr),\n",
    "        )\n",
    "        .sort_values(\"month\")\n",
    "    )\n",
    "\n",
    "    monthly.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"Saved {OUT_CSV}\")\n",
    "\n",
    "    # --- Quicklook figure ---\n",
    "    x = monthly[\"month\"].values\n",
    "    fig, ax = plt.subplots(figsize=(9, 4))\n",
    "\n",
    "    ax.plot(x, monthly[\"m_med\"], \"-o\", label=\"Morning slope (median)\")\n",
    "    ax.plot(x, monthly[\"e_med\"], \"-o\", label=\"Evening slope (median)\")\n",
    "    ax.axhline(0, color=\"k\", lw=1.2, ls=\"--\")\n",
    "\n",
    "    ax.set_yticks([-3, -2, -1, 0, 1, 2, 3])\n",
    "    ax.set_xticks(np.arange(1, 13))\n",
    "    ax.set_xlim(0.5, 12.5)\n",
    "\n",
    "    # Tick styling\n",
    "    for t in ax.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10)\n",
    "        t.set_color(\"black\")\n",
    "        t.set_weight(\"bold\")\n",
    "    for t in ax.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10)\n",
    "        t.set_color(\"black\")\n",
    "        t.set_weight(\"bold\")\n",
    "\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.text(\n",
    "        0.5,\n",
    "        0.89,\n",
    "        \"Quiet monthly diurnal slopes at OUCA (seasonal LT windows)\",\n",
    "        ha=\"center\",\n",
    "        fontsize=12,\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "    fig.text(\n",
    "        0.5,\n",
    "        0.03,\n",
    "        \"Month of year\",\n",
    "        ha=\"center\",\n",
    "        fontsize=12,\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "    fig.text(\n",
    "        0.06,\n",
    "        0.5,\n",
    "        \"dVTEC/dt [TECU/hour]\",\n",
    "        va=\"center\",\n",
    "        rotation=\"vertical\",\n",
    "        fontsize=12,\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "\n",
    "    fig.savefig(OUT_PNG, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved {OUT_PNG}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf7733-4478-4efc-a2d0-6277d5b34185",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combined figure: EIA crest latitude vs. monthly diurnal VTEC slopes\n",
    "\n",
    "This cell builds a 2-panel figure:\n",
    "\n",
    "  (1) Time series of the daily median latitude of the northern EIA crest\n",
    "      near the OUCA longitude.\n",
    "  (2) Monthly median diurnal slopes (morning/evening) of VTEC at OUCA,\n",
    "      previously computed with diurnal_slopes_from_S30.py.\n",
    "\n",
    "Inputs\n",
    "------\n",
    "- CSV_EIA:\n",
    "    CSV produced by eia_crest_from_ionex_using_my_reader.py\n",
    "    Must contain at least:\n",
    "        * date_lt          (local-date of the crest)\n",
    "        * crest_lat_med    (daily median crest latitude in degrees)\n",
    "\n",
    "- CSV_SLOPE:\n",
    "    CSV produced by diurnal_slopes_from_S30.py\n",
    "    Must contain at least:\n",
    "        * month            (1..12)\n",
    "        * m_med            (morning slope median, TECU/hour)\n",
    "        * e_med            (evening slope median, TECU/hour)\n",
    "\n",
    "Output\n",
    "------\n",
    "- OUT_PNG_COMBO:\n",
    "    PNG file with the two-panel figure, ready for publication.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "\n",
    "# --------- CONFIG: update paths if needed ---------\n",
    "CSV_EIA = Path(\"\\output_csv\\daily_eia_crest_latitude.csv\")\n",
    "CSV_SLOPE = Path(\"\\output_csv\\monthly_diurnal_slopes_seasonal_windows.csv\")\n",
    "OUT_PNG_COMBO = Path(\"\\output_csv\\EIAcrest_vs_monthly_slopes_MS.png\")\n",
    "\n",
    "OUCA_LAT = 31.206  # OUCA geodetic latitude [deg]\n",
    "\n",
    "# --------- READ INPUT DATA ---------\n",
    "# 1) EIA crest (daily)\n",
    "crest = pd.read_csv(CSV_EIA)\n",
    "\n",
    "if \"date_lt\" not in crest.columns:\n",
    "    raise ValueError(\"CSV_EIA must contain a 'date_lt' column.\")\n",
    "\n",
    "crest[\"date_lt\"] = pd.to_datetime(crest[\"date_lt\"], errors=\"coerce\")\n",
    "crest = crest.dropna(subset=[\"date_lt\", \"crest_lat_med\"])\n",
    "\n",
    "# 2) Monthly diurnal slopes\n",
    "monthly = pd.read_csv(CSV_SLOPE)\n",
    "for col in [\"month\", \"m_med\", \"e_med\"]:\n",
    "    if col not in monthly.columns:\n",
    "        raise ValueError(f\"CSV_SLOPE must contain the '{col}' column.\")\n",
    "\n",
    "monthly = monthly.sort_values(\"month\")\n",
    "x = monthly[\"month\"].values\n",
    "month_labels = [calendar.month_abbr[m] for m in x]  # Jan, Feb, ...\n",
    "\n",
    "# --------- BUILD 2-PANEL FIGURE ---------\n",
    "fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(12, 10), sharex=False)\n",
    "\n",
    "# =======================\n",
    "# (1) TOP PANEL: EIA CREST LATITUDE\n",
    "# =======================\n",
    "ax_top.plot(\n",
    "    crest[\"date_lt\"],\n",
    "    crest[\"crest_lat_med\"],\n",
    "    lw=1.2,\n",
    "    label=\"Daily median crest latitude\",\n",
    ")\n",
    "ax_top.axhline(\n",
    "    OUCA_LAT,\n",
    "    ls=\"--\",\n",
    "    color=\"k\",\n",
    "    lw=1.0,\n",
    "    label=\"OUCA latitude\",\n",
    ")\n",
    "\n",
    "ax_top.set_ylabel(\"Latitude [deg]\", fontsize=12, fontweight=\"bold\")\n",
    "ax_top.grid(True, alpha=0.3)\n",
    "ax_top.legend(loc=\"best\", frameon=True)\n",
    "\n",
    "# Tick styling\n",
    "for t in ax_top.yaxis.get_ticklabels():\n",
    "    t.set_fontsize(12)\n",
    "    t.set_color(\"black\")\n",
    "    t.set_weight(\"bold\")\n",
    "for t in ax_top.xaxis.get_ticklabels():\n",
    "    t.set_fontsize(12)\n",
    "    t.set_color(\"black\")\n",
    "    t.set_weight(\"bold\")\n",
    "\n",
    "ax_top.set_title(\n",
    "    \"Northern EIA crest latitude near OUCA longitude\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    "    loc=\"center\",\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# (2) BOTTOM PANEL: MONTHLY DIURNAL SLOPES\n",
    "# =======================\n",
    "ax_bot.plot(\n",
    "    x,\n",
    "    monthly[\"m_med\"],\n",
    "    \"-o\",\n",
    "    label=\"Morning slope (median)\",\n",
    ")\n",
    "ax_bot.plot(\n",
    "    x,\n",
    "    monthly[\"e_med\"],\n",
    "    \"-o\",\n",
    "    label=\"Evening slope (median)\",\n",
    ")\n",
    "ax_bot.axhline(0, color=\"k\", lw=1.2, ls=\"--\")\n",
    "\n",
    "ax_bot.set_yticks([-3, -2, -1, 0, 1, 2, 3])\n",
    "ax_bot.set_xticks(x)\n",
    "ax_bot.set_xticklabels(month_labels)\n",
    "ax_bot.set_xlim(0.5, 12.5)\n",
    "\n",
    "# Tick styling\n",
    "for t in ax_bot.yaxis.get_ticklabels():\n",
    "    t.set_fontsize(12)\n",
    "    t.set_color(\"black\")\n",
    "    t.set_weight(\"bold\")\n",
    "for t in ax_bot.xaxis.get_ticklabels():\n",
    "    t.set_fontsize(12)\n",
    "    t.set_color(\"black\")\n",
    "    t.set_weight(\"bold\")\n",
    "\n",
    "ax_bot.grid(True, alpha=0.3)\n",
    "ax_bot.legend(loc=\"best\", frameon=True)\n",
    "\n",
    "ax_bot.set_ylabel(\"dVTEC/dt [TECU/hour]\", fontsize=12, fontweight=\"bold\")\n",
    "ax_bot.set_title(\n",
    "    \"Quiet monthly diurnal slopes at OUCA (seasonal LT windows)\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    "    loc=\"center\",\n",
    ")\n",
    "\n",
    "# Global x-axis label\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.03,\n",
    "    \"Month of year\",\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    "    weight=\"bold\",\n",
    ")\n",
    "\n",
    "fig.savefig(OUT_PNG_COMBO, dpi=300)\n",
    "plt.close(fig)\n",
    "print(f\"Saved combined figure -> {OUT_PNG_COMBO}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
