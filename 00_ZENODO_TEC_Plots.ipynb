{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d30b0b68-1504-44c0-9122-26a0206bc07a",
   "metadata": {},
   "source": [
    "Figure unique 3 rangées: F10.7, Kp, Dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f5b54-4775-405d-b043-151a4f919cfe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ===== Figure unique 3 rangées: F10.7, Kp, Dst (2010–2025) avec période TEC surlignée =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# --------- Paramètres d'affichage ---------\n",
    "matplotlib.rcParams['savefig.dpi'] = 300\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 9)\n",
    "matplotlib.rcParams['font.size'] = 8\n",
    "\n",
    "# --------- Chemins (adapter si besoin) ---------\n",
    "CSV_PATH   = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/Indices/F10_7_2010_2025.csv\")\n",
    "Kp_TXT     = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/Indices/GFZ_all_indices_2010-2025.txt\")\n",
    "Dst_TXT    = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/Indices/Kyoto_DST_index_2010-2025.txt\")\n",
    "OUT_ALL_PNG = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/figures/F107_Kp_Dst_3rows_2010-2025.png\")\n",
    "\n",
    "# --------- Fenêtres temporelles ---------\n",
    "plot_start = pd.Timestamp(\"2010-01-01\")\n",
    "plot_end   = pd.Timestamp(\"2025-09-26\")\n",
    "tec_start  = pd.Timestamp(\"2015-10-01\")\n",
    "tec_end    = pd.Timestamp(\"2025-09-26\")\n",
    "\n",
    "# --------- Outils ---------\n",
    "def jd_to_datetime_utc(jd):\n",
    "    jd = float(jd)\n",
    "    J = int(jd + 0.5)\n",
    "    f = jd + 0.5 - J\n",
    "    if J >= 2299161:\n",
    "        a = int((J - 1867216.25) / 36524.25)\n",
    "        A = J + 1 + a - int(a / 4)\n",
    "    else:\n",
    "        A = J\n",
    "    B = A + 1524\n",
    "    C = int((B - 122.1) / 365.25)\n",
    "    D = int(365.25 * C)\n",
    "    E = int((B - D) / 30.6001)\n",
    "    day = B - D - int(30.6001 * E) + f\n",
    "    month = E - 1 if E < 14 else E - 13\n",
    "    year = C - 4716 if month > 2 else C - 4715\n",
    "    day_int = int(day)\n",
    "    frac_day = day - day_int\n",
    "    seconds = frac_day * 86400.0\n",
    "    hh = int(seconds // 3600)\n",
    "    mm = int((seconds % 3600) // 60)\n",
    "    ss = int(round(seconds % 60))\n",
    "    if ss == 60:\n",
    "        ss = 0; mm += 1\n",
    "    if mm == 60:\n",
    "        mm = 0; hh += 1\n",
    "    return datetime(year, month, day_int, hh, mm, ss, tzinfo=timezone.utc)\n",
    "\n",
    "def load_kp_gfz_daily(path: Path) -> pd.DataFrame:\n",
    "    dates, kp_daily, kp8_store = [], [], []\n",
    "    with open(path, \"r\", errors=\"ignore\") as fh:\n",
    "        for line in fh:\n",
    "            if not line.strip() or line.lstrip().startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) < 28:\n",
    "                continue\n",
    "            try:\n",
    "                y, m, d = int(parts[0]), int(parts[1]), int(parts[2])\n",
    "                kp8 = [float(x) for x in parts[7:15]]\n",
    "            except Exception:\n",
    "                continue\n",
    "            kparr = np.array(kp8, dtype=float)\n",
    "            kparr[kparr < 0] = np.nan\n",
    "            kp_mean = float(np.nanmean(kparr)) if np.isfinite(kparr).any() else np.nan\n",
    "            dates.append(pd.Timestamp(year=y, month=m, day=d))\n",
    "            kp_daily.append(kp_mean)\n",
    "            kp8_store.append(kp8)\n",
    "    df = pd.DataFrame({\"date\": dates, \"kp_daily\": kp_daily, \"kp8\": kp8_store})\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def load_dst_kyoto_daily(path: Path) -> pd.DataFrame:\n",
    "    dates, daily, hours_list = [], [], []\n",
    "    with open(path, \"r\", errors=\"ignore\") as fh:\n",
    "        for line in fh:\n",
    "            if not line.strip() or line.lstrip().startswith(\"#\") or not line.startswith(\"DST\"):\n",
    "                continue\n",
    "            try:\n",
    "                yy = int(line[3:5]); mm = int(line[5:7]); dd = int(line[8:10])\n",
    "            except Exception:\n",
    "                continue\n",
    "            cent = line[14:16].strip()\n",
    "            if cent.isdigit():\n",
    "                year = int(f\"{cent}{yy:02d}\")\n",
    "            else:\n",
    "                year = 1900 + yy if yy >= 50 else 2000 + yy\n",
    "            vals = []\n",
    "            for i in range(24):\n",
    "                s = line[20 + i*4 : 24 + i*4].strip()\n",
    "                if not s:\n",
    "                    vals.append(np.nan); continue\n",
    "                try:\n",
    "                    v = int(s)\n",
    "                except Exception:\n",
    "                    vals.append(np.nan); continue\n",
    "                vals.append(np.nan if v == 9999 else float(v))\n",
    "            dst_mean = float(np.nanmean(vals)) if np.isfinite(vals).any() else np.nan\n",
    "            dates.append(pd.Timestamp(year=year, month=mm, day=dd))\n",
    "            daily.append(dst_mean)\n",
    "            hours_list.append(vals)\n",
    "    df = pd.DataFrame({\"date\": dates, \"dst_daily\": daily, \"dst24\": hours_list})\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# --------- Lecture F10.7 (CSV Penticton: JD, F_obs, F_adj) ---------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "cols = list(df.columns)\n",
    "if len(cols) < 3:\n",
    "    raise ValueError(\"Le CSV doit contenir ≥3 colonnes (JD, F_obs, F_adj).\")\n",
    "jd_col, fobs_col, fadj_col = cols[0], cols[1], cols[2]\n",
    "\n",
    "df[\"datetime_utc\"] = pd.to_datetime([jd_to_datetime_utc(x) for x in df[jd_col]], utc=True)\n",
    "df[\"date\"] = pd.to_datetime(df[\"datetime_utc\"].dt.date)\n",
    "\n",
    "# filtrage outliers sur la colonne ajustée\n",
    "non_outliers_df = df.drop(df[df[fadj_col] > 500].index)\n",
    "\n",
    "m_window = (non_outliers_df[\"date\"] >= plot_start) & (non_outliers_df[\"date\"] <= plot_end)\n",
    "dfw = non_outliers_df.loc[m_window].copy()\n",
    "\n",
    "# --------- Lecture Kp et Dst ---------\n",
    "kp_df  = load_kp_gfz_daily(Kp_TXT)\n",
    "dst_df = load_dst_kyoto_daily(Dst_TXT)\n",
    "\n",
    "kp_df  = kp_df[(kp_df[\"date\"]  >= plot_start) & (kp_df[\"date\"]  <= plot_end)].copy()\n",
    "dst_df = dst_df[(dst_df[\"date\"] >= plot_start) & (dst_df[\"date\"] <= plot_end)].copy()\n",
    "\n",
    "# --------- Masques période TEC ---------\n",
    "m_f_tec   = (dfw[\"date\"]   >= tec_start) & (dfw[\"date\"]   <= tec_end)\n",
    "m_kp_tec  = (kp_df[\"date\"] >= tec_start) & (kp_df[\"date\"] <= tec_end)\n",
    "m_dst_tec = (dst_df[\"date\"]>= tec_start) & (dst_df[\"date\"]<= tec_end)\n",
    "\n",
    "# --------- Figure 3 rangées, abscisses partagées ---------\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(10, 9), dpi=300)\n",
    "\n",
    "# 1) F10.7 (ajusté 1 AU)\n",
    "ax = axes[0]\n",
    "ax.plot(dfw[\"date\"], dfw[fadj_col], lw=1.2, label=\"F10.7 (1-AU adjusted) (Penticton)\")\n",
    "ax.plot(dfw.loc[m_f_tec, \"date\"], dfw.loc[m_f_tec, fadj_col], lw=2.0, color=\"red\",\n",
    "        label=\"Période TEC\")\n",
    "ax.set_ylabel(\"$F_{10.7}$ [sfu]\", fontsize=12, weight=\"bold\")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"best\", prop={'size':8})\n",
    "\n",
    "# 2) Kp journalier (moyenne des 8×3h)\n",
    "ax = axes[1]\n",
    "ax.plot(kp_df[\"date\"], kp_df[\"kp_daily\"], lw=1.2, label=\"Kp quotidien\")\n",
    "ax.plot(kp_df.loc[m_kp_tec, \"date\"], kp_df.loc[m_kp_tec, \"kp_daily\"], lw=2.0, color=\"red\",\n",
    "        label=\"Période TEC\")\n",
    "ax.set_ylabel(\"Kp\", fontsize=12, weight=\"bold\")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"best\", prop={'size':8})\n",
    "\n",
    "# 3) Dst journalier (moyenne des 24h)\n",
    "ax = axes[2]\n",
    "ax.plot(dst_df[\"date\"], dst_df[\"dst_daily\"], lw=1.2, label=\"Dst quotidien\")\n",
    "ax.plot(dst_df.loc[m_dst_tec, \"date\"], dst_df.loc[m_dst_tec, \"dst_daily\"], lw=2.0, color=\"red\",\n",
    "        label=\"Période TEC\")\n",
    "ax.set_ylabel(\"Dst [nT]\", fontsize=12, weight=\"bold\")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"best\", prop={'size':8})\n",
    "\n",
    "# --------- Mise en forme commune ---------\n",
    "for ax in axes:\n",
    "    ax.set_xlim(plot_start, plot_end)\n",
    "    for tick in ax.yaxis.get_ticklabels():\n",
    "        tick.set_fontsize(12)\n",
    "        tick.set_color('black')\n",
    "        tick.set_weight('bold')\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    ax.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "for tick in axes[-1].xaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12)\n",
    "    tick.set_color('black')\n",
    "    tick.set_weight('bold')\n",
    "\n",
    "fig.text(0.5, 0.965, \"F10.7, Kp, and Dst — 2010–2025 | TEC study period: Oct 2015–Sep 2025\",\n",
    "         ha=\"center\", fontsize=12, weight=\"bold\")\n",
    "fig.subplots_adjust(left=0.12, right=0.97, top=0.93, bottom=0.06, hspace=0.0)\n",
    "fig.text(0.5, 0.01, \"Date\", ha=\"center\", fontsize=12, weight=\"bold\")\n",
    "\n",
    "fig.savefig(OUT_ALL_PNG, dpi=300)\n",
    "plt.close(fig)\n",
    "print(f\"✅ Figure combinée sauvegardée → {OUT_ALL_PNG}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25577741-bcfe-49b7-ac29-06f1e588f834",
   "metadata": {},
   "source": [
    "Figure unique 3 rangées avec ombre: F10.7, Kp, Dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b953e1-a53b-4e1b-8aca-14b34f1b4845",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ===== Figure unique 3 rangées: F10.7, Kp, Dst (2010–2025) avec période TEC surlignée =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# --------- Paramètres d'affichage ---------\n",
    "matplotlib.rcParams['savefig.dpi'] = 300\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 9)\n",
    "matplotlib.rcParams['font.size'] = 8\n",
    "\n",
    "# --------- Chemins (adapter si besoin) ---------\n",
    "CSV_PATH   = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/Indices/F10_7_2010_2025.csv\")\n",
    "Kp_TXT     = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/Indices/GFZ_all_indices_2010-2025.txt\")\n",
    "Dst_TXT    = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/Indices/Kyoto_DST_index_2010-2025.txt\")\n",
    "OUT_ALL_PNG = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/figures/F107_Kp_Dst_3rows_2010-2025_shadowed.png\")\n",
    "\n",
    "# --------- Fenêtres temporelles ---------\n",
    "plot_start = pd.Timestamp(\"2010-01-01\")\n",
    "plot_end   = pd.Timestamp(\"2025-09-26\")\n",
    "tec_start  = pd.Timestamp(\"2015-10-01\")\n",
    "tec_end    = pd.Timestamp(\"2025-09-26\")\n",
    "\n",
    "# --------- Outils ---------\n",
    "def jd_to_datetime_utc(jd):\n",
    "    jd = float(jd)\n",
    "    J = int(jd + 0.5)\n",
    "    f = jd + 0.5 - J\n",
    "    if J >= 2299161:\n",
    "        a = int((J - 1867216.25) / 36524.25)\n",
    "        A = J + 1 + a - int(a / 4)\n",
    "    else:\n",
    "        A = J\n",
    "    B = A + 1524\n",
    "    C = int((B - 122.1) / 365.25)\n",
    "    D = int(365.25 * C)\n",
    "    E = int((B - D) / 30.6001)\n",
    "    day = B - D - int(30.6001 * E) + f\n",
    "    month = E - 1 if E < 14 else E - 13\n",
    "    year = C - 4716 if month > 2 else C - 4715\n",
    "    day_int = int(day)\n",
    "    frac_day = day - day_int\n",
    "    seconds = frac_day * 86400.0\n",
    "    hh = int(seconds // 3600)\n",
    "    mm = int((seconds % 3600) // 60)\n",
    "    ss = int(round(seconds % 60))\n",
    "    if ss == 60:\n",
    "        ss = 0; mm += 1\n",
    "    if mm == 60:\n",
    "        mm = 0; hh += 1\n",
    "    return datetime(year, month, day_int, hh, mm, ss, tzinfo=timezone.utc)\n",
    "\n",
    "def load_kp_gfz_daily(path: Path) -> pd.DataFrame:\n",
    "    dates, kp_daily, kp8_store = [], [], []\n",
    "    with open(path, \"r\", errors=\"ignore\") as fh:\n",
    "        for line in fh:\n",
    "            if not line.strip() or line.lstrip().startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) < 28:\n",
    "                continue\n",
    "            try:\n",
    "                y, m, d = int(parts[0]), int(parts[1]), int(parts[2])\n",
    "                kp8 = [float(x) for x in parts[7:15]]\n",
    "            except Exception:\n",
    "                continue\n",
    "            kparr = np.array(kp8, dtype=float)\n",
    "            kparr[kparr < 0] = np.nan\n",
    "            kp_mean = float(np.nanmean(kparr)) if np.isfinite(kparr).any() else np.nan\n",
    "            dates.append(pd.Timestamp(year=y, month=m, day=d))\n",
    "            kp_daily.append(kp_mean)\n",
    "            kp8_store.append(kp8)\n",
    "    df = pd.DataFrame({\"date\": dates, \"kp_daily\": kp_daily, \"kp8\": kp8_store})\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def load_dst_kyoto_daily(path: Path) -> pd.DataFrame:\n",
    "    dates, daily, hours_list = [], [], []\n",
    "    with open(path, \"r\", errors=\"ignore\") as fh:\n",
    "        for line in fh:\n",
    "            if not line.strip() or line.lstrip().startswith(\"#\") or not line.startswith(\"DST\"):\n",
    "                continue\n",
    "            try:\n",
    "                yy = int(line[3:5]); mm = int(line[5:7]); dd = int(line[8:10])\n",
    "            except Exception:\n",
    "                continue\n",
    "            cent = line[14:16].strip()\n",
    "            if cent.isdigit():\n",
    "                year = int(f\"{cent}{yy:02d}\")\n",
    "            else:\n",
    "                year = 1900 + yy if yy >= 50 else 2000 + yy\n",
    "            vals = []\n",
    "            for i in range(24):\n",
    "                s = line[20 + i*4 : 24 + i*4].strip()\n",
    "                if not s:\n",
    "                    vals.append(np.nan); continue\n",
    "                try:\n",
    "                    v = int(s)\n",
    "                except Exception:\n",
    "                    vals.append(np.nan); continue\n",
    "                vals.append(np.nan if v == 9999 else float(v))\n",
    "            dst_mean = float(np.nanmean(vals)) if np.isfinite(vals).any() else np.nan\n",
    "            dates.append(pd.Timestamp(year=year, month=mm, day=dd))\n",
    "            daily.append(dst_mean)\n",
    "            hours_list.append(vals)\n",
    "    df = pd.DataFrame({\"date\": dates, \"dst_daily\": daily, \"dst24\": hours_list})\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# --------- Lecture F10.7 (CSV Penticton: JD, F_obs, F_adj) ---------\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "cols = list(df.columns)\n",
    "if len(cols) < 3:\n",
    "    raise ValueError(\"Le CSV doit contenir ≥3 colonnes (JD, F_obs, F_adj).\")\n",
    "jd_col, fobs_col, fadj_col = cols[0], cols[1], cols[2]\n",
    "\n",
    "df[\"datetime_utc\"] = pd.to_datetime([jd_to_datetime_utc(x) for x in df[jd_col]], utc=True)\n",
    "df[\"date\"] = pd.to_datetime(df[\"datetime_utc\"].dt.date)\n",
    "\n",
    "# filtrage outliers sur la colonne ajustée\n",
    "non_outliers_df = df.drop(df[df[fadj_col] > 500].index)\n",
    "\n",
    "m_window = (non_outliers_df[\"date\"] >= plot_start) & (non_outliers_df[\"date\"] <= plot_end)\n",
    "dfw = non_outliers_df.loc[m_window].copy()\n",
    "\n",
    "# --------- Lecture Kp et Dst ---------\n",
    "kp_df  = load_kp_gfz_daily(Kp_TXT)\n",
    "dst_df = load_dst_kyoto_daily(Dst_TXT)\n",
    "\n",
    "kp_df  = kp_df[(kp_df[\"date\"]  >= plot_start) & (kp_df[\"date\"]  <= plot_end)].copy()\n",
    "dst_df = dst_df[(dst_df[\"date\"] >= plot_start) & (dst_df[\"date\"] <= plot_end)].copy()\n",
    "\n",
    "# --------- Masques période TEC ---------\n",
    "m_f_tec   = (dfw[\"date\"]   >= tec_start) & (dfw[\"date\"]   <= tec_end)\n",
    "m_kp_tec  = (kp_df[\"date\"] >= tec_start) & (kp_df[\"date\"] <= tec_end)\n",
    "m_dst_tec = (dst_df[\"date\"]>= tec_start) & (dst_df[\"date\"]<= tec_end)\n",
    "\n",
    "# --------- Figure 3 rangées, abscisses partagées ---------\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(10, 9), dpi=300)\n",
    "\n",
    "# 1) F10.7 (ajusté 1 AU)\n",
    "ax = axes[0]\n",
    "ax.plot(dfw[\"date\"], dfw[fadj_col], lw=1.2, label=\"F10.7 (1-AU adjusted) (Penticton)\")\n",
    "ax.axvspan(tec_start, tec_end, color=\"red\", alpha=0.2, linewidth=0, label=\"TEC period\")\n",
    "#ax.set_ylabel(\"$F_{10.7}$ [sfu]\", fontsize=12, weight=\"bold\")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"upper center\", prop={'size':8})\n",
    "\n",
    "# 2) Kp journalier (moyenne des 8×3h)\n",
    "ax = axes[1]\n",
    "ax.plot(kp_df[\"date\"], kp_df[\"kp_daily\"], lw=1.2, label=\"Daily Kp (GFZ)\")\n",
    "ax.axvspan(tec_start, tec_end, color=\"green\", alpha=0.2, linewidth=0, label=\"TEC period\")\n",
    "#ax.set_ylabel(\"Kp\", fontsize=12, weight=\"bold\")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"upper center\", prop={'size':8})\n",
    "\n",
    "# 3) Dst journalier (moyenne des 24h)\n",
    "ax = axes[2]\n",
    "ax.plot(dst_df[\"date\"], dst_df[\"dst_daily\"], lw=1.2, label=\"Daily Dst (Kyoto)\")\n",
    "ax.axvspan(tec_start, tec_end, color=\"orange\", alpha=0.2, linewidth=0, label=\"TEC period\")\n",
    "#ax.set_ylabel(\"Dst [nT]\", fontsize=12, weight=\"bold\")\n",
    "ax.grid(True, alpha=0.35)\n",
    "ax.legend(loc=\"lower center\", prop={'size':8})\n",
    "\n",
    "# --------- Mise en forme commune ---------\n",
    "for ax in axes:\n",
    "    ax.set_xlim(plot_start, plot_end)\n",
    "    for tick in ax.yaxis.get_ticklabels():\n",
    "        tick.set_fontsize(12)\n",
    "        tick.set_color('black')\n",
    "        tick.set_weight('bold')\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    ax.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "for tick in axes[-1].xaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12)\n",
    "    tick.set_color('black')\n",
    "    tick.set_weight('bold')\n",
    "\n",
    "fig.text(0.5, 0.965, \"F10.7, Kp, and Dst — 2010–2025 | TEC study period: Oct 2015–Sep 2025 shadowed\",\n",
    "         ha=\"center\", fontsize=12, weight=\"bold\")\n",
    "fig.subplots_adjust(left=0.12, right=0.97, top=0.93, bottom=0.06, hspace=0.0)\n",
    "fig.text(0.5, 0.01, \"Date\", ha=\"center\", fontsize=12, weight=\"bold\")\n",
    "fig.text(0.05, 0.75, \"$F_{10.7}$ [sfu]\", ha=\"center\", rotation=90, fontsize=12, weight=\"bold\")\n",
    "fig.text(0.05, 0.5, \"Kp\", ha=\"center\", rotation=90, fontsize=12, weight=\"bold\")\n",
    "fig.text(0.05, 0.15, \"DST [nT]\", ha=\"center\", rotation=90, fontsize=12, weight=\"bold\")\n",
    "#plt.show()\n",
    "fig.savefig(OUT_ALL_PNG, dpi=300)\n",
    "plt.close(fig)\n",
    "print(f\"✅ Figure combinée sauvegardée → {OUT_ALL_PNG}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69890085-01e2-4707-b7b5-167818c3a731",
   "metadata": {},
   "source": [
    "Generate 4 daily tec figures / Year with GIM and offset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69724c0f-5cb5-4a8b-a1bf-9507d12e8ec5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# FIGURES JOURNALIERES 2×2 PAR AN\n",
    "# ========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# --- chemins des CSV déjà enrichis ---\n",
    "CSV_30MIN_WITH_GIM = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/2015_2025_MS_VTEC_30min_stats.csv\")\n",
    "CSV_DAILY_WITH_OFF = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/2015_2025_MS_VTEC_daily_stats_UTC_with_indices_and_max_with_GFZlabels.csv\")\n",
    "\n",
    "# --- colonnes TEC dans le CSV 30 min ---\n",
    "VTEC_MED_COL  = \"VTEC_median\"        # <- déjà utilisé dans ta pipeline\n",
    "VTEC_MEAN_COL = \"VTEC_mean\"          # <- si elle n'existe pas, on l'ignore\n",
    "GIM_COL       = \"vtec_gim\"\n",
    "GIM_OFSSET= 'gim_offset_tecu'\n",
    "\n",
    "# --- dossier de sortie des figures ---\n",
    "FIG_DIR = Path(CSV_30MIN_WITH_GIM).parent / \"figures/figs_quiet/MS_FIGURES_GIM\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb697c5-9c49-4488-a3e4-ba4b567e88b5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _set_xticks_30min(ax):\n",
    "    ax.set_xlim(-1, 24)\n",
    "    ax.set_xticks(np.arange(0, 24, 2))\n",
    "    ax.set_xticklabels([f\"{h:02d}\" for h in range(0, 24, 2)], rotation=0)\n",
    "# --- utilitaires de lecture ---\n",
    "def _load_30min_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # ts_utc\n",
    "    if \"ts_utc\" in df.columns:\n",
    "        df[\"ts_utc\"] = pd.to_datetime(df[\"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "    else:\n",
    "        t = pd.to_datetime(df[\"time\"], utc=True, errors=\"coerce\")\n",
    "        df[\"ts_utc\"] = t\n",
    "\n",
    "    # date_utc\n",
    "    if \"date_utc\" in df.columns:\n",
    "        df[\"date_utc\"] = pd.to_datetime(df[\"date_utc\"], utc=True, errors=\"coerce\").dt.date\n",
    "    else:\n",
    "        df[\"date_utc\"] = df[\"ts_utc\"].dt.floor(\"D\").dt.date\n",
    "\n",
    "    for c in [VTEC_MED_COL, VTEC_MEAN_COL, GIM_COL]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _load_daily_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    if \"date_utc\" in df.columns:\n",
    "        df[\"date_utc\"] = pd.to_datetime(df[\"date_utc\"], utc=True, errors=\"coerce\").dt.date\n",
    "    elif \"date\" in df.columns:\n",
    "        df[\"date_utc\"] = pd.to_datetime(df[\"date\"], utc=True, errors=\"coerce\").dt.date\n",
    "    return df\n",
    "\n",
    "s30 = _load_30min_csv(CSV_30MIN_WITH_GIM)\n",
    "# --- normalisation des types temps/date ---\n",
    "s30[\"ts_utc\"]   = pd.to_datetime(s30[\"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "s30[\"date_utc\"] = pd.to_datetime(s30[\"date_utc\"], utc=True, errors=\"coerce\").dt.date\n",
    "\n",
    "daily_off = _load_daily_csv(CSV_DAILY_WITH_OFF) if Path(CSV_DAILY_WITH_OFF).exists() else pd.DataFrame(columns=[\"date_utc\",\"gim_offset_tecu\"])\n",
    "\n",
    "# --- offset du jour: depuis le CSV daily si dispo, sinon calcul médiane(VTEC_median - GIM_VTEC) sur le jour ---\n",
    "def get_daily_offset(day, s30_df, daily_df=None):\n",
    "    # 1) try daily CSV if provided\n",
    "    if daily_df is not None and \"gim_offset_tecu\" in daily_df.columns:\n",
    "        row = daily_df.loc[daily_df[\"date_utc\"] == day, \"gim_offset_tecu\"]\n",
    "        if not row.empty and pd.notna(row.iloc[0]):\n",
    "            return float(row.iloc[0])\n",
    "\n",
    "    # 2) fallback: compute from the 30-min CSV\n",
    "    mask = s30_df[\"date_utc\"] == day\n",
    "    v = pd.to_numeric(s30_df.loc[mask, \"VTEC_median\"], errors=\"coerce\")\n",
    "    g = pd.to_numeric(s30_df.loc[mask, \"vtec_gim\"],    errors=\"coerce\")\n",
    "    joined = pd.concat([v, g], axis=1).dropna()\n",
    "    if joined.empty:\n",
    "        return float(\"nan\")\n",
    "    return float((joined.iloc[:,0] - joined.iloc[:,1]).median())\n",
    "\n",
    "\n",
    "# --- choix des 4 jours par année ---\n",
    "# Par défaut: ~15 jan/avr/jul/oct ; s’il n’y a pas de données ce jour-là,\n",
    "# on prend le jour existant le plus proche dans l’année.\n",
    "# 4 jours \"typiques\" (tu peux changer)\n",
    "DEFAULT_MONTH_DAY = [(1, 15), (4, 15), (7, 15), (11, 15)]\n",
    "\n",
    "def nearest_available_date(year: int, target_date, available_dates):\n",
    "    \"\"\"Renvoie la date dispo la plus proche de target_date (tout en tz-naïf).\"\"\"\n",
    "    target = pd.Timestamp(target_date)  # naïf (pas de tz)\n",
    "\n",
    "    # Liste -> DatetimeIndex, purge des NaT\n",
    "    avail_ts = pd.to_datetime(available_dates, errors=\"coerce\")\n",
    "    avail_ts = avail_ts[~pd.isna(avail_ts)]\n",
    "    if len(avail_ts) == 0:\n",
    "        return None\n",
    "\n",
    "    # Écarts temporels (timedelta64[ns]) -> ndarray robuste\n",
    "    diff = (avail_ts - target)\n",
    "    try:\n",
    "        deltas = diff.to_numpy()      # pandas >= 0.24+\n",
    "    except Exception:\n",
    "        deltas = np.asarray(diff)     # repli générique\n",
    "\n",
    "    # indice de l’écart absolu minimal\n",
    "    i_min = int(np.nanargmin(np.abs(deltas)))\n",
    "    return pd.Timestamp(avail_ts[i_min]).date()\n",
    "\n",
    "\n",
    "def pick_days_for_year(year: int, s30: pd.DataFrame) -> list:\n",
    "    \"\"\"Choisit 4 jours pour l'année donnée, au plus proche des jours cibles.\"\"\"\n",
    "    # s'assurer que date_utc est bien un 'date' (naïf)\n",
    "    date_utc = pd.to_datetime(s30[\"date_utc\"], errors=\"coerce\").dt.date\n",
    "    mask_year = pd.to_datetime(date_utc).dt.year == year\n",
    "\n",
    "    dates_year = pd.to_datetime(date_utc[mask_year], errors=\"coerce\").dropna().unique()\n",
    "    out = []\n",
    "    for m, d in DEFAULT_MONTH_DAY:\n",
    "        tgt = pd.Timestamp(year=year, month=m, day=d)        # <-- SANS tz\n",
    "        chosen = nearest_available_date(year, tgt, dates_year)\n",
    "        if chosen is not None:\n",
    "            out.append(chosen)\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- plot d'une année (2×2) ---\n",
    "def plot_year_grid(year: int, s30: pd.DataFrame, days: list[object] | None = None) -> Path | None:\n",
    "    # jours choisis\n",
    "    if not days:\n",
    "        days = pick_days_for_year(year, s30)\n",
    "    days = list(days)\n",
    "    if len(days) == 0:\n",
    "        print(f\"[INFO] {year}: pas de données.\")\n",
    "        return None\n",
    "    if len(days) < 4:\n",
    "        print(f\"[INFO] {year}: seulement {len(days)} jour(s) disponibles, la grille 2×2 sera partielle.\")\n",
    "\n",
    "    # figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 4), sharex=True, sharey=False, constrained_layout=False)\n",
    "    # pas d’espace vertical dans une même colonne\n",
    "    fig.subplots_adjust(hspace=0.0, wspace=0.12)\n",
    "\n",
    "    # styles\n",
    "    has_mean = VTEC_MEAN_COL in s30.columns\n",
    "    line_kw = dict(lw=1.6)\n",
    "    # boucler sur les 4 cases (row-major)\n",
    "    for k in range(4):\n",
    "        r, c = divmod(k, 2)\n",
    "        ax = axes[r, c]\n",
    "        if k >= len(days):\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "        day = days[k]\n",
    "        day0 = pd.Timestamp(day, tz=\"UTC\")\n",
    "        day1 = day0 + pd.Timedelta(days=1)\n",
    "\n",
    "        sd = s30.loc[(s30[\"date_utc\"] == day)].copy()\n",
    "        if sd.empty:\n",
    "            ax.text(0.5, 0.5, \"Pas de données\", transform=ax.transAxes, ha=\"center\", va=\"center\")\n",
    "            continue\n",
    "\n",
    "        # x = heures UT depuis minuit\n",
    "        hours = (sd[\"ts_utc\"] - day0).dt.total_seconds() / 3600.0\n",
    "\n",
    "        # tracés\n",
    "        if VTEC_MED_COL in sd.columns:\n",
    "            ax.plot(hours, sd[VTEC_MED_COL], label=\"VTEC median (30 min)\", **line_kw)\n",
    "        if has_mean:\n",
    "            ax.plot(hours, sd[VTEC_MEAN_COL], label=\"VTEC mean (30 min)\", ls=\"--\", **line_kw)\n",
    "        if GIM_COL in sd.columns:\n",
    "            ax.plot(hours, sd[GIM_COL], label=\"GIM (CODG) 30 min\", ls=\":\", **line_kw)\n",
    "\n",
    "        # offset du jour (CSV daily ou calcul direct)\n",
    "        off = get_daily_offset(day, sd)\n",
    "        off_txt = f\"median offset = {off:.2f} TECU\" if np.isfinite(off) else \"offset médian = n/a\"\n",
    "\n",
    "        # titres/labels\n",
    "        #ax.text(0.8, 0.09, f\"{day}  —  {off_txt}\", ha='center', fontsize=8, weight='bold')\n",
    "        ax.set_title(f\"{day}  —  {off_txt}\", fontsize=10, loc=\"center\", weight='bold')\n",
    "        ax.set_xlim(0, 24)\n",
    "        ax.set_yticks([5,15,25,35,45])\n",
    "        ax.grid(True, alpha=0.25)\n",
    "        # ticks heures pleines\n",
    "        #ax.set_xticks(np.arange(0, 25, 3))\n",
    "        ylim=(0,35)\n",
    "        ax.set_ylim(*ylim)\n",
    "        _set_xticks_30min(ax)\n",
    "        for t in ax.yaxis.get_ticklabels():\n",
    "            t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "        for t in ax.xaxis.get_ticklabels():\n",
    "            t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "        #if r == 0:\n",
    "        #    ax.legend(loc='upper left', fontsize=8, frameon=False)\n",
    "        #if r == 1:\n",
    "        #    ax.set_xlabel(\"Heures UT\")\n",
    "\n",
    "        #if c == 0:\n",
    "        #    ax.set_ylabel(\"VTEC (TECU)\")\n",
    "        # pas d'étiquette x sur la ligne du haut\n",
    "        #if r == 0:\n",
    "        #    ax.label_outer()\n",
    "\n",
    "    # légende commune (une seule fois)\n",
    "    handles, labels = [], []\n",
    "    for line in axes[0,0].lines:\n",
    "        handles.append(line)\n",
    "        labels.append(line.get_label())\n",
    "    plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    fig.legend(handles, labels, loc=\"upper center\", ncol=3, frameon=False, bbox_to_anchor=(0.5, 1))\n",
    "    fig.text(0.5, 1, f\"OUCA Observatory — VTEC 30 min vs GIM (année {year})\", ha='center', fontsize=12, weight='bold')\n",
    "    fig.text(0.5, 0.02, 'Local Time (LT)', ha='center', fontsize=12, weight='bold')\n",
    "    fig.text(0.08, 0.5, 'TEC [TECU]', va='center', rotation='vertical', fontsize=12, weight='bold')\n",
    "    out = FIG_DIR / f\"VTEC_GIM_daily_2x2_{year}.png\"\n",
    "    #fig.suptitle(f\"Observatoire d'Oukaimeden — VTEC 30 min vs GIM (année {year})\", y=1.08, fontsize=12)\n",
    "    fig.savefig(out, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Figure {year} → {out}\")\n",
    "    return out\n",
    "\n",
    "# --- exécution: toutes les années présentes dans le CSV 30 min ---\n",
    "years = sorted(\n",
    "    pd.to_datetime(s30[\"date_utc\"], errors=\"coerce\")\n",
    "      .dt.year.dropna().astype(int).unique()\n",
    ")\n",
    "\n",
    "for y in years:\n",
    "    plot_year_grid(y, s30)  # ou bien: plot_year_grid(y, s30, days=[date1, date2, date3, date4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc445f6-75fe-4f6b-9c2a-f1f54ea96d0f",
   "metadata": {},
   "source": [
    "Generate Observed VTEC and GIM for Quiet days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10a3e8-38e0-44de-844f-4148292984c3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# === Fenêtre demandée ===\n",
    "PERIOD_START = pd.Timestamp(\"2015-10-01\", tz=\"UTC\").date()\n",
    "PERIOD_END   = pd.Timestamp(\"2025-09-26\", tz=\"UTC\").date()\n",
    "\n",
    "FIG_DIR = Path(r\"C:\\Users\\mkmoh\\Dropbox\\1-DATA\\TEC_DATA\\New_Data\\figures\\figs_quiet\\MS_FIGURES_GIM\")\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _set_xticks_30min(ax):\n",
    "    ax.set_xlim(0, 24)\n",
    "    ax.set_xticks(np.arange(0, 24, 2))\n",
    "    ax.set_xticklabels([f\"{h:02d}\" for h in range(0, 24, 2)], rotation=0)\n",
    "    \n",
    "# --- Sécurité types ---\n",
    "s30[\"ts_utc\"]   = pd.to_datetime(s30[\"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "s30[\"date_utc\"] = pd.to_datetime(s30[\"date_utc\"], errors=\"coerce\").dt.date\n",
    "\n",
    "daily=_load_daily_csv(CSV_DAILY_WITH_OFF)\n",
    "daily[\"date_utc\"] = pd.to_datetime(daily[\"date_utc\"], errors=\"coerce\").dt.date\n",
    "VTEC_COL  = \"VTEC_median\"\n",
    "# --- Si vous avez une colonne de moyenne, on l'utilise (sinon elle sera ignorée dans la légende)\n",
    "#MEAN_CANDIDATES = [\"VTEC_mean\",\"VTEC_Mean\",\"VTEC_avg\",\"VTEC_average\",\"mean_VTEC\",\"VTECmean\"]\n",
    "MEAN_COL = \"VTEC_mean\"\n",
    "\n",
    "def get_daily_offset(day, s30_df, daily_df=None):\n",
    "    if daily_df is not None and \"gim_offset_tecu\" in daily_df.columns:\n",
    "        v = daily_df.loc[daily_df[\"date_utc\"] == day, \"gim_offset_tecu\"].dropna()\n",
    "        if len(v): return float(v.iloc[0])\n",
    "    df = s30_df.loc[s30_df[\"date_utc\"] == day, [VTEC_COL, \"vtec_gim\"]].dropna()\n",
    "    return float((df[VTEC_COL] - df[\"GIM_VTEC\"]).median()) if not df.empty else np.nan\n",
    "\n",
    "def daily_quiet_metrics(s30_df):\n",
    "    def _one(df):\n",
    "        v = pd.to_numeric(df[VTEC_COL], errors=\"coerce\")\n",
    "        g = pd.to_numeric(df[\"vtec_gim\"], errors=\"coerce\")\n",
    "        cov_v = v.notna().sum() / 48.0\n",
    "        cov_g = g.notna().sum() / 48.0\n",
    "        if v.notna().any():\n",
    "            q75 = np.nanpercentile(v, 75); q25 = np.nanpercentile(v, 25)\n",
    "            iqr = q75 - q25\n",
    "            std = np.nanstd(v)\n",
    "            vv = v.to_numpy()\n",
    "            dmed = np.nanmedian(np.abs(np.diff(vv))) if np.count_nonzero(~np.isnan(vv)) > 1 else np.nan\n",
    "        else:\n",
    "            iqr = std = dmed = np.nan\n",
    "        return pd.Series({\"cov_vtec\": cov_v, \"cov_gim\": cov_g, \"iqr\": iqr, \"std\": std, \"dV_med\": dmed})\n",
    "    m = s30_df.groupby(\"date_utc\", as_index=False).apply(_one).reset_index(drop=True)\n",
    "    return m\n",
    "\n",
    "def pick_10_quiet_days_geomagQ(s30_df, daily_df):\n",
    "    \"\"\"10 jours calmes en se basant sur daily.geomag_label == 'Q' + métriques VTEC.\"\"\"\n",
    "    if \"geomag_label_gfz_QDNQ\" not in daily_df.columns:\n",
    "        raise RuntimeError(\"La colonne 'geomag_label_gfz_QDNQ' est absente du CSV daily.\")\n",
    "    # restreindre période et normaliser label\n",
    "    d = daily_df.copy()\n",
    "    d = d[(d[\"date_utc\"] >= PERIOD_START) & (d[\"date_utc\"] <= PERIOD_END)].copy()\n",
    "    d[\"geomag_label_norm\"] = d[\"geomag_label_gfz_QDNQ\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # jours 'Q' (quiet)\n",
    "    q_days = d.loc[d[\"geomag_label_norm\"] == \"Q\", [\"date_utc\"]].dropna().drop_duplicates()\n",
    "\n",
    "    # métriques sur s30 dans la période\n",
    "    s = s30_df[(s30_df[\"date_utc\"] >= PERIOD_START) & (s30_df[\"date_utc\"] <= PERIOD_END)].copy()\n",
    "    metrics = daily_quiet_metrics(s)\n",
    "\n",
    "    # ne garder que les jours 'Q'\n",
    "    metQ = metrics.merge(q_days, on=\"date_utc\", how=\"inner\")\n",
    "\n",
    "    # qualité: couverture suffisante\n",
    "    metQ = metQ[(metQ[\"cov_vtec\"] >= 0.85) & (metQ[\"cov_gim\"] >= 0.70)].copy()\n",
    "\n",
    "    # trier par calme (iqr, puis |Δ| médian, puis std)\n",
    "    metQ = metQ.sort_values([\"iqr\", \"dV_med\", \"std\"], ascending=True)\n",
    "\n",
    "    days = list(metQ[\"date_utc\"].head(10))\n",
    "    if len(days) < 10:\n",
    "        print(f\"[INFO] Seulement {len(days)} jour(s) 'Q' éligible(s) dans la période (couverture/qualité).\")\n",
    "    return days\n",
    "\n",
    "def plot_quiet_days_5x2(days, s30_df, daily_df=None, title_suffix=\"jours Q (2015-10 → 2018-07)\"):\n",
    "    # complétion à 10 pour remplir la grille\n",
    "    days = list(days) + [None] * max(0, 10 - len(days))\n",
    "    fig, axes = plt.subplots(5, 2, figsize=(10, 10), sharex=True, sharey=False, constrained_layout=False)\n",
    "    handles_global = None\n",
    "    fig.subplots_adjust(hspace=0.0, wspace=0.12)\n",
    "    for k, day in enumerate(days):\n",
    "        r, c = divmod(k, 2)\n",
    "        ax = axes[r, c]\n",
    "        if day is None:\n",
    "            ax.axis(\"off\"); continue\n",
    "\n",
    "        df = s30_df.loc[s30_df[\"date_utc\"] == day].copy().sort_values(\"ts_utc\")\n",
    "        t_hours = df[\"ts_utc\"].dt.hour + df[\"ts_utc\"].dt.minute/60.0\n",
    "\n",
    "        ln1 = ax.plot(t_hours, df[VTEC_COL], lw=2, label=\"VTEC mediane\")[0]\n",
    "        if MEAN_COL is not None:\n",
    "            ln2 = ax.plot(t_hours, df[MEAN_COL], lw=1.8, ls=\"--\", label=\"VTEC mean\")[0]\n",
    "        ln3 = ax.plot(t_hours, df[\"vtec_gim\"], lw=1.8, ls=\"--\", label=\"VTEC GIM\")[0]\n",
    "\n",
    "        off = get_daily_offset(day, s30_df, daily_df)\n",
    "        off_txt = f\"offset median = {off:.2f} TECU\" if np.isfinite(off) else \"offset médian = n/a\"\n",
    "        ax.set_title(f\"{day} — {off_txt}\", fontsize=10, loc=\"center\", weight='bold',y=0.8)\n",
    "        #ax.set_title(str(y), fontweight='bold', )\n",
    "        ax.set_xlim(0, 24)\n",
    "        ax.grid(True, alpha=0.25)\n",
    "        # ticks heures pleines\n",
    "        #ax.set_xticks(np.arange(0, 25, 3))\n",
    "        ylim=(0,21)\n",
    "        ax.set_ylim(*ylim)\n",
    "        ax.set_yticks([5,10,15,20])\n",
    "        \n",
    "        _set_xticks_30min(ax)\n",
    "        for t in ax.yaxis.get_ticklabels():\n",
    "            t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "        for t in ax.xaxis.get_ticklabels():\n",
    "            t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "        \n",
    "        #if c == 0: ax.set_ylabel(\"VTEC (TECU)\")\n",
    "        #if r == 4: ax.set_xlabel(\"Heures UT\")\n",
    "        #else:      ax.label_outer()\n",
    "\n",
    "        if handles_global is None:\n",
    "            handles_global = [line for line in ax.lines]\n",
    "\n",
    "    if handles_global:\n",
    "        labels_global = [h.get_label() for h in handles_global]\n",
    "        fig.legend(handles_global, labels_global, loc=\"upper center\", ncol=3, frameon=False, bbox_to_anchor=(0.5, 0.93))\n",
    "\n",
    "    #fig.suptitle(f\"Observatoire d’Oukaimeden — 10 {title_suffix}\\nVTEC 30 min (médiane/moyenne) vs GIM\", y=1.04, fontsize=13)\n",
    "    plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    #fig.legend(handles, labels, loc=\"upper center\", ncol=3, frameon=False, bbox_to_anchor=(0.5, 1))\n",
    "    fig.text(0.5, 0.94, f\"OUCA Observatory — Quiet time VTEC vs GIM\", ha='center', fontsize=12, weight='bold')\n",
    "    fig.text(0.5, 0.06, 'Local Time (LT)', ha='center', fontsize=12, weight='bold')\n",
    "    fig.text(0.08, 0.5, 'TEC [TECU]', va='center', rotation='vertical', fontsize=12, weight='bold')\n",
    "    out = FIG_DIR / \"VTEC_GIM_10days_geomagQ_5x2_2015-2025.png\"\n",
    "    fig.savefig(out, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Figure sauvegardée → {out}\")\n",
    "    return out\n",
    "\n",
    "# === Sélection + tracé (basé UNIQUEMENT sur geomag_label == 'Q') ===\n",
    "quiet_days_Q = pick_10_quiet_days_geomagQ(s30, daily)\n",
    "print(\"Jours 'Q' sélectionnés:\", quiet_days_Q)\n",
    "plot_quiet_days_5x2(quiet_days_Q, s30, daily, title_suffix=\"jours géomagnétiquement calmes (label Q)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5997a5d-7c53-46bb-bce1-4de2bcccb001",
   "metadata": {},
   "source": [
    "Generate Final figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca4620-63e7-406d-90fb-032a786d5a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Union, List\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, date, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c7386-36b4-465e-92c2-95c1d51c6aef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 0 — SETUP & HELPERS\n",
    "# =========================\n",
    "# ------- Paramètres -------\n",
    "CSV = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/2015_2025_MS_VTEC_daily_stats_UTC_with_indices_and_max_with_GFZlabels.csv\")\n",
    "CSV_30MIN  = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/2015_2025_MS_VTEC_30min_stats.csv\")\n",
    "OUTDIR_FIG = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/figures/figs_quiet/\")\n",
    "TIME_COL   = \"date_utc\"\n",
    "OFFSET_COL = \"gim_offset_tecu\"\n",
    "QUIET_COL  = \"geomag_label_gfz_QDNQ\"      # 'Q','D','NQ'\n",
    "SOLAR_COL  = \"solar_label\"                # 'low','high'\n",
    "LOCAL_TZ = \"Africa/Casablanca\"   # pour les diurnes (affichage LT)\n",
    "VTEC_COL = \"VTEC_median\"         # colonne VTEC dans le CSV 30 min\n",
    "START      = pd.Timestamp(\"2015-10-01\", tz=\"UTC\")\n",
    "END        = pd.Timestamp(\"2025-09-26\", tz=\"UTC\")\n",
    "# -------------------------\n",
    "# ---- chargements (30 min) ----\n",
    "s30 = pd.read_csv(CSV_30MIN)\n",
    "t_utc = pd.to_datetime(s30[\"time\"], utc=True, errors=\"coerce\")\n",
    "s30 = s30.assign(\n",
    "    ts_utc=t_utc,\n",
    "    date_utc=t_utc.dt.floor(\"D\").dt.date,\n",
    "    slot=(t_utc.dt.hour*2 + (t_utc.dt.minute//30)).astype(int)  # 0..47\n",
    ")\n",
    "s30[VTEC_COL] = pd.to_numeric(s30[VTEC_COL], errors=\"coerce\")\n",
    "\n",
    "# Chargement + fenêtre temporelle\n",
    "df = pd.read_csv(CSV)\n",
    "df[TIME_COL] = pd.to_datetime(df[TIME_COL], utc=True, errors=\"coerce\")\n",
    "df = df[(df[TIME_COL] >= START) & (df[TIME_COL] <= END)].copy()\n",
    "\n",
    "# Masques\n",
    "m_off   = pd.to_numeric(df[OFFSET_COL], errors=\"coerce\").abs() < 20\n",
    "m_quiet = (df[QUIET_COL] == \"Q\")\n",
    "m_slow  = (df[SOLAR_COL].str.lower() == \"low\")\n",
    "\n",
    "# Année\n",
    "df[\"year\"] = df[TIME_COL].dt.year\n",
    "\n",
    "# --------- Récap global ---------\n",
    "N = len(df)\n",
    "summary_global = pd.DataFrame({\n",
    "    \"metric\": [\n",
    "        \"total\",\n",
    "        \"|offset|<20\",\n",
    "        \"quiet(Q)\",\n",
    "        \"solar_low\",\n",
    "        \"|offset|<20 ∩ quiet\",\n",
    "        \"|offset|<20 ∩ solar_low\",\n",
    "        \"quiet ∩ solar_low\",\n",
    "        \"offset ∩ quiet ∩ solar_low\",\n",
    "    ],\n",
    "    \"count\": [\n",
    "        N,\n",
    "        int(m_off.sum()),\n",
    "        int(m_quiet.sum()),\n",
    "        int(m_slow.sum()),\n",
    "        int((m_off & m_quiet).sum()),\n",
    "        int((m_off & m_slow).sum()),\n",
    "        int((m_quiet & m_slow).sum()),\n",
    "        int((m_off & m_quiet & m_slow).sum()),\n",
    "    ],\n",
    "})\n",
    "summary_global[\"pct_of_total_%\"] = (100 * summary_global[\"count\"] / N).round(2)\n",
    "print(\"=== Global (Oct 2015 → Sep 2025) ===\")\n",
    "print(summary_global.to_string(index=False))\n",
    "\n",
    "# --------- Par année: filtres simples ---------\n",
    "by_year_simple = (\n",
    "    df.assign(\n",
    "        off=m_off,\n",
    "        quiet=m_quiet,\n",
    "        solar_low=m_slow,\n",
    "    )\n",
    "    .groupby(\"year\")\n",
    "    .agg(\n",
    "        total=(\"year\",\"size\"),\n",
    "        off_sm20=(\"off\",\"sum\"),\n",
    "        quiet_Q=(\"quiet\",\"sum\"),\n",
    "        solar_low=(\"solar_low\",\"sum\"),\n",
    "    )\n",
    "    .assign(\n",
    "        pct_off=lambda d: (100*d[\"off_sm20\"]/d[\"total\"]).round(2),\n",
    "        pct_quiet=lambda d: (100*d[\"quiet_Q\"]/d[\"total\"]).round(2),\n",
    "        pct_slow=lambda d: (100*d[\"solar_low\"]/d[\"total\"]).round(2),\n",
    "    )\n",
    ")\n",
    "print(\"\\n=== Par année — filtres simples ===\")\n",
    "print(by_year_simple.to_string())\n",
    "\n",
    "# --------- Par année: intersections ---------\n",
    "by_year_inter = (\n",
    "    df.assign(\n",
    "        inter_off_quiet = (m_off & m_quiet),\n",
    "        inter_off_slow  = (m_off & m_slow),\n",
    "        inter_quiet_slow= (m_quiet & m_slow),\n",
    "        inter_all       = (m_off & m_quiet & m_slow),\n",
    "    )\n",
    "    .groupby(\"year\")\n",
    "    .agg(\n",
    "        total=(\"year\",\"size\"),\n",
    "        off_quiet=(\"inter_off_quiet\",\"sum\"),\n",
    "        off_slow=(\"inter_off_slow\",\"sum\"),\n",
    "        quiet_slow=(\"inter_quiet_slow\",\"sum\"),\n",
    "        all_three=(\"inter_all\",\"sum\"),\n",
    "    )\n",
    "    .assign(\n",
    "        pct_off_quiet=lambda d: (100*d[\"off_quiet\"]/d[\"total\"]).round(2),\n",
    "        pct_off_slow =lambda d: (100*d[\"off_slow\"]/d[\"total\"]).round(2),\n",
    "        pct_quiet_slow=lambda d:(100*d[\"quiet_slow\"]/d[\"total\"]).round(2),\n",
    "        pct_all_three=lambda d:(100*d[\"all_three\"]/d[\"total\"]).round(2),\n",
    "    )\n",
    ")\n",
    "print(\"\\n=== Par année — intersections ===\")\n",
    "print(by_year_inter.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee09d23-087a-42fd-97cb-9364f80b0182",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --------- (Option) Conserver uniquement l’intersection pour analyses suivantes ---------\n",
    "df_kept = df[m_off & m_quiet & m_slow].copy()\n",
    "print(f\"\\nLignes gardées (intersection trois filtres): {len(df_kept)}/{N}\")\n",
    "if \"date_utc\" in df_kept.columns:\n",
    "    d = pd.to_datetime(df_kept[\"date_utc\"], utc=True, errors=\"coerce\")\n",
    "else:\n",
    "    d = pd.to_datetime(df_kept[\"date\"], utc=True, errors=\"coerce\")\n",
    "df_kept[\"date_utc\"] = d.dt.floor(\"D\").dt.date\n",
    "\n",
    "S = s30[s30[\"date_utc\"].isin(df_kept['date_utc'])].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb4cb3-6bc1-4b58-91ea-9569c0b195a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ---- utilitaires ----\n",
    "def _set_xticks_30min(ax):\n",
    "    ax.set_xlim(0, 48)\n",
    "    ax.set_xticks(np.arange(0, 48, 8))\n",
    "    ax.set_xticklabels([f\"{h:02d}\" for h in range(0, 24, 4)], rotation=0)\n",
    "\n",
    "def _clean_slot(df, name=\"slot\"):\n",
    "    \"\"\"Enlève 'slot' de l'index s'il y est, et supprime les colonnes dupliquées.\"\"\"\n",
    "    out = df\n",
    "    if name in (out.index.names or []):\n",
    "        out = out.reset_index()\n",
    "    if out.columns.duplicated().any():\n",
    "        out = out.loc[:, ~out.columns.duplicated()]\n",
    "    return out\n",
    "\n",
    "def agg_diurnal(df, val=VTEC_COL):\n",
    "    \"\"\"Agrège sur les 48 slots (0..47) en imposant un axe de réindexage clair.\"\"\"\n",
    "    df = _clean_slot(df, \"slot\")\n",
    "    slots = pd.Index(range(48), name=\"slot\")\n",
    "    g = df.groupby(\"slot\")[val]\n",
    "    def _re(s): \n",
    "        s = s.copy()\n",
    "        s.index.name = \"slot\"\n",
    "        return s.reindex(slots)\n",
    "    out = pd.DataFrame({\n",
    "        \"slot\": slots.values,\n",
    "        \"median\": _re(g.median()),\n",
    "        \"mean\":   _re(g.mean()),\n",
    "        \"q25\":    _re(g.quantile(0.25)),\n",
    "        \"q75\":    _re(g.quantile(0.75)),\n",
    "        \"std\":    _re(g.std(ddof=1)),\n",
    "        \"N\":      _re(g.count())\n",
    "    }).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "def slot_ticks_2h(ax):\n",
    "    ax.set_xlim(-1, 48)\n",
    "    ax.set_xticks(np.arange(0,48,4))\n",
    "    ax.set_xticklabels([f\"{h:02d}\" for h in range(0,24,2)], rotation=0)\n",
    "\n",
    "def nice_y(ax, vmin=0, vmax=50, step=10):\n",
    "    ax.set_ylim(vmin, vmax)\n",
    "    ax.set_yticks(np.arange(vmin, vmax+step, step))\n",
    "\n",
    "row_colors = ['green','red','blue','orange','purple','brown']\n",
    "def _panel_color(idx):\n",
    "    r, _ = divmod(idx, 2)\n",
    "    return row_colors[r % len(row_colors)]\n",
    "\n",
    "print(f\"Quiet days retenus: {len(df_kept)} — échantillons 30min: {len(S)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6a6cd-ca7e-4ee7-a95a-2cbc66247730",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 1 — COURBES DIURNES PAR ANNÉE (4×2)\n",
    "# median + IQR (q25–q75) + mean — jours quiet\n",
    "# ==========================================\n",
    "years = sorted({pd.Timestamp(d).year for d in df_kept['date_utc']})\n",
    "n = len(years)\n",
    "rows, cols = (6, 2) if n > 6 else (int(np.ceil(n/2)), 2)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 2*rows), squeeze=False, sharex='col')\n",
    "ylim=(0,50)\n",
    "for i, y in enumerate(years):\n",
    "    ax = axes[i//2, i%2]\n",
    "    color = _panel_color(i)\n",
    "    Sy = S[pd.to_datetime(S[\"date_utc\"]).dt.year == y]\n",
    "    D = agg_diurnal(Sy)\n",
    "\n",
    "    ax.plot(D[\"slot\"].values, D[\"median\"].values, '-',color=color,  lw=2.2, label='median')\n",
    "    ax.fill_between(D[\"slot\"].values, D[\"q25\"].values, D[\"q75\"].values,color=color, alpha=0.2, label='IQR (25–75)')\n",
    "    ax.plot(D[\"slot\"].values, D[\"mean\"].values,   '--',color='k', lw=1.6, label='mean')\n",
    "\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yticks([5,15,25,35,45])\n",
    "    \n",
    "    label = str(y)\n",
    "    ax.set_ylabel(label, weight='bold')\n",
    "    \n",
    "    _set_xticks_30min(ax)\n",
    "    \n",
    "    #slot_ticks_2h(ax); nice_y(ax, 0, 45, 5)\n",
    "    ax.grid(alpha=0.3) \n",
    "    #ax.set_title(str(y), weight='bold')\n",
    "    # style ticks\n",
    "    for t in ax.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    for t in ax.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    if i == 0:\n",
    "        ax.legend(loc='upper left', fontsize=8, frameon=False)\n",
    "\n",
    "# nettoyer cases vides\n",
    "for j in range(n, rows*cols):\n",
    "    axes[j//2, j%2].axis('off')\n",
    "\n",
    "plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "fig.text(0.5, 0.89, f'Annualy Diurnal Quiet time VTEC', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.5, 0.06, 'Local Time (LT)', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.06, 0.5, 'TEC [TECU]', va='center', rotation='vertical', fontsize=12, weight='bold')\n",
    "\n",
    "out = OUTDIR_FIG / \"Low_solar_activity_QUIET_YEARS_diurnal_mean_median_IQR_MS.png\"\n",
    "#plt.show()\n",
    "fig.savefig(out, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7fb114-45fd-481e-a53b-8ad2f3e39ea2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 2 — COURBES DIURNES PAR MOIS (6×2)\n",
    "# median + IQR + mean sur tous jours quiet, toutes années\n",
    "# ==========================================\n",
    "ylim=(0,50)\n",
    "fig, axes = plt.subplots(6,2, figsize=(12,12), squeeze=False, sharex='col')\n",
    "for m in range(1,13):\n",
    "    ax = axes[(m-1)//2, (m-1)%2]\n",
    "    Sm = S[pd.to_datetime(S[\"date_utc\"]).dt.month == m]\n",
    "    D = agg_diurnal(Sm)\n",
    "    color = _panel_color(m-1)\n",
    "    ax.plot(D[\"slot\"], D[\"median\"], '-',color=color, lw=2.2, label='median')\n",
    "    ax.fill_between(D[\"slot\"], D[\"q25\"], D[\"q75\"],color=color, alpha=0.2, label='IQR')\n",
    "    ax.plot(D[\"slot\"], D[\"mean\"], '--',color='k', lw=1.6, label='mean')\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yticks([5,15,25,35,45])\n",
    "    \n",
    "    label = pd.Timestamp(2000, m, 1).strftime('%B')\n",
    "    ax.set_ylabel(label, weight='bold')\n",
    "    \n",
    "    _set_xticks_30min(ax)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_ylabel(pd.Timestamp(2000,m,1).strftime('%B'), weight='bold')\n",
    "    \n",
    "    # style ticks\n",
    "    for t in ax.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    for t in ax.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "        \n",
    "axes[0,0].legend(frameon=False, fontsize=9, loc='upper left')\n",
    "\n",
    "plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "fig.text(0.5, 0.89, f'Monthly Diurnal Quiet time VTEC', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.5, 0.06, 'Local Time (LT)', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.06, 0.5, 'TEC [TECU]', va='center', rotation='vertical', fontsize=12, weight='bold')\n",
    "\n",
    "#plt.show()\n",
    "out = OUTDIR_FIG/\"Low_solar_activity_QUIET_MONTHS_diurnal_mean_median_IQR_MS.png\"\n",
    "fig.savefig(out, dpi=300, bbox_inches='tight'); plt.close(fig)\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8e580-43b3-4dee-8b90-64a57ff9129b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL A — STATS CLÉS COURBES DIURNES PAR MOIS\n",
    "# (à partir de S et agg_diurnal)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _slot_to_lt_h(slot: int) -> float:\n",
    "    \"\"\"slot (0..47) -> heure locale en décimal (0.0–23.5).\"\"\"\n",
    "    return 0.5 * float(slot)\n",
    "\n",
    "def _slot_to_lt_str(slot: int) -> str:\n",
    "    \"\"\"slot (0..47) -> 'HH:MM'.\"\"\"\n",
    "    h_float = 0.5 * float(slot)\n",
    "    h = int(h_float)\n",
    "    m = int(round((h_float - h) * 60))\n",
    "    return f\"{h:02d}:{m:02d}\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "for m in range(1, 13):\n",
    "    Sm = S[pd.to_datetime(S[\"date_utc\"]).dt.month == m].copy()\n",
    "    if Sm.empty:\n",
    "        continue\n",
    "\n",
    "    D = agg_diurnal(Sm).copy()   # doit contenir au moins: 'slot', 'median'\n",
    "    D = D.dropna(subset=[\"median\"])\n",
    "    if D.empty:\n",
    "        continue\n",
    "\n",
    "    # pic diurne du mois (max de la médiane)\n",
    "    idx_max = D[\"median\"].idxmax()\n",
    "    peak_val = float(D.loc[idx_max, \"median\"])\n",
    "    peak_slot = int(D.loc[idx_max, \"slot\"])\n",
    "    peak_lt   = _slot_to_lt_str(peak_slot)\n",
    "\n",
    "    # minimum diurne (souvent pré-dawn / nuit)\n",
    "    idx_min = D[\"median\"].idxmin()\n",
    "    min_val = float(D.loc[idx_min, \"median\"])\n",
    "    min_slot = int(D.loc[idx_min, \"slot\"])\n",
    "    min_lt   = _slot_to_lt_str(min_slot)\n",
    "\n",
    "    # contraste jour/nuit (amplitude intra-journalière)\n",
    "    day_night_range = peak_val - min_val\n",
    "\n",
    "    # pour info: médiane dans un noyau pré-dawn (00–04 LT) et après-midi (12–18 LT)\n",
    "    D[\"lt_hour\"] = D[\"slot\"].apply(_slot_to_lt_h)\n",
    "    pre_dawn = D[(D[\"lt_hour\"] >= 0.0) & (D[\"lt_hour\"] < 4.0)]\n",
    "    afternoon = D[(D[\"lt_hour\"] >= 12.0) & (D[\"lt_hour\"] < 18.0)]\n",
    "\n",
    "    pre_dawn_med = float(pre_dawn[\"median\"].mean()) if not pre_dawn.empty else np.nan\n",
    "    aft_med      = float(afternoon[\"median\"].mean()) if not afternoon.empty else np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"month\": m,\n",
    "        \"month_name\": pd.Timestamp(2000, m, 1).strftime(\"%b\"),\n",
    "        \"peak_median_TECU\": peak_val,\n",
    "        \"lt_of_peak\": peak_lt,\n",
    "        \"min_median_TECU\": min_val,\n",
    "        \"lt_of_min\": min_lt,\n",
    "        \"day_night_range_TECU\": day_night_range,\n",
    "        \"pre_dawn_median_00_04_TECU\": pre_dawn_med,\n",
    "        \"afternoon_median_12_18_TECU\": aft_med,\n",
    "    })\n",
    "\n",
    "monthly_diurnal_stats = pd.DataFrame(rows).sort_values(\"month\")\n",
    "\n",
    "print(\"=== Monthly diurnal median VTEC stats (quiet QSL–GIM20) ===\")\n",
    "print(monthly_diurnal_stats.to_string(index=False,\n",
    "      float_format=lambda x: f\"{x:6.2f}\"))\n",
    "\n",
    "# Résumés rapides pour le texte\n",
    "print(\"\\n--- Key diagnostics for text ---\")\n",
    "# mois du pic maximal\n",
    "i_max = monthly_diurnal_stats[\"peak_median_TECU\"].idxmax()\n",
    "print(\"Largest monthly diurnal median peak:\",\n",
    "      f\"{monthly_diurnal_stats.loc[i_max, 'peak_median_TECU']:.2f} TECU\",\n",
    "      f\"in {monthly_diurnal_stats.loc[i_max, 'month_name']} at\",\n",
    "      monthly_diurnal_stats.loc[i_max, \"lt_of_peak\"])\n",
    "\n",
    "# mois du plus faible pic\n",
    "i_min = monthly_diurnal_stats[\"peak_median_TECU\"].idxmin()\n",
    "print(\"Smallest monthly diurnal median peak:\",\n",
    "      f\"{monthly_diurnal_stats.loc[i_min, 'peak_median_TECU']:.2f} TECU\",\n",
    "      f\"in {monthly_diurnal_stats.loc[i_min, 'month_name']} at\",\n",
    "      monthly_diurnal_stats.loc[i_min, \"lt_of_peak\"])\n",
    "\n",
    "# plage des heures de pic\n",
    "lt_peaks = monthly_diurnal_stats[\"lt_of_peak\"].tolist()\n",
    "print(\"Monthly peak times (LT) from\",\n",
    "      lt_peaks[0], \"to\", lt_peaks[-1],\n",
    "      \"for\", \", \".join(monthly_diurnal_stats['month_name'].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71491a82-689b-43bb-ac4d-b4a453173cc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 3 — COURBES DIURNES PAR SAISON (2×2)\n",
    "# median + IQR + mean — jours quiet\n",
    "# ==========================================\n",
    "def season_of_month(m):\n",
    "    return \"DJF\" if m in (12,1,2) else (\"MAM\" if m in (3,4,5) else (\"JJA\" if m in (6,7,8) else \"SON\"))\n",
    "\n",
    "S[\"season\"] = pd.to_datetime(S[\"date_utc\"]).dt.month.map(season_of_month)\n",
    "\n",
    "order = [\"DJF\",\"MAM\",\"JJA\",\"SON\"]\n",
    "fig, axes = plt.subplots(2,2, figsize=(12,5), squeeze=False, sharex='col')\n",
    "\n",
    "for i, sname in enumerate(order):\n",
    "    color = _panel_color(i)\n",
    "    ax = axes[i//2, i%2]\n",
    "    Ss = S[S[\"season\"]==sname]\n",
    "    D = agg_diurnal(Ss)\n",
    "    \n",
    "    ax.plot(D[\"slot\"], D[\"median\"], '-', color=color, lw=2.2, label='median')\n",
    "    ax.fill_between(D[\"slot\"], D[\"q25\"], D[\"q75\"],color=color, alpha=0.2, label='IQR')\n",
    "    ax.plot(D[\"slot\"], D[\"mean\"], '--',color='k', lw=1.6, label='mean')\n",
    "    \n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yticks([5,15,25,35,45])\n",
    "    \n",
    "    label = sname\n",
    "    ax.set_ylabel(label, weight='bold')\n",
    "    \n",
    "    _set_xticks_30min(ax)\n",
    "\n",
    "    # style ticks\n",
    "    for t in ax.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    for t in ax.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "        \n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "\n",
    "axes[0,0].legend(frameon=False, fontsize=9, loc='upper left')\n",
    "\n",
    "plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "fig.text(0.5, 0.89, f'Seasonal Diurnal Quiet time VTEC', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.5, 0.03, 'Local Time (LT)', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.06, 0.5, 'TEC [TECU]', va='center', rotation='vertical', fontsize=12, weight='bold')\n",
    "\n",
    "#plt.show()\n",
    "out = OUTDIR_FIG/\"Low_solar_activity_QUIET_SEASONS_diurnal_mean_median_IQR_MS.png\"\n",
    "fig.savefig(out, dpi=300, bbox_inches='tight'); plt.close(fig)\n",
    "print(\"Saved:\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c0ca6-b042-44c9-8148-a2dd7b866b9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL B — STATS CLÉS COURBES DIURNES PAR SAISON\n",
    "# (à partir de S, season_of_month et agg_diurnal)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _slot_to_lt_h(slot: int) -> float:\n",
    "    return 0.5 * float(slot)\n",
    "\n",
    "def _slot_to_lt_str(slot: int) -> str:\n",
    "    h_float = 0.5 * float(slot)\n",
    "    h = int(h_float)\n",
    "    m = int(round((h_float - h) * 60))\n",
    "    return f\"{h:02d}:{m:02d}\"\n",
    "\n",
    "def season_of_month(m):\n",
    "    return \"DJF\" if m in (12,1,2) else (\"MAM\" if m in (3,4,5)\n",
    "           else (\"JJA\" if m in (6,7,8) else \"SON\"))\n",
    "\n",
    "S = S.copy()\n",
    "S[\"month\"] = pd.to_datetime(S[\"date_utc\"]).dt.month\n",
    "S[\"season\"] = S[\"month\"].map(season_of_month)\n",
    "\n",
    "rows = []\n",
    "order = [\"DJF\",\"MAM\",\"JJA\",\"SON\"]\n",
    "\n",
    "for sname in order:\n",
    "    Ss = S[S[\"season\"] == sname].copy()\n",
    "    if Ss.empty:\n",
    "        continue\n",
    "\n",
    "    D = agg_diurnal(Ss).copy()\n",
    "    D = D.dropna(subset=[\"median\"])\n",
    "    if D.empty:\n",
    "        continue\n",
    "\n",
    "    # pic diurne saisonnier\n",
    "    idx_max = D[\"median\"].idxmax()\n",
    "    peak_val = float(D.loc[idx_max, \"median\"])\n",
    "    peak_slot = int(D.loc[idx_max, \"slot\"])\n",
    "    peak_lt   = _slot_to_lt_str(peak_slot)\n",
    "\n",
    "    # minimum saisonnier\n",
    "    idx_min = D[\"median\"].idxmin()\n",
    "    min_val = float(D.loc[idx_min, \"median\"])\n",
    "    min_slot = int(D.loc[idx_min, \"slot\"])\n",
    "    min_lt   = _slot_to_lt_str(min_slot)\n",
    "\n",
    "    day_night_range = peak_val - min_val\n",
    "\n",
    "    D[\"lt_hour\"] = D[\"slot\"].apply(_slot_to_lt_h)\n",
    "    pre_dawn = D[(D[\"lt_hour\"] >= 0.0) & (D[\"lt_hour\"] < 4.0)]\n",
    "    afternoon = D[(D[\"lt_hour\"] >= 12.0) & (D[\"lt_hour\"] < 18.0)]\n",
    "\n",
    "    pre_dawn_med = float(pre_dawn[\"median\"].mean()) if not pre_dawn.empty else np.nan\n",
    "    aft_med      = float(afternoon[\"median\"].mean()) if not afternoon.empty else np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"season\": sname,\n",
    "        \"peak_median_TECU\": peak_val,\n",
    "        \"lt_of_peak\": peak_lt,\n",
    "        \"min_median_TECU\": min_val,\n",
    "        \"lt_of_min\": min_lt,\n",
    "        \"day_night_range_TECU\": day_night_range,\n",
    "        \"pre_dawn_median_00_04_TECU\": pre_dawn_med,\n",
    "        \"afternoon_median_12_18_TECU\": aft_med,\n",
    "    })\n",
    "\n",
    "seasonal_diurnal_stats = pd.DataFrame(rows).set_index(\"season\").loc[order].reset_index()\n",
    "\n",
    "print(\"=== Seasonal diurnal median VTEC stats (quiet QSL–GIM20) ===\")\n",
    "print(seasonal_diurnal_stats.to_string(index=False,\n",
    "      float_format=lambda x: f\"{x:6.2f}\"))\n",
    "\n",
    "print(\"\\n--- Key diagnostics for text ---\")\n",
    "for _, r in seasonal_diurnal_stats.iterrows():\n",
    "    print(f\"{r['season']}: peak median ≈ {r['peak_median_TECU']:.2f} TECU at {r['lt_of_peak']} LT; \"\n",
    "          f\"night min ≈ {r['min_median_TECU']:.2f} TECU at {r['lt_of_min']} LT; \"\n",
    "          f\"day–night range ≈ {r['day_night_range_TECU']:.2f} TECU; \"\n",
    "          f\"pre-dawn (00–04 LT) median ≈ {r['pre_dawn_median_00_04_TECU']:.2f} TECU; \"\n",
    "          f\"afternoon (12–18 LT) median ≈ {r['afternoon_median_12_18_TECU']:.2f} TECU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b48b3-4bc7-4a40-b847-acaaa4f74294",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 4 — HEURE DU MAX QUOTIDIEN (HISTOGRAMME, LT)\n",
    "# ==========================================\n",
    "# pour chaque jour quiet : slot du max (si plusieurs, dernier)\n",
    "idx = S.groupby(\"date_utc\")[VTEC_COL].idxmax()\n",
    "daily_max = S.loc[idx, [\"date_utc\",\"slot\",VTEC_COL]].sort_values(\"date_utc\")\n",
    "# convertir slot en heure locale (LT) lisible\n",
    "hours = daily_max[\"slot\"]/2.0  # 0..23.5\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.hist(hours, bins=np.arange(-0.25,24.75,0.5), edgecolor='k', alpha=0.7)\n",
    "def _set_xticks_30min(ax):\n",
    "    ax.set_xlim(-1, 24)\n",
    "    ax.set_xticks(np.arange(0, 24, 4))\n",
    "    ax.set_xticklabels([f\"{h:02d}\" for h in range(0, 24, 4)], rotation=0)\n",
    "#label = sname\n",
    "ax.set_ylabel(\"Count of days\", weight='bold')\n",
    "    \n",
    "_set_xticks_30min(ax)\n",
    "# style ticks\n",
    "for t in ax.yaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "for t in ax.xaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    \n",
    "ax.grid(alpha=0.3)\n",
    "#ax.set_xticks(np.arange(0,24,2)); ax.set_xticklabels([f\"{h:02d}:00\" for h in range(0,24,2)])\n",
    "#ax.set_xlim(-0.5, 23.5); ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_title(\"Distribution of Local-Time of the Daily VTEC Maximum on Quiet Days\", weight='bold')\n",
    "ax.set_xlabel(\"Local Time (LT)\", weight='bold');\n",
    "#plt.show()\n",
    "out = OUTDIR_FIG/\"Low_solar_activity_QUIET_hist_hour_of_daily_max_LT_MS.png\"\n",
    "fig.savefig(out, dpi=300); plt.close(fig)\n",
    "print(\"Saved:\", out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf182c6-03bc-4350-b424-719937ac878f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pytz\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "LOCAL_TZ = \"Africa/Casablanca\"\n",
    "VTEC_MAX_COL = \"VTEC_max\"  # amplitude du max sur la grille 30 min\n",
    "TIME_COL_UTC = \"max_ts_utc\"           # timestamp du max en UTC (tz-aware)\n",
    "OUT_FIG = Path(r\"C:\\Users\\mkmoh\\Dropbox\\1-DATA\\TEC_DATA\\New_Data\\figures\\figs_quiet\\TEC09_Low_solar_activity_QUIET_hist_hour_of_daily_max_LT_MS.png\")\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "def hist_fwhm(centers, counts):\n",
    "    \"\"\"\n",
    "    Approximation simple de la FWHM (full width at half-maximum) pour un histogramme:\n",
    "    distance entre le premier et le dernier centre dont la hauteur >= half-max.\n",
    "    \"\"\"\n",
    "    counts = np.asarray(counts, float)\n",
    "    centers = np.asarray(centers, float)\n",
    "    if counts.size == 0:\n",
    "        return np.nan\n",
    "    peak = counts.max()\n",
    "    if peak <= 0:\n",
    "        return np.nan\n",
    "    half = peak / 2.0\n",
    "    mask = counts >= half\n",
    "    if not np.any(mask):\n",
    "        return np.nan\n",
    "    xs = centers[mask]\n",
    "    if xs.size == 1:\n",
    "        return 0.0\n",
    "    return xs[-1] - xs[0]\n",
    "\n",
    "\n",
    "# ====== PRÉPARATION DU DATAFRAME ======\n",
    "df_daily = df_kept.copy()\n",
    "\n",
    "# s'assurer que max_ts_utc est bien en datetime UTC\n",
    "df_daily[TIME_COL_UTC] = pd.to_datetime(df_daily[TIME_COL_UTC], utc=True, errors=\"coerce\")\n",
    "tz = pytz.timezone(LOCAL_TZ)\n",
    "\n",
    "df_daily[\"max_ts_lt\"] = df_daily[TIME_COL_UTC].dt.tz_convert(tz)\n",
    "df_daily[\"max_hour_lt\"] = df_daily[\"max_ts_lt\"].dt.hour + df_daily[\"max_ts_lt\"].dt.minute/60.0\n",
    "df_daily[\"month\"] = df_daily[\"max_ts_lt\"].dt.month\n",
    "df_daily[\"doy\"] = df_daily[\"max_ts_lt\"].dt.dayofyear  # si tu veux DOY plus tard\n",
    "\n",
    "# filtrage NaN de base\n",
    "df_daily = df_daily[np.isfinite(df_daily[\"max_hour_lt\"]) & np.isfinite(df_daily[VTEC_MAX_COL])].copy()\n",
    "\n",
    "if df_daily.empty:\n",
    "    print(\"df_daily est vide après filtrage.\")\n",
    "else:\n",
    "    # ====== FIGURE 3 PANNEAUX ======\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(\n",
    "        3, 1, figsize=(10, 9),\n",
    "        gridspec_kw={\"height_ratios\": [2.0, 1.3, 1.3]}\n",
    "    )\n",
    "\n",
    "    # ---------- 1) HISTOGRAMME HEURE LOCALE DU MAX ----------\n",
    "    h = df_daily[\"max_hour_lt\"].values\n",
    "\n",
    "    # bins 30 min entre 0 et 24h\n",
    "    bins = np.arange(0.0, 24.0 + 0.5, 0.5)\n",
    "    counts, bin_edges, patches = ax1.hist(\n",
    "        h, bins=bins, edgecolor=\"black\", alpha=0.7,\n",
    "        label=\"Daily max count\"\n",
    "    )\n",
    "    centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "    # courbe reliant les sommets\n",
    "    ax1.plot(centers, counts, \"-o\", linewidth=1.5, markersize=4,\n",
    "             label=\"Bin-top curve\")\n",
    "\n",
    "    # stats: mode, FWHM, amplitude du pic\n",
    "    if counts.sum() > 0:\n",
    "        idx_peak = int(np.argmax(counts))\n",
    "        mode_hour = centers[idx_peak]\n",
    "        mode_hour = centers[idx_peak]\n",
    "        median_hour = df_daily[\"max_hour_lt\"].median()\n",
    "        peak_amp = int(counts[idx_peak])\n",
    "        fwhm = hist_fwhm(centers, counts)\n",
    "\n",
    "        print(f\"Mode ≈ {mode_hour:.2f} LT, median ≈ {median_hour:.2f} LT, FWHM ≈ {fwhm:.2f} h, peak = {peak_amp} days.\")\n",
    "\n",
    "        stats_label = (\n",
    "            f\"Mode ≈ {mode_hour:4.1f} h LT, \"\n",
    "            f\"FWHM ≈ {fwhm:3.1f} h, \"\n",
    "            f\"peak = {peak_amp} days\"\n",
    "        )\n",
    "        ax1.legend(title=stats_label, loc=\"upper left\", fontsize=10)\n",
    "    else:\n",
    "        ax1.legend(loc=\"upper left\", fontsize=9)\n",
    "\n",
    "    ax1.set_xlim(0, 24)\n",
    "    ax1.set_xticks(np.arange(0, 25, 2))\n",
    "    ax1.set_ylabel(\"Number of days\", weight=\"bold\")\n",
    "    ax1.set_xlabel(\"Local Time (LT)\", weight=\"bold\")\n",
    "    ax1.set_title(\"Local time of daily VTEC maximum (QSL–GIM20)\", weight=\"bold\")\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    for t in ax1.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color(\"black\"); t.set_weight(\"bold\")\n",
    "    for t in ax1.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color(\"black\"); t.set_weight(\"bold\")\n",
    "\n",
    "    # ---------- 2) SCATTER AMPLITUDE DU MAX VS MOIS ----------\n",
    "    x_month = df_daily[\"month\"].values\n",
    "    y_vtec = df_daily[VTEC_MAX_COL].values\n",
    "\n",
    "    ax2.scatter(x_month, y_vtec, color='k', alpha=0.4, s=15,\n",
    "                label=\"Daily maxima\")\n",
    "\n",
    "    # médiane mensuelle pour tendance saisonnière\n",
    "    month_median_vtec = (df_daily\n",
    "                         .groupby(\"month\")[VTEC_MAX_COL]\n",
    "                         .median()\n",
    "                         .reindex(np.arange(1, 13)))\n",
    "\n",
    "    ax2.plot(np.arange(1, 13), month_median_vtec.values, \"-o\",\n",
    "             linewidth=2, label=\"Monthly median max\")\n",
    "\n",
    "    ax2.set_xlim(0.5, 12.5)\n",
    "    ax2.set_xticks(np.arange(1, 13))\n",
    "    ax2.set_xticklabels([\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\n",
    "                         \"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"])\n",
    "    ax2.set_ylabel(\"Daily max VTEC [TECU]\", weight=\"bold\")\n",
    "    ax2.set_xlabel(\"Month of year\", weight=\"bold\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend(loc=\"upper center\", fontsize=9)\n",
    "\n",
    "    for t in ax2.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color(\"black\"); t.set_weight(\"bold\")\n",
    "    for t in ax2.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color(\"black\"); t.set_weight(\"bold\")\n",
    "\n",
    "    # ---------- 3) SCATTER HEURE DU MAX VS MOIS ----------\n",
    "    y_hour = df_daily[\"max_hour_lt\"].values\n",
    "\n",
    "    ax3.scatter(x_month, y_hour, color='k', alpha=0.4, s=15,\n",
    "                label=\"Daily peak time\")\n",
    "\n",
    "    # médiane mensuelle de l'heure du max\n",
    "    month_median_hour = (df_daily\n",
    "                         .groupby(\"month\")[\"max_hour_lt\"]\n",
    "                         .median()\n",
    "                         .reindex(np.arange(1, 13)))\n",
    "\n",
    "    ax3.plot(np.arange(1, 13), month_median_hour.values, \"-o\",\n",
    "             linewidth=2, label=\"Monthly median time\")\n",
    "\n",
    "    ax3.set_xlim(0.5, 12.5)\n",
    "    ax3.set_xticks(np.arange(1, 13))\n",
    "    ax3.set_xticklabels([\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\n",
    "                         \"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"])\n",
    "    ax3.set_xlabel(\"Month of year\", weight=\"bold\")\n",
    "    ax3.set_ylabel(\"Local time \\n of daily max [LT]\", weight=\"bold\")\n",
    "    ax3.set_ylim(0, 24)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend(loc=\"lower center\", fontsize=9)\n",
    "\n",
    "    for t in ax3.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color(\"black\"); t.set_weight(\"bold\")\n",
    "    for t in ax3.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color(\"black\"); t.set_weight(\"bold\")\n",
    "\n",
    "    fig.savefig(OUT_FIG, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", OUT_FIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f0de0-cabd-4ad4-a2ea-91adf5353ad4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# seasonal peak hour variability\n",
    "df_season = df_daily.copy()\n",
    "df_season[\"month\"] = df_season[\"max_ts_lt\"].dt.month\n",
    "\n",
    "def month_to_season(m):\n",
    "    if m in (12, 1, 2):\n",
    "        return \"DJF\"\n",
    "    elif m in (3, 4, 5):\n",
    "        return \"MAM\"\n",
    "    elif m in (6, 7, 8):\n",
    "        return \"JJA\"\n",
    "    else:\n",
    "        return \"SON\"\n",
    "\n",
    "df_season[\"season\"] = df_season[\"month\"].apply(month_to_season)\n",
    "\n",
    "# Median and IQR of peak time per season\n",
    "def iqr(x):\n",
    "    x = np.asarray(x, float)\n",
    "    return np.nanpercentile(x, 75) - np.nanpercentile(x, 25)\n",
    "\n",
    "season_stats = (df_season\n",
    "                .groupby(\"season\")[\"max_hour_lt\"]\n",
    "                .agg([\"count\", \"median\", iqr])\n",
    "                .reset_index())\n",
    "print(season_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2189dd-2fbe-43ac-ac65-7060910e842c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Amplitude of daily peak variability\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --------- CONFIG ---------\n",
    "VTEC_MAX_COL = \"VTEC_max_from_30min\"   # amplitude quotidienne du max\n",
    "TIME_COL_UTC = \"max_ts_utc\"           # timestamp du max en UTC\n",
    "# ---------------------------\n",
    "\n",
    "df_daily = df_kept.copy()\n",
    "\n",
    "# Assurer types corrects\n",
    "df_daily[VTEC_MAX_COL] = pd.to_numeric(df_daily[VTEC_MAX_COL], errors=\"coerce\")\n",
    "df_daily[TIME_COL_UTC] = pd.to_datetime(df_daily[TIME_COL_UTC], utc=True, errors=\"coerce\")\n",
    "\n",
    "# Derive month if not present\n",
    "if \"month\" not in df_daily.columns:\n",
    "    df_daily[\"month\"] = df_daily[TIME_COL_UTC].dt.month\n",
    "\n",
    "# Filtrer les NaN\n",
    "df_daily = df_daily[np.isfinite(df_daily[VTEC_MAX_COL])].copy()\n",
    "if df_daily.empty:\n",
    "    print(\"df_daily is empty after filtering.\")\n",
    "else:\n",
    "    # ----- 1) Range global des maxima quotidiens -----\n",
    "    vtec_min = df_daily[VTEC_MAX_COL].min()\n",
    "    vtec_max = df_daily[VTEC_MAX_COL].max()\n",
    "    vtec_p05 = np.nanpercentile(df_daily[VTEC_MAX_COL], 5)\n",
    "    vtec_p95 = np.nanpercentile(df_daily[VTEC_MAX_COL], 95)\n",
    "\n",
    "    print(\"Global daily peak VTEC range:\")\n",
    "    print(f\"  min        = {vtec_min:.2f} TECU\")\n",
    "    print(f\"  max        = {vtec_max:.2f} TECU\")\n",
    "    print(f\"  5th perc   = {vtec_p05:.2f} TECU  (robust lower bound)\")\n",
    "    print(f\"  95th perc  = {vtec_p95:.2f} TECU  (robust upper bound)\")\n",
    "    print(\"\")\n",
    "\n",
    "    # ----- 2) Médianes mensuelles des maxima -----\n",
    "    month_median = (df_daily\n",
    "                    .groupby(\"month\")[VTEC_MAX_COL]\n",
    "                    .median()\n",
    "                    .reindex(np.arange(1,13)))\n",
    "    month_count = (df_daily\n",
    "                   .groupby(\"month\")[VTEC_MAX_COL]\n",
    "                   .count()\n",
    "                   .reindex(np.arange(1,13)))\n",
    "\n",
    "    month_stats = pd.DataFrame({\n",
    "        \"month\": np.arange(1,13),\n",
    "        \"n_days\": month_count.values,\n",
    "        \"median_VTEC_max\": month_median.values\n",
    "    })\n",
    "\n",
    "    month_name = {\n",
    "        1:\"Jan\", 2:\"Feb\", 3:\"Mar\", 4:\"Apr\", 5:\"May\", 6:\"Jun\",\n",
    "        7:\"Jul\", 8:\"Aug\", 9:\"Sep\", 10:\"Oct\", 11:\"Nov\", 12:\"Dec\"\n",
    "    }\n",
    "    month_stats[\"name\"] = month_stats[\"month\"].map(month_name)\n",
    "\n",
    "    print(\"Monthly median of daily VTEC maxima:\")\n",
    "    print(month_stats.to_string(index=False, float_format=lambda x: f\"{x:6.2f}\"))\n",
    "    print(\"\")\n",
    "\n",
    "    # ----- 3) Mois / saisons de plus grands et plus faibles maxima -----\n",
    "\n",
    "    # Mois de plus grands maxima (sur toute l'année)\n",
    "    idx_max = month_median.idxmax()\n",
    "    vtec_equinox_summer = month_median.max()\n",
    "    print(f\"Largest monthly median peak VTEC:\")\n",
    "    print(f\"  month = {idx_max} ({month_name[idx_max]}), median = {vtec_equinox_summer:.2f} TECU\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Hiver : DJF (12,1,2) -> min de la médiane parmi ces mois\n",
    "    winter_months = [12, 1, 2]\n",
    "    winter_medians = month_median.loc[winter_months].dropna()\n",
    "    if not winter_medians.empty:\n",
    "        w_idx_min = winter_medians.idxmin()\n",
    "        vtec_winter = winter_medians.min()\n",
    "        print(\"Winter (DJF) monthly median peaks:\")\n",
    "        for m in winter_months:\n",
    "            if not np.isnan(month_median.loc[m]):\n",
    "                print(f\"  {m:2d} ({month_name[m]}): median = {month_median.loc[m]:.2f} TECU\")\n",
    "        print(f\"Lowest winter median peak VTEC:\")\n",
    "        print(f\"  month = {w_idx_min} ({month_name[w_idx_min]}), median = {vtec_winter:.2f} TECU\")\n",
    "    else:\n",
    "        print(\"No data for winter months (DJF) in monthly medians.\")\n",
    "\n",
    "    # ----- 4) Résumé prêt pour le paragraphe -----\n",
    "    print(\"\\n--- Summary for LaTeX paragraph ---\")\n",
    "    print(f\"Use VTEC_min ≈ {vtec_p05:.1f} TECU and VTEC_max ≈ {vtec_p95:.1f} TECU as a robust daily peak range.\")\n",
    "    print(f\"Use VTEC_equinox/summer ≈ {vtec_equinox_summer:.1f} TECU in {month_name[idx_max]} (month of largest median peak).\")\n",
    "    if not winter_medians.empty:\n",
    "        print(f\"Use VTEC_winter ≈ {vtec_winter:.1f} TECU in {month_name[w_idx_min]} for the lowest winter median.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7186c81-4e8a-4a3f-9542-17481b313488",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 6b — BOXplots par heure locale (bins de 2 h) — jours quiet QSL–GIM20\n",
    "# Style harmonisé avec les boxplots mensuels/saisonniers\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# On part de S (30 min, déjà filtré QSL–GIM20) et de VTEC_COL\n",
    "S_hour = S.copy()\n",
    "\n",
    "# Bin 2 h basé sur les slots 30 min (0..47) → 0,2,4,...,22\n",
    "S_hour[\"hour2\"] = (S_hour[\"slot\"] // 4) * 2\n",
    "\n",
    "hours2 = np.arange(0, 24, 2)  # 0,2,...,22\n",
    "\n",
    "# Données pour chaque bin 2 h\n",
    "data_h = [S_hour.loc[S_hour[\"hour2\"] == h, VTEC_COL].dropna().to_numpy()\n",
    "          for h in hours2]\n",
    "has_data = [len(v) > 0 for v in data_h]\n",
    "\n",
    "# Moyenne par bin 2 h (pour la courbe noire)\n",
    "mh = (S_hour.groupby(\"hour2\", as_index=False)[VTEC_COL]\n",
    "          .mean()\n",
    "          .set_index(\"hour2\")\n",
    "          .reindex(hours2))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "\n",
    "# Positions des boîtes : 1..N\n",
    "pos  = [i + 1 for i, ok in enumerate(has_data) if ok]\n",
    "dat  = [v for v, ok in zip(data_h, has_data) if ok]\n",
    "labs = [h for h, ok in zip(hours2, has_data) if ok]\n",
    "\n",
    "if dat:\n",
    "    ax.boxplot(\n",
    "        dat,\n",
    "        positions=pos,\n",
    "        patch_artist=True,\n",
    "        showmeans=True,\n",
    "        whis=(5, 95),\n",
    "        meanprops=dict(marker='D', markersize=4,\n",
    "                       markerfacecolor='black', markeredgecolor='white'),\n",
    "        boxprops=dict(facecolor='#c7e9ff', edgecolor='#1f4d7a', linewidth=1.2),\n",
    "        medianprops=dict(color='crimson', linewidth=1.8),\n",
    "        whiskerprops=dict(color='#1f4d7a', linewidth=1.0, linestyle='--'),\n",
    "        capprops=dict(color='#1f4d7a', linewidth=1.0),\n",
    "        flierprops=dict(marker='x', markersize=3,\n",
    "                        markeredgecolor='gray', markerfacecolor='none', alpha=0.5),\n",
    "    )\n",
    "\n",
    "# Courbe des moyennes (alignée sur les centres des boîtes)\n",
    "ax.plot(\n",
    "    np.arange(1, len(hours2) + 1),\n",
    "    mh[VTEC_COL].to_numpy(),\n",
    "    color=\"black\", marker=\"o\", linewidth=2, markersize=5,\n",
    "    label=\"Mean\"\n",
    ")\n",
    "\n",
    "# Ticks et style\n",
    "ax.set_xlim(0.5, len(hours2) + 0.5)\n",
    "ax.set_xticks(np.arange(1, len(hours2) + 1))\n",
    "ax.set_xticklabels([f\"{h:02d}\" for h in hours2])\n",
    "\n",
    "for tick in ax.yaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12); tick.set_color('black'); tick.set_weight('bold')\n",
    "for tick in ax.xaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12); tick.set_color('black'); tick.set_weight('bold')\n",
    "\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(frameon=False, loc=\"upper left\")\n",
    "\n",
    "# Titres et labels comme pour les figures mensuelles/saisonnières\n",
    "fig.text(0.5, 0.92,\n",
    "         \"Quiet days VTEC distribution by 2 h local-time bins\",\n",
    "         ha=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "fig.text(0.5, 0.01,\n",
    "         \"Local time LT\", ha=\"center\",\n",
    "         fontsize=12, fontweight=\"bold\")\n",
    "fig.text(0.04, 0.5,\n",
    "         \"TEC [TECU]\", va=\"center\", rotation=\"vertical\",\n",
    "         fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "out = OUTDIR_FIG / \"TEC08_Low_solar_activity_QUIET_boxplot_by_2h_MS.png\"\n",
    "fig.savefig(out, dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bdaa38-7eae-4d2e-bfa2-18b9d391a997",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "# -------- CONFIG --------\n",
    "TIME_COL = \"time\"           # 30-min UTC timestamp column\n",
    "VTEC_COL = \"VTEC_median\"    # 30-min VTEC\n",
    "QUIET_FLAG = False # optional\n",
    "LOCAL_TZ = \"Africa/Casablanca\"\n",
    "# ------------------------\n",
    "\n",
    "# Start from your 30-min climatology dataframe\n",
    "df = S.copy()   # <-- replace S_30 by your actual df name (e.g., S or df_kept_30min)\n",
    "\n",
    "# Keep only QSL--GIM20 days if the flag exists\n",
    "if QUIET_FLAG in df.columns:\n",
    "    df = df[df[QUIET_FLAG] == True].copy()\n",
    "\n",
    "# Parse time and convert to local time\n",
    "df[TIME_COL] = pd.to_datetime(df[TIME_COL], utc=True, errors=\"coerce\")\n",
    "tz = pytz.timezone(LOCAL_TZ)\n",
    "df[\"ts_lt\"] = df[TIME_COL].dt.tz_convert(tz)\n",
    "\n",
    "# Local hour (float)\n",
    "df[\"lt_hour\"] = df[\"ts_lt\"].dt.hour + df[\"ts_lt\"].dt.minute / 60.0\n",
    "\n",
    "# Define 2h-bin start: 0,2,4,...,22\n",
    "df[\"lt_bin_start\"] = (2 * np.floor(df[\"lt_hour\"] / 2)).astype(int)\n",
    "df.loc[df[\"lt_bin_start\"] == 24, \"lt_bin_start\"] = 22  # safety, should not happen\n",
    "\n",
    "# Drop NaNs\n",
    "df = df[np.isfinite(df[VTEC_COL]) & np.isfinite(df[\"lt_bin_start\"])].copy()\n",
    "\n",
    "# Aggregate by 2h bin\n",
    "def iqr(x):\n",
    "    x = np.asarray(x, float)\n",
    "    return np.nanpercentile(x, 75) - np.nanpercentile(x, 25)\n",
    "\n",
    "stats = (df\n",
    "         .groupby(\"lt_bin_start\")[VTEC_COL]\n",
    "         .agg(count=\"count\",\n",
    "              median=\"median\",\n",
    "              iqr=iqr)\n",
    "         .reset_index()\n",
    "         .sort_values(\"lt_bin_start\"))\n",
    "\n",
    "# Add string labels like \"00-02\", \"02-04\", ...\n",
    "def bin_label(h):\n",
    "    return f\"{h:02d}–{(h+2)%24:02d}\"\n",
    "\n",
    "stats[\"LT_bin\"] = stats[\"lt_bin_start\"].apply(bin_label)\n",
    "\n",
    "print(\"VTEC distribution by 2-hour local-time bins (QSL--GIM20):\")\n",
    "print(stats[[\"LT_bin\",\"count\",\"median\",\"iqr\"]]\n",
    "      .to_string(index=False, float_format=lambda x: f\"{x:6.2f}\"))\n",
    "\n",
    "# Extract some key bins for the text:\n",
    "def get_bin_value(h_start):\n",
    "    row = stats.loc[stats[\"lt_bin_start\"] == h_start]\n",
    "    if row.empty:\n",
    "        return np.nan, np.nan\n",
    "    return float(row[\"median\"].iloc[0]), float(row[\"iqr\"].iloc[0])\n",
    "\n",
    "# Example bins:\n",
    "med_06_08, iqr_06_08 = get_bin_value(6)   # 06–08 LT\n",
    "med_14_16, iqr_14_16 = get_bin_value(14)  # 14–16 LT\n",
    "med_00_02, iqr_00_02 = get_bin_value(0)   # 00–02 LT (night)\n",
    "med_02_04, iqr_02_04 = get_bin_value(2)   # 02–04 LT (night)\n",
    "\n",
    "print(\"\\n--- Key values for text ---\")\n",
    "print(f\"Median VTEC 06–08 LT  ≈ {med_06_08:.2f} TECU (IQR ≈ {iqr_06_08:.2f} TECU)\")\n",
    "print(f\"Median VTEC 14–16 LT  ≈ {med_14_16:.2f} TECU (IQR ≈ {iqr_14_16:.2f} TECU)\")\n",
    "print(f\"Median VTEC 00–02 LT  ≈ {med_00_02:.2f} TECU (IQR ≈ {iqr_00_02:.2f} TECU)\")\n",
    "print(f\"Median VTEC 02–04 LT  ≈ {med_02_04:.2f} TECU (IQR ≈ {iqr_02_04:.2f} TECU)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c3197-6d7f-4269-8346-0800796459cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# FIGURE COMBINÉE — ECDF (3 heures) + EXCEEDANCE (20/30/40 TECU)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ecdf(x):\n",
    "    x = np.sort(x[~np.isnan(x)])\n",
    "    if x.size == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    y = np.arange(1, x.size+1)/x.size\n",
    "    return x, y\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "labels_ecdf = {\"09:00\":18, \"12:00\":24, \"15:00\":30}  # slots pour ECDF\n",
    "thresholds = [20, 30, 40]                           # seuils exceedance\n",
    "# -----------------------------\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    2, 1, figsize=(8, 8),\n",
    "    gridspec_kw={\"height_ratios\": [1.1, 1.0]}\n",
    ")\n",
    "\n",
    "# ===================== PANNEL HAUT: ECDF ======================\n",
    "quantiles = {}\n",
    "\n",
    "for lab, slot in labels_ecdf.items():\n",
    "    vals = S.loc[S[\"slot\"] == slot, VTEC_COL].to_numpy()\n",
    "    x, y = ecdf(vals)\n",
    "    if x.size:\n",
    "        ax1.plot(x, y, lw=3, label=lab)\n",
    "        # quantiles (optionnel, juste au cas où tu veux les relire)\n",
    "        p50 = np.nanpercentile(vals, 50)\n",
    "        p75 = np.nanpercentile(vals, 75)\n",
    "        p90 = np.nanpercentile(vals, 90)\n",
    "        quantiles[lab] = (p50, p75, p90)\n",
    "\n",
    "# style axe ECDF\n",
    "ax1.set_xlim(0, max(50, np.nanpercentile(S[VTEC_COL], 99)))\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.legend(frameon=True, title=\"Local time\")\n",
    "\n",
    "for t in ax1.yaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "for t in ax1.xaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "\n",
    "ax1.set_ylabel(\"CDF VTEC\", weight='bold')\n",
    "ax1.set_title(\"(a) Empirical CDF of VTEC at 09:00, 12:00, 15:00 LT\",\n",
    "              loc=\"left\", weight='bold')\n",
    "\n",
    "# ================= PANNEL BAS: EXCEEDANCE =====================\n",
    "g = S.groupby(\"slot\")[VTEC_COL]\n",
    "den = g.count().rename(\"N\")\n",
    "\n",
    "def slot_ticks_2h_local(ax):\n",
    "    \"\"\"\n",
    "    Place des ticks toutes 2h en LT sur l'axe des x, en supposant:\n",
    "      slot = 0..47, 1 slot = 30 min, LT = slot * 0.5 h\n",
    "    \"\"\"\n",
    "    slots_2h = np.arange(0, 48, 4)  # 4 slots = 2 h\n",
    "    labels = [f\"{int(0.5*s):02d}:00\" for s in slots_2h]\n",
    "    ax.set_xlim(0, 47)\n",
    "    ax.set_xticks(slots_2h)\n",
    "    ax.set_xticklabels(labels)\n",
    "\n",
    "for thr in thresholds:\n",
    "    num = S.assign(hit=S[VTEC_COL] >= thr).groupby(\"slot\")[\"hit\"].sum()\n",
    "    p = (num / den).reindex(np.arange(48)).values\n",
    "    ax2.plot(np.arange(48), p, '-o', ms=3, lw=2, label=f\"≥ {thr} TECU\")\n",
    "\n",
    "slot_ticks_2h_local(ax2)\n",
    "ax2.set_ylim(0, 0.4)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "for t in ax2.yaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "for t in ax2.xaxis.get_ticklabels():\n",
    "    t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "\n",
    "ax2.set_xlabel(\"Local Time (LT)\", weight='bold')\n",
    "ax2.set_ylabel(\"Probability\", weight='bold')\n",
    "ax2.legend(frameon=True)\n",
    "ax2.set_title(\"(b) Probability of VTEC exceeding fixed thresholds\",\n",
    "              loc=\"left\", weight='bold')\n",
    "\n",
    "fig.tight_layout(rect=[0.03, 0.03, 0.97, 0.95])\n",
    "fig.suptitle(\"VTEC distributions and exceedance probabilities at Oukaimeden (QSL–GIM20)\",\n",
    "             y=0.98, fontsize=12, weight='bold')\n",
    "\n",
    "out = OUTDIR_FIG / \"Low_solar_activity_QUIET_ECDF_exceedance_MS.png\"\n",
    "fig.savefig(out, dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Saved combined figure:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc75bd-66e2-47d4-852c-3f5fa1114b32",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 9 — ANOMALIES PAR ANNÉE (médiane diurne – climatologie quiet)\n",
    "# ==========================================\n",
    "CLIM = agg_diurnal(S)[[\"slot\",\"median\"]].rename(columns={\"median\":\"clim_median\"})\n",
    "fig, axes = plt.subplots(6,2, figsize=(12,8), squeeze=False)\n",
    "for i,y in enumerate(sorted({pd.Timestamp(d).year for d in df_kept['date_utc']})):\n",
    "    ax = axes[i//2, i%2]\n",
    "    Sy = S[pd.to_datetime(S[\"date_utc\"]).dt.year == y]\n",
    "    Dy = agg_diurnal(Sy)[[\"slot\",\"median\"]].merge(CLIM, on=\"slot\", how=\"left\")\n",
    "    Dy[\"anom\"] = Dy[\"median\"] - Dy[\"clim_median\"]\n",
    "    ax.axhline(0, color='k', lw=3, ls='--')\n",
    "    ax.plot(Dy[\"slot\"], Dy[\"anom\"], '-', lw=2)\n",
    "    \n",
    "    # style ticks\n",
    "    for t in ax.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    for t in ax.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "        \n",
    "    slot_ticks_2h(ax); ax.grid(alpha=0.3)\n",
    "    \n",
    "    ax.set_title(str(y), fontweight='bold', y=0.75)\n",
    "    ax.set_ylim(-5,50); ax.set_yticks(np.arange(0,49,15))\n",
    "\n",
    "# Supprimer la case en bas-droite\n",
    "fig.delaxes(axes[-1, 1])\n",
    "\n",
    "# Afficher les heures (ticks x) en bas-gauche ET aussi à droite\n",
    "rows, cols = axes.shape\n",
    "\n",
    "# 1) Tout cacher par défaut\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        axes[r, c].tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "# 2) Bas-gauche visible\n",
    "axes[rows-1, 0].tick_params(axis='x', labelbottom=True)\n",
    "\n",
    "# 3) Trouver le panneau le plus bas qui existe encore dans la colonne de droite\n",
    "right_row = None\n",
    "for r in range(rows-1, -1, -1):\n",
    "    if axes[r, 1] in fig.axes:   # la case existe (pas supprimée)\n",
    "        right_row = r\n",
    "        break\n",
    "\n",
    "# 4) Activer les heures sur ce panneau de droite\n",
    "if right_row is not None:\n",
    "    axes[right_row, 1].tick_params(axis='x', labelbottom=True)\n",
    "\n",
    "# Espacement vertical nul et textes\n",
    "#fig.subplots_adjust(hspace=0)\n",
    "#fig.text(0.5, 0.05, 'Local Time (LT)', ha='center', fontsize=12, weight='bold')\n",
    "\n",
    "\n",
    "plt.setp([a.get_xticklabels() for a in axes[0, :]], visible=False)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "fig.text(0.5, 0.9, f'VTEC Anomaly (Diurnal Median) vs Quiet-Time Climatology', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.5, 0.05, 'Local Time (LT)', ha='center', fontsize=12, weight='bold')\n",
    "fig.text(0.07, 0.5, 'VTEC Anomaly', va='center', rotation='vertical', fontsize=12, weight='bold')\n",
    "#fig.tight_layout(rect=[0.03,0.03,0.98,0.96])\n",
    "out = OUTDIR_FIG/\"Low_solar_activity_QUIET_yearly_anomaly_vs_climatology_MS.png\"\n",
    "#plt.show()\n",
    "fig.savefig(out, dpi=300) \n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fd72c-bf8f-4ab2-9c19-164091264175",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Climatologie diurne multi-annuelle (déjà utilisée pour la figure) ---\n",
    "CLIM = agg_diurnal(S)[[\"slot\", \"median\"]].rename(columns={\"median\": \"clim_median\"})\n",
    "\n",
    "# --- Liste des années présentes dans df_kept ---\n",
    "years = sorted({pd.Timestamp(d).year for d in df_kept[\"date_utc\"]})\n",
    "\n",
    "def slot_to_lt(slot):\n",
    "    \"\"\"Convertit un slot (0..47) en heure locale (HH:MM) en supposant 30 min par slot.\"\"\"\n",
    "    h_float = 0.5 * slot\n",
    "    h = int(h_float)\n",
    "    m = int(round((h_float - h) * 60))\n",
    "    return f\"{h:02d}:{m:02d}\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "for y in years:\n",
    "    # Sous-ensemble de S pour l'année y\n",
    "    Sy = S[pd.to_datetime(S[\"date_utc\"]).dt.year == y].copy()\n",
    "    if Sy.empty:\n",
    "        continue\n",
    "\n",
    "    # Diurne médian pour l'année y\n",
    "    Dy = agg_diurnal(Sy)[[\"slot\", \"median\"]].merge(CLIM, on=\"slot\", how=\"left\")\n",
    "    Dy[\"anom\"] = Dy[\"median\"] - Dy[\"clim_median\"]\n",
    "\n",
    "    # 1) Anomalie max et heure correspondante\n",
    "    max_anom = float(Dy[\"anom\"].max())\n",
    "    idx_max = Dy[\"anom\"].idxmax()\n",
    "    slot_max = int(Dy.loc[idx_max, \"slot\"])\n",
    "    lt_max = slot_to_lt(slot_max)\n",
    "\n",
    "    # 2) Anomalie min et heure correspondante\n",
    "    min_anom = float(Dy[\"anom\"].min())\n",
    "    idx_min = Dy[\"anom\"].idxmin()\n",
    "    slot_min = int(Dy.loc[idx_min, \"slot\"])\n",
    "    lt_min = slot_to_lt(slot_min)\n",
    "\n",
    "    # 3) Anomalie moyenne sur toute la journée (48 slots)\n",
    "    mean_anom_all = float(Dy[\"anom\"].mean())\n",
    "\n",
    "    # 4) Anomalie moyenne sur l'après-midi (par ex. 12–18 LT → slots 24..36 inclus)\n",
    "    aft = Dy[(Dy[\"slot\"] >= 24) & (Dy[\"slot\"] <= 36)]\n",
    "    mean_anom_aft = float(aft[\"anom\"].mean()) if not aft.empty else np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"year\": y,\n",
    "        \"max_anom_TECU\": max_anom,\n",
    "        \"lt_of_max\": lt_max,\n",
    "        \"min_anom_TECU\": min_anom,\n",
    "        \"lt_of_min\": lt_min,\n",
    "        \"mean_anom_all_TECU\": mean_anom_all,\n",
    "        \"mean_anom_12_18LT_TECU\": mean_anom_aft\n",
    "    })\n",
    "\n",
    "anom_stats = pd.DataFrame(rows).sort_values(\"year\")\n",
    "\n",
    "# Impression propre pour le papier\n",
    "print(\"Yearly diurnal VTEC anomalies relative to the quiet-time climatology:\")\n",
    "print(anom_stats.to_string(index=False,\n",
    "                           float_format=lambda x: f\"{x:6.2f}\"))\n",
    "\n",
    "# Quelques résumés utiles pour le texte:\n",
    "print(\"\\n--- Summary for LaTeX paragraph ---\")\n",
    "y_max_global = anom_stats.loc[anom_stats[\"max_anom_TECU\"].idxmax(), \"year\"]\n",
    "max_global = anom_stats[\"max_anom_TECU\"].max()\n",
    "print(f\"Largest positive anomaly: {max_global:.2f} TECU in {y_max_global} \"\n",
    "      f\"(at local time {anom_stats.loc[anom_stats['max_anom_TECU'].idxmax(), 'lt_of_max']}).\")\n",
    "\n",
    "y_min_global = anom_stats.loc[anom_stats[\"min_anom_TECU\"].idxmin(), \"year\"]\n",
    "min_global = anom_stats[\"min_anom_TECU\"].min()\n",
    "print(f\"Largest negative anomaly: {min_global:.2f} TECU in {y_min_global} \"\n",
    "      f\"(at local time {anom_stats.loc[anom_stats['min_anom_TECU'].idxmin(), 'lt_of_min']}).\")\n",
    "\n",
    "print(\"\\nAfternoon (12–18 LT) mean anomalies by year:\")\n",
    "for _, r in anom_stats.iterrows():\n",
    "    print(f\"  {int(r['year'])}: mean anomaly 12–18 LT ≈ {r['mean_anom_12_18LT_TECU']:.2f} TECU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653fe199-83b6-4725-83b6-750e424a8cae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 10 — Monthly & seasonal box + mean\n",
    "# ==========================================\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns, calendar\n",
    "from pathlib import Path\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# --------- PARAMS ---------\n",
    "TIME_COL  = \"date_utc\"\n",
    "VTEC_COL  = \"VTEC_median\"\n",
    "LABEL_COL = \"geomag_label_gfz_QDNQ\"   # 'Q', 'D', 'NQ'\n",
    "START     = pd.Timestamp(\"2015-10-01\", tz=\"UTC\")\n",
    "END       = pd.Timestamp(\"2025-09-26\", tz=\"UTC\")\n",
    "# --------------------------\n",
    "\n",
    "# --- s'assurer que la colonne temps est bien en datetime ---\n",
    "df = df.copy()\n",
    "df[TIME_COL] = pd.to_datetime(df[TIME_COL], utc=True, errors=\"coerce\")\n",
    "df = df[(df[TIME_COL] >= START) & (df[TIME_COL] <= END)].copy()\n",
    "\n",
    "# si tu veux être sûr d’être bien sur QSL–GIM20, tu peux remettre ces filtres:\n",
    "# df = df[df[LABEL_COL] == \"Q\"].copy()\n",
    "# df = df[pd.to_numeric(df[\"gim_offset_tecu\"], errors=\"coerce\").abs() <= 20].copy()\n",
    "\n",
    "# maintenant .dt fonctionne\n",
    "df[\"month\"] = df[TIME_COL].dt.month\n",
    "\n",
    "# -------- MENSUEL (toutes années confondues) --------\n",
    "mlabels = [calendar.month_abbr[m] for m in range(1,13)]\n",
    "all_months = np.arange(1,13)\n",
    "\n",
    "data_bp = [df.loc[df[\"month\"]==m, VTEC_COL].dropna().to_numpy() for m in all_months]\n",
    "has_data = [len(v)>0 for v in data_bp]\n",
    "\n",
    "mm = (df.groupby(\"month\", as_index=False)[VTEC_COL]\n",
    "        .mean()\n",
    "        .set_index(\"month\")\n",
    "        .reindex(all_months))\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,4))\n",
    "pos = [m for m,ok in zip(all_months,has_data) if ok]\n",
    "dat = [v for v,ok in zip(data_bp,has_data) if ok]\n",
    "\n",
    "if dat:\n",
    "    ax.boxplot(\n",
    "        dat, positions=pos, patch_artist=True, showmeans=True, whis=(5,95),\n",
    "        meanprops=dict(marker='D', markersize=4, markerfacecolor='black', markeredgecolor='white'),\n",
    "        boxprops=dict(facecolor='#c7e9ff', edgecolor='#1f4d7a', linewidth=1.2),\n",
    "        medianprops=dict(color='crimson', linewidth=1.8),\n",
    "        whiskerprops=dict(color='#1f4d7a', linewidth=1.0, linestyle='--'),\n",
    "        capprops=dict(color='#1f4d7a', linewidth=1.0),\n",
    "        flierprops=dict(marker='x', markersize=3, markeredgecolor='gray', markerfacecolor='none', alpha=0.5),\n",
    "    )\n",
    "\n",
    "ax.plot(all_months, mm[VTEC_COL].to_numpy(), color=\"black\", marker=\"o\", linewidth=2, markersize=5, label=\"Mean\")\n",
    "for tick in ax.yaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12); tick.set_color('black'); tick.set_weight('bold')\n",
    "for tick in ax.xaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12); tick.set_color('black'); tick.set_weight('bold')\n",
    "\n",
    "ax.set_xlim(0.5, 12.5)\n",
    "ax.set_xticks(all_months)\n",
    "ax.set_xticklabels(mlabels)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(frameon=False, loc=\"upper left\")\n",
    "\n",
    "fig.text(0.5, 0.92, \"Quiet days monthly median and mean from Oct 2015 to Sep 2025\",\n",
    "         ha=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "fig.text(0.5, 0.00, \"Month\", ha=\"center\", fontsize=14, fontweight=\"bold\")\n",
    "fig.text(0.04, 0.5, \"TEC [TECU]\", va=\"center\", rotation=\"vertical\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "out = OUTDIR_FIG/\"Low_solar_activity_QUIET_monthly_median_boxplot_means_curve_by_LT_MS.png\"\n",
    "fig.savefig(out, dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out)\n",
    "\n",
    "# -------- SAISONNIER (toutes années confondues) --------\n",
    "def to_season(m):\n",
    "    if m in (12,1,2):  return \"DJF\"\n",
    "    if m in (3,4,5):   return \"MAM\"\n",
    "    if m in (6,7,8):   return \"JJA\"\n",
    "    return \"SON\"\n",
    "\n",
    "df[\"season\"] = df[\"month\"].map(to_season)\n",
    "\n",
    "order = [\"DJF\",\"MAM\",\"JJA\",\"SON\"]\n",
    "data_s = [df.loc[df[\"season\"]==s, VTEC_COL].dropna().to_numpy() for s in order]\n",
    "has_s  = [len(v)>0 for v in data_s]\n",
    "\n",
    "ms = (df.groupby(\"season\", as_index=False)[VTEC_COL]\n",
    "        .mean()\n",
    "        .set_index(\"season\")\n",
    "        .reindex(order))\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,4))\n",
    "pos = [i+1 for i,ok in enumerate(has_s) if ok]\n",
    "dat = [v for v,ok in zip(data_s,has_s) if ok]\n",
    "labs = [s for s,ok in zip(order,has_s) if ok]\n",
    "\n",
    "if dat:\n",
    "    ax.boxplot(\n",
    "        dat, positions=pos, patch_artist=True, showmeans=True, whis=(5,95),\n",
    "        meanprops=dict(marker='D', markersize=4, markerfacecolor='black', markeredgecolor='white'),\n",
    "        boxprops=dict(facecolor='#c7e9ff', edgecolor='#1f4d7a', linewidth=1.2),\n",
    "        medianprops=dict(color='crimson', linewidth=1.8),\n",
    "        whiskerprops=dict(color='#1f4d7a', linewidth=1.0, linestyle='--'),\n",
    "        capprops=dict(color='#1f4d7a', linewidth=1.0),\n",
    "        flierprops=dict(marker='x', markersize=3, markeredgecolor='gray', markerfacecolor='none', alpha=0.5),\n",
    "    )\n",
    "\n",
    "ax.plot(np.arange(1,5), ms[VTEC_COL].to_numpy(), color=\"black\", marker=\"o\", linewidth=3, markersize=5, label=\"Mean\")\n",
    "\n",
    "for tick in ax.yaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12); tick.set_color('black'); tick.set_weight('bold')\n",
    "for tick in ax.xaxis.get_ticklabels():\n",
    "    tick.set_fontsize(12); tick.set_color('black'); tick.set_weight('bold')\n",
    "\n",
    "ax.set_xlim(0.5, 4.5)\n",
    "ax.set_xticks(np.arange(1,5))\n",
    "ax.set_xticklabels(order)\n",
    "ax.legend(frameon=False, loc=\"upper left\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.text(0.5, 0.92, \"Quiet days seasonal median and mean from Oct 2015 to Sep 2025\",\n",
    "         ha=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "fig.text(0.5, 0.001, \"Season\", ha=\"center\", fontsize=14, fontweight=\"bold\")\n",
    "fig.text(0.04, 0.5, \"TEC [TECU]\", va=\"center\", rotation=\"vertical\", fontsize=15, fontweight=\"bold\")\n",
    "\n",
    "out = OUTDIR_FIG/\"Low_solar_activity_QUIET_seasonal_median_boxplot_means_curve_by_LT_MS.png\"\n",
    "fig.savefig(out, dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd06d5-aebf-421e-aa6a-b8590c9e4b9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL 10b — Stats numériques pour les boxplots mensuels et saisonniers\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import calendar\n",
    "\n",
    "VTEC_COL = \"VTEC_median\"  # cohérent avec ta cellule précédente\n",
    "\n",
    "# S'assurer que month et season existent (au cas où)\n",
    "if \"month\" not in df.columns:\n",
    "    df[\"month\"] = df[\"date_utc\"].dt.month\n",
    "\n",
    "def to_season(m):\n",
    "    if m in (12,1,2):  return \"DJF\"\n",
    "    if m in (3,4,5):   return \"MAM\"\n",
    "    if m in (6,7,8):   return \"JJA\"\n",
    "    return \"SON\"\n",
    "\n",
    "if \"season\" not in df.columns:\n",
    "    df[\"season\"] = df[\"month\"].map(to_season)\n",
    "\n",
    "# ---------- 1) STATS MENSUELLES ----------\n",
    "def iqr(x):\n",
    "    x = np.asarray(x, float)\n",
    "    return np.nanpercentile(x, 75) - np.nanpercentile(x, 25)\n",
    "\n",
    "monthly_stats = (\n",
    "    df.groupby(\"month\")[VTEC_COL]\n",
    "      .agg(\n",
    "          n_days   = \"count\",\n",
    "          median   = \"median\",\n",
    "          mean     = \"mean\",\n",
    "          iqr      = iqr,\n",
    "          p5       = lambda x: np.nanpercentile(x, 5),\n",
    "          p95      = lambda x: np.nanpercentile(x, 95),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "monthly_stats[\"month_name\"] = monthly_stats[\"month\"].apply(lambda m: calendar.month_abbr[m])\n",
    "\n",
    "print(\"\\n=== Monthly stats of daily median VTEC (quiet QSL–GIM20) ===\")\n",
    "print(monthly_stats.to_string(index=False, float_format=lambda v: f\"{v:5.2f}\"))\n",
    "\n",
    "# Mois de médiane max / min\n",
    "idx_max_m = monthly_stats[\"median\"].idxmax()\n",
    "idx_min_m = monthly_stats[\"median\"].idxmin()\n",
    "\n",
    "m_max_row = monthly_stats.loc[idx_max_m]\n",
    "m_min_row = monthly_stats.loc[idx_min_m]\n",
    "\n",
    "print(\"\\n--- Key monthly values for LaTeX paragraph ---\")\n",
    "print(f\"Highest monthly median VTEC: {m_max_row['median']:.2f} TECU in {m_max_row['month_name']} \"\n",
    "      f\"(mean ≈ {m_max_row['mean']:.2f} TECU, IQR ≈ {m_max_row['iqr']:.2f} TECU).\")\n",
    "print(f\"Lowest monthly median VTEC:  {m_min_row['median']:.2f} TECU in {m_min_row['month_name']} \"\n",
    "      f\"(mean ≈ {m_min_row['mean']:.2f} TECU, IQR ≈ {m_min_row['iqr']:.2f} TECU).\")\n",
    "\n",
    "# Mois où la dispersion (IQR) est max / min\n",
    "idx_max_iqr_m = monthly_stats[\"iqr\"].idxmax()\n",
    "idx_min_iqr_m = monthly_stats[\"iqr\"].idxmin()\n",
    "iqr_max_row   = monthly_stats.loc[idx_max_iqr_m]\n",
    "iqr_min_row   = monthly_stats.loc[idx_min_iqr_m]\n",
    "\n",
    "print(f\"Largest monthly spread (IQR): {iqr_max_row['iqr']:.2f} TECU in {iqr_max_row['month_name']}.\")\n",
    "print(f\"Smallest monthly spread (IQR): {iqr_min_row['iqr']:.2f} TECU in {iqr_min_row['month_name']}.\")\n",
    "\n",
    "# Mesure simple de la dissymétrie mean–median (pour repérer les queues)\n",
    "monthly_stats[\"skew_proxy\"] = monthly_stats[\"mean\"] - monthly_stats[\"median\"]\n",
    "idx_max_skew = monthly_stats[\"skew_proxy\"].idxmax()\n",
    "idx_min_skew = monthly_stats[\"skew_proxy\"].idxmin()\n",
    "\n",
    "skew_max_row = monthly_stats.loc[idx_max_skew]\n",
    "skew_min_row = monthly_stats.loc[idx_min_skew]\n",
    "\n",
    "print(f\"Largest positive mean–median difference (right tail): \"\n",
    "      f\"{skew_max_row['skew_proxy']:.2f} TECU in {skew_max_row['month_name']}.\")\n",
    "print(f\"Largest negative mean–median difference (left tail): \"\n",
    "      f\"{skew_min_row['skew_proxy']:.2f} TECU in {skew_min_row['month_name']}.\")\n",
    "\n",
    "\n",
    "# ---------- 2) STATS SAISONNIÈRES ----------\n",
    "seasonal_stats = (\n",
    "    df.groupby(\"season\")[VTEC_COL]\n",
    "      .agg(\n",
    "          n_days   = \"count\",\n",
    "          median   = \"median\",\n",
    "          mean     = \"mean\",\n",
    "          iqr      = iqr,\n",
    "          p5       = lambda x: np.nanpercentile(x, 5),\n",
    "          p95      = lambda x: np.nanpercentile(x, 95),\n",
    "      )\n",
    "      .reindex([\"DJF\",\"MAM\",\"JJA\",\"SON\"])   # ordre canonique\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\n=== Seasonal stats of daily median VTEC (quiet QSL–GIM20) ===\")\n",
    "print(seasonal_stats.to_string(index=False, float_format=lambda v: f\"{v:5.2f}\"))\n",
    "\n",
    "idx_max_s = seasonal_stats[\"median\"].idxmax()\n",
    "idx_min_s = seasonal_stats[\"median\"].idxmin()\n",
    "s_max_row = seasonal_stats.loc[idx_max_s]\n",
    "s_min_row = seasonal_stats.loc[idx_min_s]\n",
    "\n",
    "print(\"\\n--- Key seasonal values for LaTeX paragraph ---\")\n",
    "print(f\"Highest seasonal median VTEC: {s_max_row['median']:.2f} TECU in {s_max_row['season']} \"\n",
    "      f\"(mean ≈ {s_max_row['mean']:.2f} TECU, IQR ≈ {s_max_row['iqr']:.2f} TECU).\")\n",
    "print(f\"Lowest seasonal median VTEC:  {s_min_row['median']:.2f} TECU in {s_min_row['season']} \"\n",
    "      f\"(mean ≈ {s_min_row['mean']:.2f} TECU, IQR ≈ {s_min_row['iqr']:.2f} TECU).\")\n",
    "\n",
    "# Skew proxy par saison\n",
    "seasonal_stats[\"skew_proxy\"] = seasonal_stats[\"mean\"] - seasonal_stats[\"median\"]\n",
    "idx_max_skew_s = seasonal_stats[\"skew_proxy\"].idxmax()\n",
    "idx_min_skew_s = seasonal_stats[\"skew_proxy\"].idxmin()\n",
    "\n",
    "sskew_max_row = seasonal_stats.loc[idx_max_skew_s]\n",
    "sskew_min_row = seasonal_stats.loc[idx_min_skew_s]\n",
    "\n",
    "print(f\"Largest seasonal mean–median difference: {sskew_max_row['skew_proxy']:.2f} TECU in {sskew_max_row['season']}.\")\n",
    "print(f\"Smallest seasonal mean–median difference: {sskew_min_row['skew_proxy']:.2f} TECU in {sskew_min_row['season']}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10197fa7-dd82-4f63-9ce7-d0fb6b61a486",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# eia_crest_from_ionex_using_my_reader.py\n",
    "# Extraction robuste de la latitude de la crête EIA autour d’OUCA en s’appuyant sur lq fonction read_ionex().\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import io, subprocess\n",
    "from datetime import date, datetime, timedelta, timezone\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "DEC_DIR   = Path(r\"G:\\My Drive\\14-DATA\\TEC_DATA\\Raw_Data\\IONEX\\IONEX_decompressed\")  # répertoire unique des IONEX décompressés\n",
    "OUT_DAILY = Path(r\"G:\\My Drive\\14-DATA\\TEC_DATA\\daily_eia_crest_latitude.csv\")\n",
    "OUT_FIG   = Path(r\"G:\\My Drive\\14-DATA\\TEC_DATA\\daily_eia_crest_latitude.png\")\n",
    "\n",
    "OUCA_LAT, OUCA_LON = 31.206, -7.866\n",
    "LON_BAND_DEG = 5.0             # moyenne VTEC dans [lon-5, lon+5]\n",
    "SEARCH_LAT_MIN, SEARCH_LAT_MAX = 0.0, 50.0  # fenêtre de recherche de la crête (Nord)\n",
    "ONLY_AFTERNOON_LT = False       # True pour ne garder que [LT_HOURS_WINDOW]\n",
    "LT_TZ = pytz.timezone(\"Africa/Casablanca\")\n",
    "LT_HOURS_WINDOW = (4, 20)\n",
    "\n",
    "START     = date(2015, 10, 1)\n",
    "END       = date(2025, 9, 26)\n",
    "# ============================================\n",
    "\n",
    "# ====== TES FONCTIONS (inchangées) ======\n",
    "def _open_text(p: Path) -> io.StringIO:\n",
    "    p = Path(p)\n",
    "    if not p.exists(): raise FileNotFoundError(p)\n",
    "    ext = p.suffix.lower()\n",
    "    if ext == \".gz\":\n",
    "        out = subprocess.run([\"gzip\", \"-dc\", str(p)], capture_output=True)\n",
    "        if out.returncode != 0: raise RuntimeError(\"gzip -dc failed\")\n",
    "        return io.StringIO(out.stdout.decode(\"ascii\",\"ignore\"))\n",
    "    if ext == \".z\":\n",
    "        gz = subprocess.run([\"gzip\", \"-dc\", str(p)], capture_output=True)\n",
    "        if gz.returncode == 0 and gz.stdout:\n",
    "            return io.StringIO(gz.stdout.decode(\"ascii\",\"ignore\"))\n",
    "        sz = subprocess.run([\"7z\", \"e\", \"-so\", str(p)], capture_output=True)\n",
    "        if sz.returncode != 0: raise RuntimeError(\"7z -so failed\")\n",
    "        return io.StringIO(sz.stdout.decode(\"ascii\",\"ignore\"))\n",
    "    return io.StringIO(p.read_text(encoding=\"ascii\", errors=\"ignore\"))\n",
    "\n",
    "def ionex_first_epoch_date(path: Path):\n",
    "    try:\n",
    "        f = _open_text(path)\n",
    "    except Exception:\n",
    "        return None\n",
    "    for _ in range(400):\n",
    "        line = f.readline()\n",
    "        if not line: break\n",
    "        if \"EPOCH OF FIRST MAP\" in line:\n",
    "            yr, mo, dy, hh, mm, ss = map(int, line[:60].split()[:6])\n",
    "            return datetime(yr, mo, dy, hh, mm, ss, tzinfo=timezone.utc).date()\n",
    "        if \"END OF HEADER\" in line:\n",
    "            break\n",
    "    return None\n",
    "\n",
    "def read_ionex(path: Path):\n",
    "    f = _open_text(path)\n",
    "    exp = -1\n",
    "    lat1=lat2=dlat=lon1=lon2=dlon=None\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: raise ValueError(\"Header IONEX incomplet\")\n",
    "        if \"EXPONENT\" in line:\n",
    "            s = line[:8].strip()\n",
    "            exp = int(s) if s else -1\n",
    "        if \"LAT1 / LAT2 / DLAT\" in line:\n",
    "            lat1,lat2,dlat = map(float, line[:60].split()[:3])\n",
    "        if \"LON1 / LON2 / DLON\" in line:\n",
    "            lon1,lon2,dlon = map(float, line[:60].split()[:3])\n",
    "        if \"END OF HEADER\" in line:\n",
    "            break\n",
    "    if None in (lat1,lat2,dlat,lon1,lon2,dlon): raise ValueError(\"Grille absente\")\n",
    "    nlat = int(round((lat2-lat1)/dlat))+1\n",
    "    nlon = int(round((lon2-lon1)/dlon))+1\n",
    "    lats = np.linspace(lat1, lat2, nlat)\n",
    "    lons = np.linspace(lon1, lon2, nlon)\n",
    "\n",
    "    times, maps = [], []\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break\n",
    "        if \"START OF TEC MAP\" in line:\n",
    "            # epoch\n",
    "            line = f.readline()\n",
    "            while line and \"EPOCH OF CURRENT MAP\" not in line:\n",
    "                line = f.readline()\n",
    "            if not line: break\n",
    "            yr,mo,dy,hh,mm,ss = map(int, line[:60].split()[:6])\n",
    "            t = pd.Timestamp(datetime(yr,mo,dy,hh,mm,ss, tzinfo=timezone.utc))\n",
    "            tec = np.full((nlat,nlon), np.nan)\n",
    "            bad = False\n",
    "            for ilat in range(nlat):\n",
    "                hdr = f.readline()\n",
    "                if not hdr or \"LAT/LON1/LON2/DLON/H\" not in hdr:\n",
    "                    bad=True; break\n",
    "                vals=[]\n",
    "                while len(vals) < nlon:\n",
    "                    data = f.readline()\n",
    "                    if not data or (\"START OF\" in data) or (\"END OF\" in data) or (\"LAT/LON1\" in data):\n",
    "                        bad=True; break\n",
    "                    chunks = [data[i:i+5] for i in range(0, len(data.rstrip()), 5)]\n",
    "                    for c in chunks:\n",
    "                        c = c.strip().upper()\n",
    "                        if c==\"\" or c==\"9999\": vals.append(np.nan)\n",
    "                        else:\n",
    "                            try: vals.append(float(c)*(10.0**exp))\n",
    "                            except: vals.append(np.nan)\n",
    "                        if len(vals)==nlon: break\n",
    "                if bad: break\n",
    "                if len(vals)<nlon: vals += [np.nan]*(nlon-len(vals))\n",
    "                tec[ilat, :] = vals\n",
    "            if bad:\n",
    "                # purge jusqu'à END OF TEC MAP\n",
    "                x = hdr\n",
    "                while x:\n",
    "                    if \"END OF TEC MAP\" in x: break\n",
    "                    x = f.readline()\n",
    "                continue\n",
    "            times.append(t)\n",
    "            maps.append(tec)\n",
    "    if not maps: raise ValueError(\"Aucune carte TEC\")\n",
    "    TEC = np.stack(maps, axis=0)\n",
    "    # normalisation lon/lat\n",
    "    if lons.min()>=0 and lons.max()>180:\n",
    "        order = np.argsort(((lons+180)%360)-180)\n",
    "        lons = (((lons+180)%360)-180)[order]\n",
    "        TEC  = TEC[:,:,order]\n",
    "    if lats[0]>lats[-1]:\n",
    "        lats = lats[::-1]; TEC = TEC[:, ::-1, :]\n",
    "    times = pd.to_datetime(times, utc=True)\n",
    "    return times, lats, lons, TEC\n",
    "\n",
    "def product_window(day: date) -> str:\n",
    "    if day <= date(2022, 11, 27):  # DOY<=330\n",
    "        return \"OLD\"\n",
    "    if day <= date(2025, 9, 20):   # fenêtre OPSFIN\n",
    "        return \"OPSFIN\"\n",
    "    return \"OPSRAP\"\n",
    "\n",
    "def pick_ionex_for_day(day: date) -> Path | None:\n",
    "    yy = f\"{day.year%100:02d}\"; doy = f\"{int(pd.Timestamp(day).strftime('%j')):03d}\"\n",
    "    mode = product_window(day)\n",
    "    if mode == \"OLD\":\n",
    "        cand = [f\"codg{doy}0.{yy}i\", f\"CODG{doy}0.{yy}I\"]\n",
    "        for name in cand:\n",
    "            p = DEC_DIR / name\n",
    "            if p.exists() and ionex_first_epoch_date(p) == day:\n",
    "                return p\n",
    "        for q in DEC_DIR.glob(f\"codg*{yy}i\"):\n",
    "            if ionex_first_epoch_date(q) == day: return q\n",
    "        for q in DEC_DIR.glob(f\"CODG*{yy}I\"):\n",
    "            if ionex_first_epoch_date(q) == day: return q\n",
    "        return None\n",
    "    patterns = []\n",
    "    if mode == \"OPSFIN\":\n",
    "        patterns = [f\"COD0OPSFIN_*{day.year}{doy}*_GIM.INX\",\n",
    "                    f\"COD0OPSRAP_*{day.year}{doy}*_GIM.INX\"]\n",
    "    else:\n",
    "        patterns = [f\"COD0OPSRAP_*{day.year}{doy}*_GIM.INX\",\n",
    "                    f\"COD0OPSFIN_*{day.year}{doy}*_GIM.INX\"]\n",
    "    for pat in patterns:\n",
    "        for q in DEC_DIR.glob(pat):\n",
    "            if ionex_first_epoch_date(q) == day:\n",
    "                return q\n",
    "    return None\n",
    "# =========================================\n",
    "\n",
    "# ====== OUTILS CRÊTE EIA ======\n",
    "def lon_wrap(x): return (x + 180.0) % 360.0 - 180.0\n",
    "\n",
    "def lon_band_indices(lons: np.ndarray, lon0: float, band_deg: float) -> np.ndarray:\n",
    "    l = lon_wrap(lons.copy()); lon0 = lon_wrap(lon0)\n",
    "    return np.where(np.abs(l - lon0) <= band_deg)[0]\n",
    "\n",
    "def crest_lat_from_slice(lat: np.ndarray, vtec_lat: np.ndarray,\n",
    "                         lat_min: float, lat_max: float) -> float:\n",
    "    m = (lat >= lat_min) & (lat <= lat_max)\n",
    "    if not np.any(m): return np.nan\n",
    "    with np.errstate(invalid=\"ignore\"):\n",
    "        k = np.nanargmax(vtec_lat[m])\n",
    "    return float(lat[m][k])\n",
    "\n",
    "# ====== BOUCLE PRINCIPALE ======\n",
    "rows = []\n",
    "d = START\n",
    "n_days = 0\n",
    "while d <= END:\n",
    "    p = pick_ionex_for_day(d)\n",
    "    if p is None:\n",
    "        d += timedelta(days=1); continue\n",
    "    try:\n",
    "        times, lats, lons, TEC = read_ionex(p)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {p.name}: lecture impossible -> {e}\")\n",
    "        d += timedelta(days=1); continue\n",
    "\n",
    "    # indices longitude bande ±LON_BAND_DEG\n",
    "    j_idx = lon_band_indices(lons, OUCA_LON, LON_BAND_DEG)\n",
    "    if j_idx.size == 0:\n",
    "        d += timedelta(days=1); continue\n",
    "\n",
    "    for k, t in enumerate(times):\n",
    "        t_utc = t.to_pydatetime()\n",
    "        if not (datetime.combine(d, datetime.min.time(), tzinfo=timezone.utc)\n",
    "                <= t_utc\n",
    "                <  datetime.combine(d + timedelta(days=1), datetime.min.time(), tzinfo=timezone.utc)):\n",
    "            # sécurité si le fichier couvre 3 jours\n",
    "            pass  # on ne filtre pas — on laissera l’agrégateur regrouper par date LT\n",
    "        lt = t_utc.astimezone(LT_TZ)\n",
    "        if ONLY_AFTERNOON_LT and not (LT_HOURS_WINDOW[0] <= lt.hour < LT_HOURS_WINDOW[1]):\n",
    "            continue\n",
    "\n",
    "        # moyenne VTEC sur la bande longitudinale\n",
    "        vlat = np.nanmean(TEC[k][:, j_idx], axis=1)\n",
    "        crest_lat = crest_lat_from_slice(lats, vlat, SEARCH_LAT_MIN, SEARCH_LAT_MAX)\n",
    "        rows.append({\n",
    "            \"epoch_utc\": t_utc,\n",
    "            \"epoch_lt\": lt,\n",
    "            \"date_lt\": lt.date(),\n",
    "            \"crest_lat\": crest_lat,\n",
    "            \"ouca_lat\": OUCA_LAT,\n",
    "            \"crest_minus_ouca_deg\": crest_lat - OUCA_LAT,\n",
    "            \"src_file\": p.name\n",
    "        })\n",
    "    n_days += 1\n",
    "    d += timedelta(days=1)\n",
    "\n",
    "if not rows:\n",
    "    print(\"[INFO] Aucun epoch éligible (fenêtre date/LT).\")\n",
    "else:\n",
    "    df = pd.DataFrame(rows)\n",
    "    daily = (df.groupby(\"date_lt\", as_index=False)\n",
    "               .agg(crest_lat_med=(\"crest_lat\", \"median\"),\n",
    "                    crest_lat_iqr=(\"crest_lat\", lambda x: np.nanpercentile(x, 75)-np.nanpercentile(x, 25)),\n",
    "                    crest_minus_ouca_med=(\"crest_minus_ouca_deg\", \"median\"),\n",
    "                    n_epochs=(\"crest_lat\", \"count\")))\n",
    "    daily.to_csv(OUT_DAILY, index=False)\n",
    "    print(f\"[OK] CSV écrit -> {OUT_DAILY}  | jours = {len(daily)}  | fichiers lus = {n_days}\")\n",
    "\n",
    "    # figure rapide\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    ax.plot(pd.to_datetime(daily[\"date_lt\"]), daily[\"crest_lat_med\"], lw=1.2)\n",
    "    ax.axhline(OUCA_LAT, ls=\"--\", color=\"k\", lw=1.0, label=\"OUCA latitude\")\n",
    "    ax.set_ylabel(\"Daily median crest latitude [deg]\")\n",
    "    ax.set_title(\"Northern EIA crest latitude near OUCA longitude\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(OUT_FIG, dpi=200)\n",
    "    print(f\"[OK] Figure écrite -> {OUT_FIG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384a4fb-0846-4199-8e03-059f1842b10d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# diurnal_slopes_from_S30.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------- CONFIG ----------------\n",
    "#CSV_30MIN = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/2015_2025_MS_VTEC_30min_stats.csv\")\n",
    "TIME_COL = \"time\"             # timestamp column (UTC)\n",
    "VTEC_COL = \"VTEC_median\"      # your 30-min VTEC column\n",
    "LOCAL_TZ = \"Africa/Casablanca\"\n",
    "\n",
    "# fenêtres par défaut (plus utilisées ci-dessous, mais on les laisse si besoin)\n",
    "MORNING_LT = (6, 12)          # inclusive of start, exclusive of end\n",
    "EVENING_LT = (17, 22)\n",
    "\n",
    "KEEP_ONLY_QUIET = False\n",
    "QUIET_FLAG_COL = \"is_QSL_GIM20\"  # optional boolean; set KEEP_ONLY_QUIET=False if absent\n",
    "\n",
    "OUT_CSV = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/monthly_diurnal_slopes_seasonal_windows.csv\")\n",
    "OUT_PNG = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/monthly_diurnal_slopes_seasonal_windows.png\")\n",
    "# ---------------------------------------\n",
    "\n",
    "def theil_sen(x, y):\n",
    "    x = np.asarray(x, float); y = np.asarray(y, float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[m]; y = y[m]\n",
    "    if x.size < 3:\n",
    "        return np.nan\n",
    "    slopes = []\n",
    "    for i in range(x.size-1):\n",
    "        dx = x[i+1:] - x[i]\n",
    "        dy = y[i+1:] - y[i]\n",
    "        v = dy[np.abs(dx) > 1e-12] / dx[np.abs(dx) > 1e-12]\n",
    "        if v.size:\n",
    "            slopes.append(v)\n",
    "    if not slopes:\n",
    "        return np.nan\n",
    "    slopes = np.concatenate(slopes)\n",
    "    return np.nanmedian(slopes)\n",
    "\n",
    "def window_slope(df_lt, start_hour, end_hour):\n",
    "    \"\"\"df_lt: local-time dataframe with columns ['lt_hour_float', VTEC_COL]\"\"\"\n",
    "    m = (df_lt[\"lt_hour_float\"] >= start_hour) & (df_lt[\"lt_hour_float\"] < end_hour)\n",
    "    sub = df_lt.loc[m, [\"lt_hour_float\", VTEC_COL]].dropna()\n",
    "    if len(sub) < 3:\n",
    "        return np.nan\n",
    "    return theil_sen(sub[\"lt_hour_float\"].values, sub[VTEC_COL].values)\n",
    "\n",
    "def seasonal_windows_for_month(month: int):\n",
    "    \"\"\"\n",
    "    Définit les fenêtres LT en fonction du mois.\n",
    "    - Mois 'hiver étendu' : octobre (10) -> février (2) inclus\n",
    "      matin : 07–12 LT, soir : 16–20 LT\n",
    "    - Autres mois (mars -> septembre)\n",
    "      matin : 06–16 LT, soir : 18–22 LT\n",
    "    \"\"\"\n",
    "    if month in (11, 12, 1):\n",
    "        # Nov–Jan\n",
    "        morning = (7.0, 12.0)\n",
    "        evening = (16.0, 20.0)\n",
    "    elif month == 2:\n",
    "        # Feb\n",
    "        morning = (6.0, 12.0)\n",
    "        evening = (18.0, 21.0)\n",
    "    elif month == 3:\n",
    "        # Mar\n",
    "        morning = (6.0, 12.0)\n",
    "        evening = (18.0, 21.0)\n",
    "    elif month == 4:\n",
    "        # Apr\n",
    "        morning = (6.0, 14.0)\n",
    "        evening = (19, 22.0)\n",
    "    elif month == 5:\n",
    "        # May\n",
    "        morning = (6.0, 15.0)\n",
    "        evening = (19, 22.0)\n",
    "    elif month == 6:\n",
    "        # Jun\n",
    "        morning = (6.0, 15.0)\n",
    "        evening = (18.5, 23)\n",
    "    elif month in (7,8):\n",
    "        # Jul & Aug\n",
    "        morning = (6.0, 16.0)\n",
    "        evening = (19.0, 23.0)\n",
    "    elif month == 9:\n",
    "        # Sep\n",
    "        morning = (6.0, 14.0)\n",
    "        evening = (18.5, 22.0)\n",
    "    else:\n",
    "        # Oct\n",
    "        morning = (7.0, 14.0)\n",
    "        evening = (16.0, 21.0)\n",
    "    return morning, evening\n",
    "\n",
    "def main():\n",
    "    # On suppose que tu as déjà un DataFrame S (ex: S = pd.read_csv(...))\n",
    "    df = S.copy()\n",
    "\n",
    "    # UTC parse\n",
    "    df[TIME_COL] = pd.to_datetime(df[TIME_COL], utc=True, errors=\"coerce\")\n",
    "\n",
    "    # Optional quiet filter\n",
    "    if KEEP_ONLY_QUIET and QUIET_FLAG_COL in df.columns:\n",
    "        df = df[df[QUIET_FLAG_COL] == True].copy()\n",
    "\n",
    "    # Add local time\n",
    "    tz = pytz.timezone(LOCAL_TZ)\n",
    "    df[\"ts_lt\"] = df[TIME_COL].dt.tz_convert(tz)\n",
    "    df[\"date_lt\"] = df[\"ts_lt\"].dt.date\n",
    "    df[\"lt_hour_float\"] = df[\"ts_lt\"].dt.hour + df[\"ts_lt\"].dt.minute/60.0\n",
    "    df[\"month\"] = df[\"ts_lt\"].dt.month\n",
    "    df[\"year\"] = df[\"ts_lt\"].dt.year\n",
    "\n",
    "    # Daily slopes avec fenêtres dépendant du mois\n",
    "    daily = []\n",
    "    for d, g in df.groupby(\"date_lt\"):\n",
    "        month = int(g[\"month\"].iloc[0])\n",
    "        (m_start, m_end), (e_start, e_end) = seasonal_windows_for_month(month)\n",
    "\n",
    "        s_m = window_slope(g, m_start, m_end)\n",
    "        s_e = window_slope(g, e_start, e_end)\n",
    "\n",
    "        if not np.isfinite(s_m) and not np.isfinite(s_e):\n",
    "            continue\n",
    "\n",
    "        daily.append({\n",
    "            \"date_lt\": d,\n",
    "            \"month\": month,\n",
    "            \"year\": g[\"year\"].iloc[0],\n",
    "            \"morning_start_lt\": m_start,\n",
    "            \"morning_end_lt\": m_end,\n",
    "            \"evening_start_lt\": e_start,\n",
    "            \"evening_end_lt\": e_end,\n",
    "            \"slope_morning_tec_per_hour\": s_m,\n",
    "            \"slope_evening_tec_per_hour\": s_e\n",
    "        })\n",
    "\n",
    "    daily = pd.DataFrame(daily)\n",
    "    if daily.empty:\n",
    "        print(\"No daily slopes computed.\")\n",
    "        return\n",
    "\n",
    "    # Monthly aggregates\n",
    "    def iqr(x):\n",
    "        x = np.asarray(x, float)\n",
    "        return np.nanpercentile(x, 75) - np.nanpercentile(x, 25)\n",
    "\n",
    "    monthly = (daily\n",
    "               .groupby(\"month\", as_index=False)\n",
    "               .agg(n_days=(\"date_lt\", \"count\"),\n",
    "                    m_med=(\"slope_morning_tec_per_hour\",\"median\"),\n",
    "                    m_iqr=(\"slope_morning_tec_per_hour\", iqr),\n",
    "                    e_med=(\"slope_evening_tec_per_hour\",\"median\"),\n",
    "                    e_iqr=(\"slope_evening_tec_per_hour\", iqr))\n",
    "               .sort_values(\"month\"))\n",
    "\n",
    "    monthly.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"Saved {OUT_CSV}\")\n",
    "\n",
    "    # Quick plot\n",
    "    x = monthly[\"month\"].values\n",
    "    fig, ax = plt.subplots(figsize=(9,4))\n",
    "    ax.plot(x, monthly[\"m_med\"], \"-o\", label=\"Morning slope (median)\")\n",
    "    ax.plot(x, monthly[\"e_med\"], \"-o\", label=\"Evening slope (median)\")\n",
    "    ax.axhline(0, color=\"k\", lw=1.2, ls=\"--\")\n",
    "    ax.set_yticks([-3,-2,-1, 0, 1, 2, 3])\n",
    "\n",
    "    # style ticks\n",
    "    for t in ax.yaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    for t in ax.xaxis.get_ticklabels():\n",
    "        t.set_fontsize(10); t.set_color('black'); t.set_weight('bold')\n",
    "    ax.set_xticks(np.arange(1,13))\n",
    "    ax.set_xlim(0.5, 12.5)\n",
    "\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.text(0.5, 0.89, \"Quiet monthly diurnal slopes at OUCA (seasonal LT windows)\",\n",
    "             ha='center', fontsize=12, weight='bold')\n",
    "    fig.text(0.5, 0.03, 'Month of year', ha='center', fontsize=12, weight='bold')\n",
    "    fig.text(0.06, 0.5, 'dVTEC/dt [TECU/hour]', va='center', rotation='vertical',\n",
    "             fontsize=12, weight='bold')\n",
    "\n",
    "    fig.savefig(OUT_PNG, dpi=300)\n",
    "    print(f\"Saved {OUT_PNG}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf7733-4478-4efc-a2d0-6277d5b34185",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CELL — Figure 2 lignes :\n",
    "#   (1) Daily median EIA crest latitude near OUCA longitude\n",
    "#   (2) Monthly diurnal slopes (morning / evening)\n",
    "# ==========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "\n",
    "# --------- CONFIG: chemins à adapter si besoin ---------\n",
    "CSV_EIA   = Path(r\"G:\\My Drive\\14-DATA\\TEC_DATA\\daily_eia_crest_latitude.csv\")\n",
    "CSV_SLOPE = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/monthly_diurnal_slopes_seasonal_windows.csv\")\n",
    "\n",
    "OUT_PNG_COMBO = Path(r\"C:/Users/mkmoh/Dropbox/1-DATA/TEC_DATA/New_Data/EIAcrest_vs_monthly_slopes_MS.png\")\n",
    "\n",
    "OUCA_LAT = 31.206\n",
    "\n",
    "# --------- LECTURE DES DONNÉES ---------\n",
    "# 1) Crête EIA (daily)\n",
    "crest = pd.read_csv(CSV_EIA)\n",
    "\n",
    "if \"date_lt\" not in crest.columns:\n",
    "    raise ValueError(\"CSV_EIA doit contenir une colonne 'date_lt'.\")\n",
    "\n",
    "crest[\"date_lt\"] = pd.to_datetime(crest[\"date_lt\"], errors=\"coerce\")\n",
    "crest = crest.dropna(subset=[\"date_lt\", \"crest_lat_med\"])\n",
    "\n",
    "# 2) Pentes mensuelles\n",
    "monthly = pd.read_csv(CSV_SLOPE)\n",
    "for col in [\"month\", \"m_med\", \"e_med\"]:\n",
    "    if col not in monthly.columns:\n",
    "        raise ValueError(f\"CSV_SLOPE doit contenir la colonne '{col}'.\")\n",
    "\n",
    "monthly = monthly.sort_values(\"month\")\n",
    "x = monthly[\"month\"].values\n",
    "month_labels = [calendar.month_abbr[m] for m in x]  # Jan, Feb, ...\n",
    "\n",
    "# --------- FIGURE À 2 PANNEAUX ---------\n",
    "fig, (ax_top, ax_bot) = plt.subplots(2, 1, figsize=(12, 10), sharex=False)\n",
    "\n",
    "# =======================\n",
    "# (1) PANEL DU HAUT : CRÊTE EIA\n",
    "# =======================\n",
    "ax_top.plot(crest[\"date_lt\"], crest[\"crest_lat_med\"], lw=1.2,\n",
    "            label=\"Daily median crest latitude\")\n",
    "ax_top.axhline(OUCA_LAT, ls=\"--\", color=\"k\", lw=1.0, label=\"OUCA latitude\")\n",
    "\n",
    "ax_top.set_ylabel(\"Latitude [deg]\", fontsize=12, fontweight=\"bold\")\n",
    "ax_top.grid(True, alpha=0.3)\n",
    "\n",
    "# Légende en bas à droite pour limiter le chevauchement\n",
    "ax_top.legend(loc=\"best\", frameon=True)\n",
    "\n",
    "# style ticks\n",
    "for t in ax_top.yaxis.get_ticklabels():\n",
    "    t.set_fontsize(12); t.set_color('black'); t.set_weight('bold')\n",
    "for t in ax_top.xaxis.get_ticklabels():\n",
    "    t.set_fontsize(12); t.set_color('black'); t.set_weight('bold')\n",
    "\n",
    "ax_top.set_title(\"Northern EIA crest latitude near OUCA longitude\",\n",
    "                 fontsize=14, fontweight=\"bold\", loc=\"center\")\n",
    "\n",
    "# =======================\n",
    "# (2) PANEL DU BAS : PENTES MENSUELLES\n",
    "# =======================\n",
    "ax_bot.plot(x, monthly[\"m_med\"], \"-o\", label=\"Morning slope (median)\")\n",
    "ax_bot.plot(x, monthly[\"e_med\"], \"-o\", label=\"Evening slope (median)\")\n",
    "ax_bot.axhline(0, color=\"k\", lw=1.2, ls=\"--\")\n",
    "\n",
    "ax_bot.set_yticks([-3, -2, -1, 0, 1, 2, 3])\n",
    "ax_bot.set_xticks(x)\n",
    "ax_bot.set_xticklabels(month_labels)\n",
    "\n",
    "ax_bot.set_xlim(0.5, 12.5)\n",
    "\n",
    "# style ticks\n",
    "for t in ax_bot.yaxis.get_ticklabels():\n",
    "    t.set_fontsize(12); t.set_color('black'); t.set_weight('bold')\n",
    "for t in ax_bot.xaxis.get_ticklabels():\n",
    "    t.set_fontsize(12); t.set_color('black'); t.set_weight('bold')\n",
    "\n",
    "ax_bot.grid(True, alpha=0.3)\n",
    "\n",
    "# Légende en haut à droite pour rester hors des branches négatives\n",
    "ax_bot.legend(loc=\"best\", frameon=True)\n",
    "\n",
    "# Labels propres au panneau du bas\n",
    "ax_bot.set_ylabel('dVTEC/dt [TECU/hour]', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax_bot.set_title(\"Quiet monthly diurnal slopes at OUCA (seasonal LT windows)\",\n",
    "                 fontsize=14, fontweight=\"bold\", loc=\"center\")\n",
    "\n",
    "# Label global de l’axe x\n",
    "fig.text(0.5, 0.03, 'Month of year', ha='center', fontsize=12, weight='bold')\n",
    "\n",
    "#fig.tight_layout(rect=[0.06, 0.06, 0.98, 0.93])\n",
    "\n",
    "fig.savefig(OUT_PNG_COMBO, dpi=300)\n",
    "plt.close(fig)\n",
    "print(f\"Saved combined figure -> {OUT_PNG_COMBO}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
